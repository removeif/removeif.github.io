{"pages":[{"title":"","text":"404","link":"/404.html"},{"title":"最新评论列表","text":"ps:latest comment exists 10 minutes delay…","link":"/comment/index.html"},{"title":"关于我","text":"个人简介 本科计算机科学与技术专业 从事JAVA后端开发 码畜一枚 坚信代码改变世界 博客 网站采用的Icarus主题 本站推荐索引 技术知识点 Java并发知识点 法律法规 法律法规数据库 中华人名共和国网络安全法 中华人民共和国劳动法 其他 网易云音乐歌单分享 记录 12:24:05/08/23/2019 一月遍收银色界，两山相击海潮音。 January不知细叶谁裁出，二月春风似剪刀。 February风光三月连樱笋，美人踌躇白日静。 March四月清和雨乍晴，南山当户转分明。 April松下茅亭五月凉，汀沙云树晚苍苍。 May依依宜织江雨空，雨中六月兰台风。 June七月新秋风露早，渚莲尚拆庭梧老。 July风回玉宇三更夜，露滴金茎八月秋。 August可怜九月初三夜，露似珍珠月似弓。 September江南十月春色早，处处梅花当水开。 October每到十一月初五，一狐疑了一狐疑。 November日晏霜浓十二月，林疏石瘦第三溪。 December – jawil/blog 13:24:05/08/22/2019 若能避开猛烈的欢喜,自然也不会有悲伤的来袭。 –《人间失格》 16:24:05/07/19/2019 相看两不厌，只有敬亭山。 –李白 15:06:28/06/06/2019 爱情就像在海滩上捡贝壳，不要捡最大的， 也不要捡最漂亮的，要捡就捡自己最喜欢的， 最重要的是捡到了自己喜欢的 就永远不要再去海边了。 –公众号文章 11:07/05/22/2019 无论走到哪里，都应该记住。过去都是假的，回忆是一条没有尽头的路，一切以往的春天都不复存在，就连那最坚韧而又狂乱的爱情归根结底也不过是一种转瞬即逝的现实。 –马尔克斯《百年孤独》 11:05/05/22/2019 我觉得美不是一切，它很浪费人生。美要加上滋味、加上开心、加上别的东西，才是人生的美满。 –张曼玉 15:37/05/06/2019 Under no circumstances will I give up loving you.山无棱天地合才敢与君绝。 –《mooc学院》 17:15/04/26/2019 一个人无法自成孤岛，要么至少，一个人无法自成最理想的孤岛。 –《岛上书店》 17:12/04/22/2019 你写下的每一个bug，都是人类反抗被人工智能统治的一颗子弹 17:12/04/22/2019 所谓活着并不是单纯的呼吸，心脏跳动，也不是脑电波，而是在这个世界上留下痕迹。要能看见自己一路走来的脚印，并确信那些都是自己留下的印记，这才叫活着。 –《东野圭吾》 2019计划 21:59/12/31/2018 2019-GOALS 购买的专业书籍至少看完一遍（并发、重构、设计模式…） 微信读书每天一个小时(目前时长:95h,年终总计300小时) 坚持每周去两次健身房(多练肚子、力量、学会蝶泳) 至少完成一项 前后端分离项目 完成一项 微服务项目(类似公司使用相关技术) 不辞职 多交朋友、多换位思考、多与朋友交流沟通 居安思危，多思考关注相关专业前景，生活环境 Java基础技能强化 多买书 学习更多的新菜(至少三项) 少买电子产品，少网购，少逛数码产品 学英语记单词、学数学、多看视频教程 少玩游戏 -2019.06卸载游戏","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"音乐歌单收藏","text":"温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放哟！","link":"/music1/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"poetry","text":"","link":"/poetry/index.html"},{"title":"留言板","text":"畅所欲言有留必应","link":"/message/index.html"},{"title":"","text":"图片搜集于互联网，侵权请留言，马上处理😊。","link":"/album/index.html"},{"title":"","text":"音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。有好听的音乐欢迎分享。","link":"/music/index.html"}],"posts":[{"title":"MyBatis二级缓存","text":"摘要我们在上一篇文章介绍了 MyBatis 的一级缓存的作用，如何开启，一级缓存的本质是什么，一级缓存失效的原因是什么？MyBatis 只有一级缓存吗？来找找答案吧！MyBatis 二级缓存介绍 上一篇文章中我们介绍到了 MyBatis 一级缓存其实就是 SqlSession 级别的缓存，什么是 SqlSession 级别的缓存呢？一级缓存的本质是什么呢？以及一级缓存失效的原因？我希望你在看下文之前能够回想起来这些内容。 MyBatis 一级缓存最大的共享范围就是一个SqlSession内部，那么如果多个 SqlSession 需要共享缓存，则需要开启二级缓存，开启二级缓存后，会使用 CachingExecutor 装饰 Executor，进入一级缓存的查询流程前，先在CachingExecutor 进行二级缓存的查询，具体的工作流程如下所示 当二级缓存开启后，同一个命名空间(namespace) 所有的操作语句，都影响着一个 共同的 cache，也就是二级缓存被多个 SqlSession 共享，是一个全局的变量。当开启缓存后，数据的查询执行的流程就是 二级缓存 -&gt; 一级缓存 -&gt; 数据库。 二级缓存开启条件 二级缓存默认是不开启的，需要手动开启二级缓存，实现二级缓存的时候，MyBatis要求返回的POJO必须是可序列化的。开启二级缓存的条件也是比较简单，通过直接在 MyBatis 配置文件中通过 1&lt;settings&gt; &lt;setting name = \"cacheEnabled\" value = \"true\" /&gt;&lt;/settings&gt; 来开启二级缓存，还需要在 Mapper 的xml 配置文件中加入 标签 设置 cache 标签的属性 cache 标签有多个属性，一起来看一些这些属性分别代表什么意义 eviction: 缓存回收策略，有这几种回收策略 LRU - 最近最少回收，移除最长时间不被使用的对象 FIFO - 先进先出，按照缓存进入的顺序来移除它们 SOFT - 软引用，移除基于垃圾回收器状态和软引用规则的对象 WEAK - 弱引用，更积极的移除基于垃圾收集器和弱引用规则的对象 默认是 LRU 最近最少回收策略 flushinterval 缓存刷新间隔，缓存多长时间刷新一次，默认不清空，设置一个毫秒值 readOnly: 是否只读；true 只读 ，MyBatis 认为所有从缓存中获取数据的操作都是只读操作，不会修改数据。MyBatis 为了加快获取数据，直接就会将数据在缓存中的引用交给用户。不安全，速度快。读写(默认)：MyBatis 觉得数据可能会被修改 size : 缓存存放多少个元素 type: 指定自定义缓存的全类名(实现Cache 接口即可) blocking：若缓存中找不到对应的key，是否会一直blocking，直到有对应的数据进入缓存。 探究二级缓存 我们继续以 MyBatis 一级缓存文章中的例子为基础，搭建一个满足二级缓存的例子，来对二级缓存进行探究，例子如下(对 一级缓存的例子部分源码进行修改)： Dept.java //存放在共享缓存中数据进行序列化操作和反序列化操作 //因此数据对应实体类必须实现【序列化接口】并提供 无参数的构造方法 1public class Dept implements Serializable myBatis-config.xml 在myBatis-config 中添加开启二级缓存的条件 1&lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; DeptDao.xml 还需要在 Mapper 对应的xml中添加 cache 标签，表示对哪个mapper 开启缓存 对应的二级缓存测试类如下： 123456789101112131415161718192021222324252627282930313233343536public class MyBatisSecondCacheTest { private SqlSession sqlSession; SqlSessionFactory factory; @Before public void start() throws IOException { InputStream is = Resources.getResourceAsStream(\"myBatis-config.xml\"); SqlSessionFactoryBuilder builderObj = new SqlSessionFactoryBuilder(); factory = builderObj.build(is); sqlSession = factory.openSession(); } @After public void destory(){ if(sqlSession!=null){ sqlSession.close(); } } @Test public void testSecondCache(){ //会话过程中第一次发送请求，从数据库中得到结果 //得到结果之后，mybatis自动将这个查询结果放入到当前用户的一级缓存 DeptDao dao = sqlSession.getMapper(DeptDao.class); Dept dept = dao.findByDeptNo(1); System.out.println(\"第一次查询得到部门对象 = \"+dept); //触发MyBatis框架从当前一级缓存中将Dept对象保存到二级缓存 sqlSession.commit(); // 改成 sqlSession.close(); 效果相同 SqlSession session2 = factory.openSession(); DeptDao dao2 = session2.getMapper(DeptDao.class); Dept dept2 = dao2.findByDeptNo(1); System.out.println(\"第二次查询得到部门对象 = \"+dept2); }} 测试二级缓存效果，提交事务，sqlSession 查询完数据后，sqlSession2相同的查询是否会从缓存中获取数据。 测试结果如下： 通过结果可以得知，首次执行的SQL语句是从数据库中查询得到的结果，然后第一个 SqlSession 执行提交，第二个 SqlSession 执行相同的查询后是从缓存中查取的。 用一下这幅图能够比较直观的反映两次 SqlSession 的缓存命中 二级缓存失效的条件 与一级缓存一样，二级缓存也会存在失效的条件的，下面我们就来探究一下哪些情况会造成二级缓存失效 第一次SqlSession 未提交 SqlSession 在未提交的时候，SQL 语句产生的查询结果还没有放入二级缓存中，这个时候 SqlSession2 在查询的时候是感受不到二级缓存的存在的，修改对应的测试类，结果如下： 1234567891011121314@Testpublic void testSqlSessionUnCommit(){ //会话过程中第一次发送请求，从数据库中得到结果 //得到结果之后，mybatis自动将这个查询结果放入到当前用户的一级缓存 DeptDao dao = sqlSession.getMapper(DeptDao.class); Dept dept = dao.findByDeptNo(1); System.out.println(\"第一次查询得到部门对象 = \"+dept); //触发MyBatis框架从当前一级缓存中将Dept对象保存到二级缓存 SqlSession session2 = factory.openSession(); DeptDao dao2 = session2.getMapper(DeptDao.class); Dept dept2 = dao2.findByDeptNo(1); System.out.println(\"第二次查询得到部门对象 = \"+dept2);} 产生的输出结果： 更新对二级缓存影响 与一级缓存一样，更新操作很可能对二级缓存造成影响，下面用三个 SqlSession来进行模拟，第一个 SqlSession 只是单纯的提交，第二个 SqlSession 用于检验二级缓存所产生的影响，第三个 SqlSession 用于执行更新操作，测试如下： 1234567891011121314151617181920212223242526@Testpublic void testSqlSessionUpdate(){ SqlSession sqlSession = factory.openSession(); SqlSession sqlSession2 = factory.openSession(); SqlSession sqlSession3 = factory.openSession(); // 第一个 SqlSession 执行更新操作 DeptDao deptDao = sqlSession.getMapper(DeptDao.class); Dept dept = deptDao.findByDeptNo(1); System.out.println(\"dept = \" + dept); sqlSession.commit(); // 判断第二个 SqlSession 是否从缓存中读取 DeptDao deptDao2 = sqlSession2.getMapper(DeptDao.class); Dept dept2 = deptDao2.findByDeptNo(1); System.out.println(\"dept2 = \" + dept2); // 第三个 SqlSession 执行更新操作 DeptDao deptDao3 = sqlSession3.getMapper(DeptDao.class); deptDao3.updateDept(new Dept(1,\"ali\",\"hz\")); sqlSession3.commit(); // 判断第二个 SqlSession 是否从缓存中读取 dept2 = deptDao2.findByDeptNo(1); System.out.println(\"dept2 = \" + dept2);} 对应的输出结果如下 ​ 探究多表操作对二级缓存的影响 现有这样一个场景，有两个表，部门表dept（deptNo,dname,loc）和 部门数量表deptNum（id,name,num），其中部门表的名称和部门数量表的名称相同，通过名称能够联查两个表可以知道其坐标(loc)和数量(num)，现在我要对部门数量表的 num 进行更新，然后我再次关联dept 和 deptNum 进行查询，你认为这个 SQL 语句能够查询到的 num 的数量是多少？来看一下代码探究一下 12345678public class DeptNum { private int id; private String name; private int num; get and set...} 12345678910111213141516171819202122public class DeptVo { private Integer deptNo; private String dname; private String loc; private Integer num; public DeptVo(Integer deptNo, String dname, String loc, Integer num) { this.deptNo = deptNo; this.dname = dname; this.loc = loc; this.num = num; } public DeptVo(String dname, Integer num) { this.dname = dname; this.num = num; } get and set... toString()...} 123456789public interface DeptDao { // ...其他方法 DeptVo selectByDeptVo(String name); DeptVo selectByDeptVoName(String name); int updateDeptVoNum(DeptVo deptVo);} 123456789101112&lt;select id=\"selectByDeptVo\" resultType=\"com.mybatis.beans.DeptVo\"&gt; select d.deptno,d.dname,d.loc,dn.num from dept d,deptNum dn where dn.name = d.dname and d.dname = #{name}&lt;/select&gt;&lt;select id=\"selectByDeptVoName\" resultType=\"com.mybatis.beans.DeptVo\"&gt; select * from deptNum where name = #{name}&lt;/select&gt;&lt;update id=\"updateDeptVoNum\" parameterType=\"com.mybatis.beans.DeptVo\"&gt; update deptNum set num = #{num} where name = #{dname}&lt;/update&gt; DeptNum 数据库初始值： 123456789101112131415161718192021/** * 探究多表操作对二级缓存的影响 */@Testpublic void testOtherMapper(){ // 第一个mapper 先执行联查操作 SqlSession sqlSession = factory.openSession(); DeptDao deptDao = sqlSession.getMapper(DeptDao.class); DeptVo deptVo = deptDao.selectByDeptVo(\"ali\"); System.out.println(\"deptVo = \" + deptVo); // 第二个mapper 执行更新操作 并提交 SqlSession sqlSession2 = factory.openSession(); DeptDao deptDao2 = sqlSession2.getMapper(DeptDao.class); deptDao2.updateDeptVoNum(new DeptVo(\"ali\",1000)); sqlSession2.commit(); sqlSession2.close(); // 第一个mapper 再次进行查询,观察查询结果 deptVo = deptDao.selectByDeptVo(\"ali\"); System.out.println(\"deptVo = \" + deptVo);} 测试结果如下： 在对DeptNum 表执行了一次更新后，再次进行联查，发现数据库中查询出的还是 num 为 1050 的值，也就是说，实际上 1050 -&gt; 1000 ，最后一次联查实际上查询的是第一次查询结果的缓存，而不是从数据库中查询得到的值，这样就读到了脏数据。 解决办法 如果是两个mapper命名空间的话，可以使用&lt;cache-ref&gt;来把一个命名空间指向另外一个命名空间，从而消除上述的影响，再次执行，就可以查询到正确的数据 二级缓存源码解析 源码模块主要分为两个部分：二级缓存的创建和二级缓存的使用，首先先对二级缓存的创建进行分析： 二级缓存的创建 二级缓存的创建是使用 Resource 读取 XML 配置文件开始的 123InputStream is = Resources.getResourceAsStream(\"myBatis-config.xml\");SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder();factory = builder.build(is); 读取配置文件后，需要对XML创建 Configuration并初始化 12XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);return build(parser.parse()); 调用 parser.parse() 解析根目录 /configuration 下面的标签，依次进行解析 12345678public Configuration parse() { if (parsed) { throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\"); } parsed = true; parseConfiguration(parser.evalNode(\"/configuration\")); return configuration;} 123456789101112131415161718192021private void parseConfiguration(XNode root) { try { //issue #117 read properties first propertiesElement(root.evalNode(\"properties\")); Properties settings = settingsAsProperties(root.evalNode(\"settings\")); loadCustomVfs(settings); typeAliasesElement(root.evalNode(\"typeAliases\")); pluginElement(root.evalNode(\"plugins\")); objectFactoryElement(root.evalNode(\"objectFactory\")); objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\")); reflectorFactoryElement(root.evalNode(\"reflectorFactory\")); settingsElement(settings); // read it after objectFactory and objectWrapperFactory issue #631 environmentsElement(root.evalNode(\"environments\")); databaseIdProviderElement(root.evalNode(\"databaseIdProvider\")); typeHandlerElement(root.evalNode(\"typeHandlers\")); mapperElement(root.evalNode(\"mappers\")); } catch (Exception e) { throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e); }} 其中有一个二级缓存的解析就是 1mapperElement(root.evalNode(\"mappers\")); 然后进去 mapperElement 方法中 12XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments()); mapperParser.parse(); 继续跟 mapperParser.parse() 方法 1234567891011public void parse() { if (!configuration.isResourceLoaded(resource)) { configurationElement(parser.evalNode(\"/mapper\")); configuration.addLoadedResource(resource); bindMapperForNamespace(); } parsePendingResultMaps(); parsePendingCacheRefs(); parsePendingStatements();} 这其中有一个 configurationElement 方法，它是对二级缓存进行创建，如下 1234567891011121314151617private void configurationElement(XNode context) { try { String namespace = context.getStringAttribute(\"namespace\"); if (namespace == null || namespace.equals(\"\")) { throw new BuilderException(\"Mapper's namespace cannot be empty\"); } builderAssistant.setCurrentNamespace(namespace); cacheRefElement(context.evalNode(\"cache-ref\")); cacheElement(context.evalNode(\"cache\")); parameterMapElement(context.evalNodes(\"/mapper/parameterMap\")); resultMapElements(context.evalNodes(\"/mapper/resultMap\")); sqlElement(context.evalNodes(\"/mapper/sql\")); buildStatementFromContext(context.evalNodes(\"select|insert|update|delete\")); } catch (Exception e) { throw new BuilderException(\"Error parsing Mapper XML. Cause: \" + e, e); }} 有两个二级缓存的关键点 12cacheRefElement(context.evalNode(\"cache-ref\"));cacheElement(context.evalNode(\"cache\")); 也就是说，mybatis 首先进行解析的是 cache-ref 标签，其次进行解析的是 cache 标签。 根据上面我们的 — 多表操作对二级缓存的影响 一节中提到的解决办法，采用 cache-ref 来进行命名空间的依赖能够避免二级缓存，但是总不能每次写一个 XML 配置都会采用这种方式吧，最有效的方式还是避免多表操作使用二级缓存 然后我们再来看一下cacheElement(context.evalNode(“cache”)) 这个方法 1234567891011121314private void cacheElement(XNode context) throws Exception { if (context != null) { String type = context.getStringAttribute(\"type\", \"PERPETUAL\"); Class&lt;? extends Cache&gt; typeClass = typeAliasRegistry.resolveAlias(type); String eviction = context.getStringAttribute(\"eviction\", \"LRU\"); Class&lt;? extends Cache&gt; evictionClass = typeAliasRegistry.resolveAlias(eviction); Long flushInterval = context.getLongAttribute(\"flushInterval\"); Integer size = context.getIntAttribute(\"size\"); boolean readWrite = !context.getBooleanAttribute(\"readOnly\", false); boolean blocking = context.getBooleanAttribute(\"blocking\", false); Properties props = context.getChildrenAsProperties(); builderAssistant.useNewCache(typeClass, evictionClass, flushInterval, size, readWrite, blocking, props); }} 认真看一下其中的属性的解析，是不是感觉很熟悉？这不就是对 cache 标签属性的解析吗？！！！ 上述最后一句代码 1builderAssistant.useNewCache(typeClass, evictionClass, flushInterval, size, readWrite, blocking, props); 1234567891011121314151617181920public Cache useNewCache(Class&lt;? extends Cache&gt; typeClass, Class&lt;? extends Cache&gt; evictionClass, Long flushInterval, Integer size, boolean readWrite, boolean blocking, Properties props) { Cache cache = new CacheBuilder(currentNamespace) .implementation(valueOrDefault(typeClass, PerpetualCache.class)) .addDecorator(valueOrDefault(evictionClass, LruCache.class)) .clearInterval(flushInterval) .size(size) .readWrite(readWrite) .blocking(blocking) .properties(props) .build(); configuration.addCache(cache); currentCache = cache; return cache; } 这段代码使用了构建器模式，一步一步构建Cache 标签的所有属性，最终把 cache 返回。 二级缓存的使用 在 mybatis 中，使用 Cache 的地方在 CachingExecutor中，来看一下 CachingExecutor 中缓存做了什么工作，我们以查询为例 12345678910111213141516171819202122@Overridepublic &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { // 得到缓存 Cache cache = ms.getCache(); if (cache != null) { // 如果需要的话刷新缓存 flushCacheIfRequired(ms); if (ms.isUseCache() &amp;&amp; resultHandler == null) { ensureNoOutParams(ms, parameterObject, boundSql); @SuppressWarnings(\"unchecked\") List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); if (list == null) { list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // issue #578 and #116 } return list; } } // 委托模式，交给SimpleExecutor等实现类去实现方法。 return delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);} 其中，先从 MapperStatement 取出缓存。只有通过,或@CacheNamespace,@CacheNamespaceRef标记使用缓存的Mapper.xml或Mapper接口（同一个namespace，不能同时使用）才会有二级缓存。 如果缓存不为空，说明是存在缓存。如果cache存在，那么会根据sql配置(&lt;insert&gt;,&lt;select&gt;,&lt;update&gt;,&lt;delete&gt;的flushCache属性来确定是否清空缓存。 1flushCacheIfRequired(ms); 然后根据xml配置的属性useCache来判断是否使用缓存(resultHandler一般使用的默认值，很少会null)。 1if (ms.isUseCache() &amp;&amp; resultHandler == null) 确保方法没有Out类型的参数，mybatis不支持存储过程的缓存，所以如果是存储过程，这里就会报错。 123456789private void ensureNoOutParams(MappedStatement ms, Object parameter, BoundSql boundSql) { if (ms.getStatementType() == StatementType.CALLABLE) { for (ParameterMapping parameterMapping : boundSql.getParameterMappings()) { if (parameterMapping.getMode() != ParameterMode.IN) { throw new ExecutorException(\"Caching stored procedures with OUT params is not supported. Please configure useCache=false in \" + ms.getId() + \" statement.\"); } } }} 然后根据在 TransactionalCacheManager 中根据 key 取出缓存，如果没有缓存，就会执行查询，并且将查询结果放到缓存中并返回取出结果，否则就执行真正的查询方法。 123456List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key);if (list == null) { list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // issue #578 and #116}return list; 是否应该使用二级缓存？ 那么究竟应该不应该使用二级缓存呢？先来看一下二级缓存的注意事项： 缓存是以namespace为单位的，不同namespace下的操作互不影响。 insert,update,delete操作会清空所在namespace下的全部缓存。 通常使用MyBatis Generator生成的代码中，都是各个表独立的，每个表都有自己的namespace。 多表操作一定不要使用二级缓存，因为多表操作进行更新操作，一定会产生脏数据。 如果你遵守二级缓存的注意事项，那么你就可以使用二级缓存。 但是，如果不能使用多表操作，二级缓存不就可以用一级缓存来替换掉吗？而且二级缓存是表级缓存，开销大，没有一级缓存直接使用 HashMap 来存储的效率更高，所以二级缓存并不推荐使用。 文章来源.","link":"/2019/08/28/MyBatis二级缓存.html"},{"title":"Vim基本入门操作","text":"简介 Vim（Vi[Improved]）编辑器是功能强大的跨平台文本文件编辑工具，继承自Unix系统的Vi编辑器，支持Linux/Mac OS X/Windows系统，利用它可以建立、修改文本文件。进入Vim编辑程序，可以在终端输入下面的命令： 1$vim [filename] 其中filename是要编辑器的文件的路径名。如果文件不存在，它将为你建立一个新文件。Vim编辑程序有三种操作模式，分别称为 编辑模式、插入模式 和 命令模式，当运行Vim时，首先进入编辑模式。 编辑模式Vim编辑方式的主要用途是在被编辑的文件中移动光标的位置。一旦光标移到到所要的位置，就可以进行剪切和粘贴正文块，删除正文和插入新的正文。当完成所有的编辑工作后，需要保存编辑器结果，退出编辑程序回到终端，可以发出ZZ命令，连续按两次大写的Z键。 跳转如果键盘上有上、下、左、右箭头的导航键，就由这些键来完成光标的移动。另外，可以用下面的键完成同样的 按字符移动 功能： 1234k 上移；j 下移；h 左移；l 右移。 上面这４个键将光标位置每次移动一行或一个 字符 。Vim还提供稍大范围移动光标的命令： 12ctrl+f 在文件中前移一页（相当于 page down）；ctrl+b 在文件中后移一页（相当于 page up）； 更大范围的移动：gg 起始位置, G最后一行,g_本行最后 123456789101112* 当光标停留在一个单词上，* 键会在文件内搜索该单词，并跳转到下一处；# 当光标停留在一个单词上，# 在文件内搜索该单词，并跳转到上一处；(/) 移动到 前/后 句 的开始；{/} 跳转到 当前/下一个 段落 的开始。g_ 到本行最后一个不是 blank 字符的位置。fa 到下一个为 a 的字符处，你也可以fs到下一个为s的字符。t, 到逗号前的第一个字符。逗号可以变成其它字符。3fa 在当前行查找第三个出现的 a。F/T 和 f 和 t 一样，只不过是相反方向;gg 将光标定位到文件第一行起始位置；G 将光标定位到文件最后一行起始位置；NG或Ngg 将光标定位到第 N 行的起始位置。 在屏幕中找到需要的 一页 时，可以用下面的命令快速移动光标：H起始行，M中间行，L最后行 123H 将光标移到屏幕上的起始行（或最上行）；M 将光标移到屏幕中间；L 将光标移到屏幕最后一行。 同样需要注意字母的大小写。H 和 L 命令还可以加数字。如 2H 表示将光标移到屏幕的第２行，3L 表示将光标移到屏幕的倒数第3行。 当将光标移到所要的行是，行内移动 光标可以用下面的命令来实现：&amp;末尾，^行头 123456w 右移光标到下一个字的开头；e 右移光标到一个字的末尾；b 左移光标到前一个字的开头；0 数字０，左移光标到本行的开始；$ 右移光标，到本行的末尾；^ 移动光标，到本行的第一个非空字符。 2.2 搜索匹配和许多先进的编辑器一样，Vim 提供了强大的字符串搜索功能。要查找文件中指定字或短语出现的位置，可以用Vim直接进行搜索，而不必以手工方式进行。搜索方法是：键入字符 / ，后面跟以要搜索的字符串，然后按回车键。编辑程序执行正向搜索（即朝文件末尾方向），并在找到指定字符串后，将光标停到该字符串的开头；键入 n 命令可以继续执行搜索，找出这一字符串下次出现的位置。用字符 ? 取代 / ，可以实现反向搜索。例如：/str ，n下次出现，n上次出现 1234/str1 正向搜索字符串 str1；n 继续搜索，找出 str1 字符串下次出现的位置；N 继续搜索，找出 str1 字符串上一次出现的位置；?str2 反向搜索字符串 str2 。 无论搜索方向如何，当到达文件末尾或开头时，搜索工作会循环到文件的另一端并继续执行。 Vim中执行搜索匹配最强大的地方是结合 正则表达式 来搜索，后续将会介绍。 2.3 替换和删除Vim常规的删除命令是 d、 x (前者删除 行 ，后者删除 字符 ),结合Vim的其他特性可以实现基础的删除功能。将光标定位于文件内指定位置后，可以用其他字符来替换光标所指向的字符，或从当前光标位置删除一个或多个字符或一行、多行。例如： 123456789101112131415rc 用 c 替换光标所指向的当前字符；nrc 用 c 替换光标所指向的前 n 个字符；5rA 用 A 替换光标所指向的前 5 个字符；x 删除光标所指向的当前字符；nx 删除光标所指向的前 n 个字符；3x 删除光标所指向的前 3 个字符；dw 删除光标右侧的字；ndw 删除光标右侧的 n 个字；3dw 删除光标右侧的 3 个字；db 删除光标左侧的字；ndb 删除光标左侧的 n 个字；5db 删除光标左侧的 5 个字；dd 删除光标所在行，并去除空隙；ndd 删除（剪切） n 行内容，并去除空隙；3dd 删除（剪切） 3 行内容，并去除空隙； 其他常用的删除命令有：d$删到行尾，d0删到行首，J合并下行 123d$ 从当前光标起删除字符直到行的结束；d0 从当前光标起删除字符直到行的开始；J 删除本行的回车符（CR），并和下一行合并。 Vim常规的替换命令有 c 和 s ，结合Vim的其他特性可以实现基础的替换功能，不过替换命令执行以后，通常会由 编辑模式 进入 插入模式 ： 12345678910111213s 用输入的正文替换光标所指向的字符；S 删除当前行，并进入插入模式；ns 用输入的正文替换光标右侧 n 个字符；nS 删除当前行在内的 n 行，并进入插入模式；cw 用输入的正文替换光标右侧的字；cW 用输入的正文替换从光标到行尾的所有字符（同 c$ )；ncw 用输入的正文替换光标右侧的 n 个字；cb 用输入的正文替换光标左侧的字；ncb 用输入的正文替换光标左侧的 n 个字；cd 用输入的正文替换光标的所在行；ncd 用输入的正文替换光标下面的 n 行；c$ 用输入的正文替换从光标开始到本行末尾的所有字符；c0 用输入的正文替换从本行开头到光标的所有字符。 2.4 复制粘贴从正文中删除的内容（如字符、字或行）并没有真正丢失，而是被剪切并复制到了一个内存缓冲区中。用户可将其粘贴到正文中的指定位置。完成这一操作的命令是：p粘到后面，P粘到前面 12p 小写字母 p，将缓冲区的内容粘贴到光标的后面；P 大写字母 P，将缓冲区的内容粘贴到光标的前面。 如果缓冲区的内容是字符或字，直接粘贴在光标的前面或后面；如果缓冲区的内容为整行正文，执行上述粘贴命令将会粘贴在当前光标所在行的上一行或下一行。 注意上述两个命令中字母的大小写。Vim 编辑器经常以一对大、小写字母（如 p 和 P）来提供一对相似的功能。通常，小写命令在光标的后面进行操作，大写命令在光标的前面进行操作。 有时需要复制一段正文到新位置，同时保留原有位置的内容。这种情况下，首先应当把指定内容复制（而不是剪切）到内存缓冲区。完成这一操作的命令是：yy 复制一行，nyy 复制n行 12345yy 复制当前行到内存缓冲区；nyy 复制 n 行内容到内存缓冲区；5yy 复制 5 行内容到内存缓冲区；“+y 复制 1 行到操作系统的粘贴板；“+nyy 复制 n 行到操作系统的粘贴板。 2.5 撤销和重复在编辑文档的过程中，为消除某个错误的编辑命令造成的后果，可以用撤消命令。另外，如果用户希望在新的光标位置重复前面执行过的编辑命令，可用重复命令。u撤销前一条，.重复最后一条命令 12u 撤消前一条命令的结果；. 重复最后一条修改正文的命令。 3. 插入模式3.1 进入插入模式在编辑模式下正确定位光标之后，可用以下命令切换到插入模式：i左，a右，o下一行，O上一行，I光标开头，A末尾 123456i 在光标左侧插入正文a 在光标右侧插入正文o 在光标所在行的下一行增添新行O 在光标所在行的上一行增添新行I 在光标所在行的开头插入A 在光标所在行的末尾插入 3.2 退出插入模式退出插入模式的方法是，按 ESC 键或组合键 Ctrl+[ ，退出插入模式之后，将会进入编辑模式 。 4. 命令模式在Vim的命令模式下，可以使用复杂的命令。在编辑模式下键入 : ，光标就跳到屏幕最后一行，并在那里显示冒号，此时已进入命令模式。命令模式又称 末行模式 ，用户输入的内容均显示在屏幕的最后一行，按回车键，Vim 执行命令。 4.1 打开、保存、退出在已经启动的Vim中打开一个文件需要用 :e 命令： 1:e path_to_file/filename 保存当前编辑的文件需要用 :w 命令（单词 write 的缩写）： 1:w 将当前文件另存为 file_temp 则： 1:w file_temp 在编辑模式下可以用 ZZ 命令退出Vim编辑程序，该命令保存对正文所作的修改，覆盖原始文件。如果只需要退出编辑程序，而不打算保存编辑的内容，可用下面的命令： 12: q 在未作修改的情况下退出；: q! 放弃所有修改，退出编辑程序。 保存并退出则可以讲两条命令结合起来使用（注意命令顺序，先保存，后退出）： 1:wq 4.2 行号与文件编辑中的每一行正文都有自己的行号，用下列命令可以移动光标到指定行（效果与 编辑模式 下的 ngg 或 nG 相同）： 1: n 将光标移到第 n 行 命令模式下，可以规定命令操作的行号范围。数值用来指定绝对行号；字符“.”表示光标所在行的行号；字符符“$”表示正文最后一行的行号；简单的表达式，例如“.+5”表示当前行往下的第 5 行。例如： 1234567:345 将光标移到第 345 行:345w file 将第 345 行写入 file 文件:3,5w file 将第 3 行至第 5 行写入 file 文件:1,.w file 将第 1 行至当前行写入 file 文件:.,$w file 将当前行至最后一行写入 file 文件:.,.+5w file 从当前行开始将 6 行内容写入 file 文件:1,$w file 将所有内容写入 file 文件，相当于 :w file 命令 在命令模式下，允许从文件中读取正文，或将正文写入文件。例如： 12345678:w 将编辑的内容写入原始文件，用来保存编辑的中间结果:wq 将编辑的内容写入原始文件并退出编辑程序（相当于 ZZ 命令）:w file 将编辑的内容写入 file 文件，保持原有文件的内容不变:a,bw file 将第 a 行至第 b 行的内容写入 file 文件:r file 读取 file 文件的内容，插入当前光标所在行的后面:e file 编辑新文件 file 代替原有内容:f file 将当前文件重命名为 file:f 打印当前文件名称和状态，如文件的行数、光标所在的行号等 4.3 字符串搜索在 编辑模式 讲过字符串的搜索，此处的 命令模式 也可以进行字符串搜索，给出一个字符串，可以通过搜索该字符串到达指定行。如果希望进行正向搜索，将待搜索的字符串置于两个 / 之间；如果希望反向搜索，则将字符串放在两个 ? 之间。例如： 1234:/str/ 正向搜索，将光标移到下一个包含字符串 str 的行:?str? 反向搜索，将光标移到上一个包含字符串 str 的行:/str/w file 正向搜索，并将第一个包含字符串 str 的行写入 file 文件:/str1/,/str2/w file 正向搜索，并将包含字符串 str1 的行至包含字符串 str2 的行写 4.4 Vim中的正则表达式当给Vim指定搜索字符串时，可以包含具有特殊含义的字符。包含这些特殊字符的搜索字符串称为正则表达式（Regular Expressions）。例如，要搜索一行正文，这行正文的开头包含 struct 字。下面的命令做不到这一点： 1:/struct/ 因为它只找出在行中任意位置包含 struct的第一行，并不一定在行的开始包含 struct 。解决问题的办法是在搜索字符串前面加上特殊字符^： 1:/^struct/ ^ 字符比较每行开头的字符串。所以上面的命令表示：找出以字符串 struct 开头的行。 也可以用类似办法在搜索字符串后面加上表示行的末尾的特殊字符 $ 来找出位于行末尾的字： 1:/^struct/ 下表给出大多数特殊字符和它们的含义： 12345678910^ 放在字符串前面，匹配行首的字；$ 放在字符串后面，匹配行尾的字；\\&lt; 匹配一个字的字头；\\&gt; 匹配一个字的字尾；. 匹配任何单个正文字符；[str] 匹配 str 中的任何单个字符；[^str] 匹配任何不在 str 中的单个字符；[a-b] 匹配 a 到 b 之间的任一字符；* 匹配前一个字符的 0 次或多次出现；\\ 转义后面的字符。 简单介绍这么多，正则表达式知识可以参考 《正则表达式30分钟入门》:http://deerchao.net/tutorials/regex/regex.htm 另外，进阶的Vim正则表达式还有对Magic 模式的介绍，可以参考 《Vim正则表达式详解》: http://blog.csdn.net/salc3k/article/details/8222397 4.5 正文替换利用 :s 命令可以实现字符串的替换。具体的用法包括： 123456:%s/str1/str2/ 用字符串 str2 替换行中首次出现的字符串 str1:s/str1/str2/g 用字符串 str2 替换行中所有出现的字符串 str1:.,$ s/str1/str2/g 用字符串 str2 替换正文当前行到末尾所有出现的字符串 str1:1,$ s/str1/str2/g 用字符串 str2 替换正文中所有出现的字符串 str1:g/str1/s//str2/g 功能同上:m,ns/str1/str2/g 将从m行到n行的str1替换成str2 从上述替换命令可以看到： 1`g` 放在命令末尾，表示对搜索字符串的每次出现进行替换,不止匹配每行中的第一次出现；不加 `g`，表示只对搜索字符串的首次出现进行替换；`g` 放在命令开头，表示对正文中所有包含搜索字符串的行进行替换操作; 1`s` 表示后面跟着一串替换的命令； 1`%` 表示替换范围是所有行，即全文。 另外一个实用的命令，在Vim中统计当前文件中字符串 str1 出现的次数，可用替换命令的变形： 1:%s/str1/&amp;/gn 4.6 删除正文在命令模式下，同样可以删除正文中的内容。例如： 12345678:d 删除光标所在行:3d 删除 3 行:.,$d 删除当前行至正文的末尾:/str1/,/str2/d 删除从字符串 str1 到 str2 的所有行:g/^\\(.*\\)$\\n\\1$/d 删除连续相同的行，保留最后一行:g/\\%(^\\1$\\n\\)\\@&lt;=\\(.*\\)$/d 删除连续相同的行，保留最开始一行:g/^\\s*$\\n\\s*$/d 删除连续多个空行，只保留一行空行:5,20s/^#//g 删除5到20行开头的 # 注释 总之，Vim的初级删除命令是用 d ，高级删除命令可以用 正则替换 的方式执行。 4.7 恢复文件Vim 在编辑某个文件时，会另外生成一个临时文件，这个文件的名称通常以 . 开头，并以 .swp 结尾。Vim 在正常退出时，该文件被删除，若意外退出，而没有保存文件的最新修改内容，则可以使用恢复命令 :recover 来恢复文件，也可以在启动Vim时用 -r 选项。 4.8 选项设置为控制不同的编辑功能，Vim 提供了很多内部选项。利用 :set 命令可以设置选项。基本语法为： 1:set option 设置选项 option 常见的功能选项包括： 123456autoindent 设置该选项，则正文自动缩进ignorecase 设置该选项，则忽略规则表达式中大小写字母的区别number 设置该选项，则显示正文行号ruler 设置该选项，则在屏幕底部显示光标所在行、列的位置tabstop 设置按 Tab 键跳过的空格数。例如 :set tabstop=n，n 默认值为 8mk 将选项保存在当前目录的 .exrc 文件中 4.9 Shell切换当处于编辑的对话过程中时，可能需要执行一些Linux命令。如果需要保存当前的结果，退出编辑程序，再执行所需的Linux命令，然后再回头继续编辑过程，就显得十分累赘。如果能在编辑的环境中运行Linux命令就要省事得多。在Vim中，可以用下面的命令来做到这一点： 1:!shell_command 执行完 shell_command 后回到Vim 这称为Shell切换。它允许执行任何可以在标准的Shell提示符下执行的命令。当这条命令执行完毕，控制返回给编辑程序。又可以继续编辑对话过程。 4.10 分屏与标签页分屏普通的Vim模式，打开一个Vim程序只能查看一个文件，如果想同时查看多个文件，就需要用到Vim分屏与标签页功能。 Vim的分屏，主要有两种方式：上下分屏（水平分屏）和左右分屏（垂直分屏），在命令模式分别敲入以下命令即可： :sp 上下分屏,:vsp左右分屏 12:split（可用缩写 :sp） 上下分屏；:vsplit（可用缩写 :vsp） 左右分屏。 另外，也可以在终端里启动vim时就开启分屏操作： 12vim -On file1 file2... 打开 file1 和 file2 ，垂直分屏vim -on file1 file2... 打开 file1 和 file2 ，水平分屏 理论上，一个Vim窗口，可以分为多个Vim屏幕，切换屏幕需要用键盘快捷键，命令分别有： 1234Ctrl+w+h 切换到当前分屏的左边一屏；Ctrl+w+l 切换到当前分屏的右边一屏；Ctrl+w+j 切换到当前分屏的下方一屏；Ctrl+w+k 切换到当前分屏的上方一屏。 即键盘上的h,j,k,l 四个Vim专用方向键，配合Ctrl键和w键（window的缩写），就能跳转到目标分屏。另外，也可以直接按 Ctrl+w+w 来跳转分屏，不过跳转方向则是在当前Vim窗口所有分屏中，按照逆时针方向跳转。 下面是改变尺寸的一些操作，主要是高度，对于宽度你可以使用 [Ctrl+W &lt;] 或是 [Ctrl+W &gt;] ，但这可能需要最新的版本才支持。 123Ctrl+W = 让所有的屏都有一样的高度；Ctrl+W + 增加高度；Ctrl+W - 减少高度。 标签页Vim的标签（Tab）页，类似浏览器的标签页，一个标签页打开一个Vim的窗口，一个Vim的窗口可以支持N个分屏。 在Vim中新建一个标签的命令是： 1:tabnew 如果要在新建标签页的同时打开一个文件，则可以在命令后面直接附带文件路径： 1:tabnew filename Vim中的每个标签页有一个唯一的数字序号，第一个标签页的序号是0，从左向右依次加一。关于标签页有一系列操作命令，简介如下： 1234567891011121314:tN[ext] 跳转到上一个匹配的标签:tabN[ext] 跳到上一个标签页:tabc[lose] 关闭当前标签页:tabdo 为每个标签页执行命令:tabe[dit] 在新标签页里编辑文件:tabf[ind] 寻找 &apos;path&apos; 里的文件，在新标签页里编辑之:tabfir[st] 转到第一个标签页:tabl[ast] 转到最后一个标签页:tabm[ove] N 把标签页移到序号为N位置:tabnew [filename] 在新标签页里编辑文件:tabn[ext] 转到下一个标签页:tabo[nly] 关闭所有除了当前标签页以外的所有标签页:tabp[revious] 转到前一个标签页:tabr[ewind] 转到第一个标签页 4.11 与外部工具集成Vim可以与许多外部程序集成，功能十分强大，比如 diff , ctags , sort , xxd 等等，下面选取几个简单介绍一下。 diffLinux命令 diff 用来对比两个文件的内容，不过对比结果显示在终端里，可读性比较差。结合Vim，在终端里可以直接输入命令 vimdiff，后面跟两个文件名作为参数： 1vimdiff file1 file2 即可在Vim里分屏显示两个文件内容的对比结果，对文件内容差异部分进行高亮标记，还可以同步滚动两个文件内容，更可以实时修改文件内容，方便程度和用户体验大大提高。 1vimdiff a.txt b.txt 如果直接给 -d 选项是一样的 1vim -d a.txt b.txt 除了在终端里开启vimdiff 功能，也可以在打开Vim后，在Vim的命令模式输入相关命令来开启 vimdiff 功能： 1:diffsplit abc.txt 如果你现在已经开启了一个文件，想Vim帮你区分你的文件跟 abc.txt 有什么区别，可以在Vim中用 diffsplit 的方式打开第二个文件，这个时 候Vim会用 split（分上下两屏）的方式开启第二个文件，并且通过颜色，fold来显示两个文件的区别 这样Vim就会用颜色帮你区分开2个文件的区别。如果文件比较大（源码）重复的部分会帮你折叠起来。 1:diffpatch filename 通过 :diffpatch 你的patch的文件名，就可以以当前文件加上你的patch来显示。vim会split一个新的屏，显示patch后的信息并且用颜色标明区别。 如果不喜欢上下对比，喜欢左右（比较符合视觉）可以在前面加 vert ，例如： 12:vert diffsplit abc.txt:vert diffpatch abc.txt 看完diff，用 :only 回到原本编辑的文件，觉得diff的讨厌颜色还是在哪里，只要用 :diffoff 关闭就好了。 还有个常用的diff中的就是 :diffu ,这个是 :diffupdate 的简写，更新的时候用。 Vim的diff功能显示效果如下所示： sortLinux命令 sort 可以对文本内容进行按行中的字符比较、排序，但在终端里使用 sort 命令处理文件，并不能实时查看文件内容。具体用法请自查手册。 xxdvim+xxd 是Linux下最常用的二进制文本编辑工具，xxd其实是Vim外部的一个转换程序，随Vim一起发布，在Vim里调用它来编辑二进制文本非常方便。 首先以二进制模式在终端里打开一个文件： 1vim -b filename Vim 的 -b 选项是告诉 Vim 打开的是一个二进制文件，不指定的话，会在后面加上 0x0a ，即一个换行符。 然后在Vim的命令模式下键入： 1:%!xxd 即可看到二进制模式显示出来的文本，看起来像这样： 1230000000: 1f8b 0808 39d7 173b 0203 7474 002b 4e49 ....9..;..tt.+NI 0000010: 4b2c 8660 eb9c ecac c462 eb94 345e 2e30 K,......b..4^.0 0000020: 373b 2731 0b22 0ca6 c1a2 d669 1035 39d9 7;&apos;1.&quot;.....i.59 然后就可以在二进制模式下编辑该文件，编辑后保存，然后用下面命令从二进制模式转换到普通模式： 1:%!xxd -r 另外，也可以调整二进制的显示模式，默认是 2 个字节为一组，可以通过 g 参数调整每组字节数： 123:%!xxd -g 1 表示每1个字节为1组 :%!xxd -g 2 表示每2个字节为1组(默认) :%!xxd -g 4 表示每4个字节为1组 5. Vim配置最初安装的Vim功能、特性支持比较少，用起来比较费劲，想要稍微“好用”一点，需做一些初步的配置。Vim的配置主要分为Vim本身特性的配置和外部插件的配置两部分。 Vim的配置是通常是存放在用户主目录的 .vimrc 的隐藏文件中的。就Vim本身特性来说，基础的配置有编程语言语法高亮、缩进设置、行号显示、搜索高亮、TAB键设置、字体设置、Vim主题设置等等，稍微高级一些的有编程语言缩进、自动补全设置等，具体配置项可以自行查资料，全面详细的配置项介绍可以参考： 《Vim Options》： http://vimcdoc.sourceforge.net/doc/options.html#%27completeopt%27 6. Vim插件Vim“编辑器之神”的称号并不是浪得虚名，然而，这个荣誉的背后，或许近半的功劳要归功于强大的插件支持特性，以及社区开发的各种各样功能强大的插件。 平时开发人员常用插件主要是目录（文件）查看和管理、编程语言缩进与自动补全、编程语言Docs支持、函数跳转、项目管理等等，简单配置可以参考下面： 《Vim插件简单介绍》： http://blog.segmentfault.com/xuelang/1190000000630547 《手把手教你把Vim改装成一个IDE编程环境(图文)》： http://blog.csdn.net/wooin/article/details/1858917 《将Vim改造为强大的IDE》： http://www.cnblogs.com/zhangsf/archive/2013/06/13/3134409.html 当然，这些插件都是拜Vim本身的插件支持特性所赐。Vim为了支持丰富的第三方插件，自身定义了一套简单的脚本开发语言，供程序员自行开发自己所需要的插件，插件开发介绍可以参考： 《Writing Vim Plugins》： http://stevelosh.com/blog/2011/09/writing-vim-plugins/ 7. Vim完整文档 Vim官方文档：http://vimdoc.sourceforge.net/ Vim中文用户手册7_3.pdf ：http://pan.baidu.com/s/1jGzbTBo 文章来源 .","link":"/2019/08/23/Vim基本入门操作.html"},{"title":"redis分布式锁Redlock的实现","text":"普通实现 说道Redis分布式锁大部分人都会想到：setnx+lua，或者知道set key value px milliseconds nx。后一种方式的核心实现命令如下： 123456789- 获取锁（unique_value可以是UUID等）SET resource_name unique_value NX PX 30000- 释放锁（lua脚本中，一定要比较value，防止误解锁）if redis.call(\"get\",KEYS[1]) == ARGV[1] then return redis.call(\"del\",KEYS[1])else return 0end 这种实现方式有3大要点（也是面试概率非常高的地方）： set命令要用set key value px milliseconds nx； value要具有唯一性； 释放锁时要验证value值，不能误解锁； 事实上这类琐最大的缺点就是它加锁时只作用在一个Redis节点上，即使Redis通过sentinel保证高可用，如果这个master节点由于某些原因发生了主从切换，那么就会出现锁丢失的情况： 在Redis的master节点上拿到了锁； 但是这个加锁的key还没有同步到slave节点； master故障，发生故障转移，slave节点升级为master节点； 导致锁丢失。 正因为如此，Redis作者antirez基于分布式环境下提出了一种更高级的分布式锁的实现方式：Redlock。笔者认为，Redlock也是Redis所有分布式锁实现方式中唯一能让面试官高潮的方式。 Redlock实现antirez提出的redlock算法大概是这样的： 在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。 为了取到锁，客户端应该执行以下操作: 获取当前Unix时间，以毫秒为单位。 依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。 如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。 Redlock源码redisson已经有对redlock算法封装，接下来对其用法进行简单介绍，并对核心源码进行分析（假设5个redis实例）。 POM依赖 123456&lt;!-- https://mvnrepository.com/artifact/org.redisson/redisson --&gt;&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt;&lt;/dependency&gt; 用法首先，我们来看一下redission封装的redlock算法实现的分布式锁用法，非常简单，跟重入锁（ReentrantLock）有点类似： 1234567891011121314151617181920Config config = new Config();config.useSentinelServers().addSentinelAddress(\"127.0.0.1:6369\",\"127.0.0.1:6379\", \"127.0.0.1:6389\") .setMasterName(\"masterName\") .setPassword(\"password\").setDatabase(0);RedissonClient redissonClient = Redisson.create(config);// 还可以getFairLock(), getReadWriteLock()RLock redLock = redissonClient.getLock(\"REDLOCK_KEY\");boolean isLock;try { isLock = redLock.tryLock(); // 500ms拿不到锁, 就认为获取锁失败。10000ms即10s是锁失效时间。 isLock = redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS); if (isLock) { //TODO if get lock success, do something; }} catch (Exception e) {} finally { // 无论如何, 最后都要解锁 redLock.unlock();} 唯一ID实现分布式锁的一个非常重要的点就是set的value要具有唯一性，redisson的value是怎样保证value的唯一性呢？答案是UUID+threadId。入口在redissonClient.getLock(“REDLOCK_KEY”)，源码在Redisson.java和RedissonLock.java中： 1234protected final UUID id = UUID.randomUUID();String getLockName(long threadId) { return id + \":\" + threadId;} 获取锁获取锁的代码为redLock.tryLock()或者redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS)，两者的最终核心源码都是下面这段代码，只不过前者获取锁的默认租约时间（leaseTime）是LOCK_EXPIRATION_INTERVAL_SECONDS，即30s： 123456789101112131415161718192021&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) { internalLockLeaseTime = unit.toMillis(leaseTime); // 获取锁时向5个redis实例发送的命令 return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command, // 首先分布式锁的KEY不能存在，如果确实不存在，那么执行hset命令（hset REDLOCK_KEY uuid+threadId 1），并通过pexpire设置失效时间（也是锁的租约时间） \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('hset', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + // 如果分布式锁的KEY已经存在，并且value也匹配，表示是当前线程持有的锁，那么重入次数加1，并且设置失效时间 \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" + \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + // 获取分布式锁的KEY的失效时间毫秒数 \"return redis.call('pttl', KEYS[1]);\", // 这三个参数分别对应KEYS[1]，ARGV[1]和ARGV[2] Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));} 获取锁的命令中， KEYS[1]就是Collections.singletonList(getName())，表示分布式锁的key，即REDLOCK_KEY； ARGV[1]就是internalLockLeaseTime，即锁的租约时间，默认30s； ARGV[2]就是getLockName(threadId)，是获取锁时set的唯一值，即UUID+threadId： 释放锁释放锁的代码为redLock.unlock()，核心源码如下： 1234567891011121314151617181920212223242526272829protected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) { // 向5个redis实例都执行如下命令 return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, // 如果分布式锁KEY不存在，那么向channel发布一条消息 \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('publish', KEYS[2], ARGV[1]); \" + \"return 1; \" + \"end;\" + // 如果分布式锁存在，但是value不匹配，表示锁已经被占用，那么直接返回 \"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \" + \"return nil;\" + \"end; \" + // 如果就是当前线程占有分布式锁，那么将重入次数减1 \"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \" + // 重入次数减1后的值如果大于0，表示分布式锁有重入过，那么只设置失效时间，还不能删除 \"if (counter &gt; 0) then \" + \"redis.call('pexpire', KEYS[1], ARGV[2]); \" + \"return 0; \" + \"else \" + // 重入次数减1后的值如果为0，表示分布式锁只获取过1次，那么删除这个KEY，并发布解锁消息 \"redis.call('del', KEYS[1]); \" + \"redis.call('publish', KEYS[2], ARGV[1]); \" + \"return 1; \"+ \"end; \" + \"return nil;\", // 这5个参数分别对应KEYS[1]，KEYS[2]，ARGV[1]，ARGV[2]和ARGV[3] Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));} 文章来源 .","link":"/2019/08/22/redis分布式锁Redlock的实现.html"},{"title":"中华人民共和国刑事诉讼法","text":"基本信息 发文字号：中华人民共和国主席令第十号 效力级别法律：时效性现行有效 发布日期：2018-10-26 实施日期：2018-10-26 发布机关：全国人大常委会 法律修订 1979年7月1日第五届全国人民代表大会第二次会议通过 根据1996年3月17日第八届全国人民代表大会第四次会议《关于修改〈中华人民共和国刑事诉讼法〉的决定》第一次修正 根据2012年3月14日第十一届全国人民代表大会第五次会议《关于修改〈中华人民共和国刑事诉讼法〉的决定》第二次修正 根据2018年10月26日第十三届全国人民代表大会常务委员会第六次会议《关于修改〈中华人民共和国刑事诉讼法〉的决定》第三次修正 中华人民共和国刑事诉讼法（2012修正） 中华人民共和国刑事诉讼法（1996修正） 中华人民共和国刑事诉讼法（1979修正） 正文 第一编 总 则第一章 任务和基本原则第一条 为了保证刑法的正确实施，惩罚犯罪，保护人民，保障国家安全和社会公共安全，维护社会主义社会秩序，根据宪法，制定本法。 第二条 中华人民共和国刑事诉讼法的任务，是保证准确、及时地查明犯罪事实，正确应用法律，惩罚犯罪分子，保障无罪的人不受刑事追究，教育公民自觉遵守法律，积极同犯罪行为作斗争，维护社会主义法制，尊重和保障人权，保护公民的人身权利、财产权利、民主权利和其他权利，保障社会主义建设事业的顺利进行。 第三条 对刑事案件的侦查、拘留、执行逮捕、预审，由公安机关负责。检察、批准逮捕、检察机关直接受理的案件的侦查、提起公诉，由人民检察院负责。审判由人民法院负责。除法律特别规定的以外，其他任何机关、团体和个人都无权行使这些权力。 人民法院、人民检察院和公安机关进行刑事诉讼，必须严格遵守本法和其他法律的有关规定。 第四条 国家安全机关依照法律规定，办理危害国家安全的刑事案件，行使与公安机关相同的职权。 第五条 人民法院依照法律规定独立行使审判权，人民检察院依照法律规定独立行使检察权，不受行政机关、社会团体和个人的干涉。 第六条 人民法院、人民检察院和公安机关进行刑事诉讼，必须依靠群众，必须以事实为根据，以法律为准绳。对于一切公民，在适用法律上一律平等，在法律面前，不允许有任何特权。 第七条 人民法院、人民检察院和公安机关进行刑事诉讼，应当分工负责，互相配合，互相制约，以保证准确有效地执行法律。 第八条 人民检察院依法对刑事诉讼实行法律监督。 第九条 各民族公民都有用本民族语言文字进行诉讼的权利。人民法院、人民检察院和公安机关对于不通晓当地通用的语言文字的诉讼参与人，应当为他们翻译。 在少数民族聚居或者多民族杂居的地区，应当用当地通用的语言进行审讯，用当地通用的文字发布判决书、布告和其他文件。 第十条 人民法院审判案件，实行两审终审制。 第十一条 人民法院审判案件，除本法另有规定的以外，一律公开进行。被告人有权获得辩护，人民法院有义务保证被告人获得辩护。 第十二条 未经人民法院依法判决，对任何人都不得确定有罪。 第十三条 人民法院审判案件，依照本法实行人民陪审员陪审的制度。 第十四条 人民法院、人民检察院和公安机关应当保障犯罪嫌疑人、被告人和其他诉讼参与人依法享有的辩护权和其他诉讼权利。 诉讼参与人对于审判人员、检察人员和侦查人员侵犯公民诉讼权利和人身侮辱的行为，有权提出控告。 第十五条 犯罪嫌疑人、被告人自愿如实供述自己的罪行，承认指控的犯罪事实，愿意接受处罚的，可以依法从宽处理。 第十六条 有下列情形之一的，不追究刑事责任，已经追究的，应当撤销案件，或者不起诉，或者终止审理，或者宣告无罪： （一）情节显著轻微、危害不大，不认为是犯罪的； （二）犯罪已过追诉时效期限的； （三）经特赦令免除刑罚的； （四）依照刑法告诉才处理的犯罪，没有告诉或者撤回告诉的； （五）犯罪嫌疑人、被告人死亡的； （六）其他法律规定免予追究刑事责任的。 第十七条 对于外国人犯罪应当追究刑事责任的，适用本法的规定。 对于享有外交特权和豁免权的外国人犯罪应当追究刑事责任的，通过外交途径解决。 第十八条 根据中华人民共和国缔结或者参加的国际条约，或者按照互惠原则，我国司法机关和外国司法机关可以相互请求刑事司法协助。 第二章 管 辖第十九条 刑事案件的侦查由公安机关进行，法律另有规定的除外。 人民检察院在对诉讼活动实行法律监督中发现的司法工作人员利用职权实施的非法拘禁、刑讯逼供、非法搜查等侵犯公民权利、损害司法公正的犯罪，可以由人民检察院立案侦查。对于公安机关管辖的国家机关工作人员利用职权实施的重大犯罪案件，需要由人民检察院直接受理的时候，经省级以上人民检察院决定，可以由人民检察院立案侦查。 自诉案件，由人民法院直接受理。 第二十条 基层人民法院管辖第一审普通刑事案件，但是依照本法由上级人民法院管辖的除外。 第二十一条 中级人民法院管辖下列第一审刑事案件： （一）危害国家安全、恐怖活动案件； （二）可能判处无期徒刑、死刑的案件。 第二十二条 高级人民法院管辖的第一审刑事案件，是全省（自治区、直辖市）性的重大刑事案件。 第二十三条 最高人民法院管辖的第一审刑事案件，是全国性的重大刑事案件。 第二十四条 上级人民法院在必要的时候，可以审判下级人民法院管辖的第一审刑事案件；下级人民法院认为案情重大、复杂需要由上级人民法院审判的第一审刑事案件，可以请求移送上一级人民法院审判。 第二十五条 刑事案件由犯罪地的人民法院管辖。如果由被告人居住地的人民法院审判更为适宜的，可以由被告人居住地的人民法院管辖。 第二十六条 几个同级人民法院都有权管辖的案件，由最初受理的人民法院审判。在必要的时候，可以移送主要犯罪地的人民法院审判。 第二十七条 上级人民法院可以指定下级人民法院审判管辖不明的案件，也可以指定下级人民法院将案件移送其他人民法院审判。 第二十八条 专门人民法院案件的管辖另行规定。 第三章 回 避第二十九条 审判人员、检察人员、侦查人员有下列情形之一的，应当自行回避，当事人及其法定代理人也有权要求他们回避： （一）是本案的当事人或者是当事人的近亲属的； （二）本人或者他的近亲属和本案有利害关系的； （三）担任过本案的证人、鉴定人、辩护人、诉讼代理人的； （四）与本案当事人有其他关系，可能影响公正处理案件的。 第三十条 审判人员、检察人员、侦查人员不得接受当事人及其委托的人的请客送礼，不得违反规定会见当事人及其委托的人。 审判人员、检察人员、侦查人员违反前款规定的，应当依法追究法律责任。当事人及其法定代理人有权要求他们回避。 第三十一条 审判人员、检察人员、侦查人员的回避，应当分别由院长、检察长、公安机关负责人决定；院长的回避，由本院审判委员会决定；检察长和公安机关负责人的回避，由同级人民检察院检察委员会决定。 对侦查人员的回避作出决定前，侦查人员不能停止对案件的侦查。 对驳回申请回避的决定，当事人及其法定代理人可以申请复议一次。 第三十二条 本章关于回避的规定适用于书记员、翻译人员和鉴定人。 辩护人、诉讼代理人可以依照本章的规定要求回避、申请复议。 第四章 辩护与代理第三十三条 犯罪嫌疑人、被告人除自己行使辩护权以外，还可以委托一至二人作为辩护人。下列的人可以被委托为辩护人： （一）律师； （二）人民团体或者犯罪嫌疑人、被告人所在单位推荐的人； （三）犯罪嫌疑人、被告人的监护人、亲友。 正在被执行刑罚或者依法被剥夺、限制人身自由的人，不得担任辩护人。 被开除公职和被吊销律师、公证员执业证书的人，不得担任辩护人，但系犯罪嫌疑人、被告人的监护人、近亲属的除外。 第三十四条 犯罪嫌疑人自被侦查机关第一次讯问或者采取强制措施之日起，有权委托辩护人；在侦查期间，只能委托律师作为辩护人。被告人有权随时委托辩护人。 侦查机关在第一次讯问犯罪嫌疑人或者对犯罪嫌疑人采取强制措施的时候，应当告知犯罪嫌疑人有权委托辩护人。人民检察院自收到移送审查起诉的案件材料之日起三日以内，应当告知犯罪嫌疑人有权委托辩护人。人民法院自受理案件之日起三日以内，应当告知被告人有权委托辩护人。犯罪嫌疑人、被告人在押期间要求委托辩护人的，人民法院、人民检察院和公安机关应当及时转达其要求。 犯罪嫌疑人、被告人在押的，也可以由其监护人、近亲属代为委托辩护人。 辩护人接受犯罪嫌疑人、被告人委托后，应当及时告知办理案件的机关。 第三十五条 犯罪嫌疑人、被告人因经济困难或者其他原因没有委托辩护人的，本人及其近亲属可以向法律援助机构提出申请。对符合法律援助条件的，法律援助机构应当指派律师为其提供辩护。 犯罪嫌疑人、被告人是盲、聋、哑人，或者是尚未完全丧失辨认或者控制自己行为能力的精神病人，没有委托辩护人的，人民法院、人民检察院和公安机关应当通知法律援助机构指派律师为其提供辩护。 犯罪嫌疑人、被告人可能被判处无期徒刑、死刑，没有委托辩护人的，人民法院、人民检察院和公安机关应当通知法律援助机构指派律师为其提供辩护。 第三十六条 法律援助机构可以在人民法院、看守所等场所派驻值班律师。犯罪嫌疑人、被告人没有委托辩护人，法律援助机构没有指派律师为其提供辩护的，由值班律师为犯罪嫌疑人、被告人提供法律咨询、程序选择建议、申请变更强制措施、对案件处理提出意见等法律帮助。 人民法院、人民检察院、看守所应当告知犯罪嫌疑人、被告人有权约见值班律师，并为犯罪嫌疑人、被告人约见值班律师提供便利。 第三十七条 辩护人的责任是根据事实和法律，提出犯罪嫌疑人、被告人无罪、罪轻或者减轻、免除其刑事责任的材料和意见，维护犯罪嫌疑人、被告人的诉讼权利和其他合法权益。 第三十八条 辩护律师在侦查期间可以为犯罪嫌疑人提供法律帮助；代理申诉、控告；申请变更强制措施；向侦查机关了解犯罪嫌疑人涉嫌的罪名和案件有关情况，提出意见。 第三十九条 辩护律师可以同在押的犯罪嫌疑人、被告人会见和通信。其他辩护人经人民法院、人民检察院许可，也可以同在押的犯罪嫌疑人、被告人会见和通信。 辩护律师持律师执业证书、律师事务所证明和委托书或者法律援助公函要求会见在押的犯罪嫌疑人、被告人的，看守所应当及时安排会见，至迟不得超过四十八小时。 危害国家安全犯罪、恐怖活动犯罪案件，在侦查期间辩护律师会见在押的犯罪嫌疑人，应当经侦查机关许可。上述案件，侦查机关应当事先通知看守所。 辩护律师会见在押的犯罪嫌疑人、被告人，可以了解案件有关情况，提供法律咨询等；自案件移送审查起诉之日起，可以向犯罪嫌疑人、被告人核实有关证据。辩护律师会见犯罪嫌疑人、被告人时不被监听。 辩护律师同被监视居住的犯罪嫌疑人、被告人会见、通信，适用第一款、第三款、第四款的规定。 第四十条 辩护律师自人民检察院对案件审查起诉之日起，可以查阅、摘抄、复制本案的案卷材料。其他辩护人经人民法院、人民检察院许可，也可以查阅、摘抄、复制上述材料。 第四十一条 辩护人认为在侦查、审查起诉期间公安机关、人民检察院收集的证明犯罪嫌疑人、被告人无罪或者罪轻的证据材料未提交的，有权申请人民检察院、人民法院调取。 第四十二条 辩护人收集的有关犯罪嫌疑人不在犯罪现场、未达到刑事责任年龄、属于依法不负刑事责任的精神病人的证据，应当及时告知公安机关、人民检察院。 第四十三条 辩护律师经证人或者其他有关单位和个人同意，可以向他们收集与本案有关的材料，也可以申请人民检察院、人民法院收集、调取证据，或者申请人民法院通知证人出庭作证。 辩护律师经人民检察院或者人民法院许可，并且经被害人或者其近亲属、被害人提供的证人同意，可以向他们收集与本案有关的材料。 第四十四条 辩护人或者其他任何人，不得帮助犯罪嫌疑人、被告人隐匿、毁灭、伪造证据或者串供，不得威胁、引诱证人作伪证以及进行其他干扰司法机关诉讼活动的行为。 违反前款规定的，应当依法追究法律责任，辩护人涉嫌犯罪的，应当由办理辩护人所承办案件的侦查机关以外的侦查机关办理。辩护人是律师的，应当及时通知其所在的律师事务所或者所属的律师协会。 第四十五条 在审判过程中，被告人可以拒绝辩护人继续为他辩护，也可以另行委托辩护人辩护。 第四十六条 公诉案件的被害人及其法定代理人或者近亲属，附带民事诉讼的当事人及其法定代理人，自案件移送审查起诉之日起，有权委托诉讼代理人。自诉案件的自诉人及其法定代理人，附带民事诉讼的当事人及其法定代理人，有权随时委托诉讼代理人。 人民检察院自收到移送审查起诉的案件材料之日起三日以内，应当告知被害人及其法定代理人或者其近亲属、附带民事诉讼的当事人及其法定代理人有权委托诉讼代理人。人民法院自受理自诉案件之日起三日以内，应当告知自诉人及其法定代理人、附带民事诉讼的当事人及其法定代理人有权委托诉讼代理人。 第四十七条 委托诉讼代理人，参照本法第三十三条的规定执行。 第四十八条 辩护律师对在执业活动中知悉的委托人的有关情况和信息，有权予以保密。但是，辩护律师在执业活动中知悉委托人或者其他人，准备或者正在实施危害国家安全、公共安全以及严重危害他人人身安全的犯罪的，应当及时告知司法机关。 第四十九条 辩护人、诉讼代理人认为公安机关、人民检察院、人民法院及其工作人员阻碍其依法行使诉讼权利的，有权向同级或者上一级人民检察院申诉或者控告。人民检察院对申诉或者控告应当及时进行审查，情况属实的，通知有关机关予以纠正。 第五章 证 据第五十条 可以用于证明案件事实的材料，都是证据。 证据包括： （一）物证； （二）书证； （三）证人证言； （四）被害人陈述； （五）犯罪嫌疑人、被告人供述和辩解； （六）鉴定意见； （七）勘验、检查、辨认、侦查实验等笔录； （八）视听资料、电子数据。 证据必须经过查证属实，才能作为定案的根据。 第五十一条 公诉案件中被告人有罪的举证责任由人民检察院承担，自诉案件中被告人有罪的举证责任由自诉人承担。 第五十二条 审判人员、检察人员、侦查人员必须依照法定程序，收集能够证实犯罪嫌疑人、被告人有罪或者无罪、犯罪情节轻重的各种证据。严禁刑讯逼供和以威胁、引诱、欺骗以及其他非法方法收集证据，不得强迫任何人证实自己有罪。必须保证一切与案件有关或者了解案情的公民，有客观地充分地提供证据的条件，除特殊情况外，可以吸收他们协助调查。 第五十三条 公安机关提请批准逮捕书、人民检察院起诉书、人民法院判决书，必须忠实于事实真象。故意隐瞒事实真象的，应当追究责任。 第五十四条 人民法院、人民检察院和公安机关有权向有关单位和个人收集、调取证据。有关单位和个人应当如实提供证据。 行政机关在行政执法和查办案件过程中收集的物证、书证、视听资料、电子数据等证据材料，在刑事诉讼中可以作为证据使用。 对涉及国家秘密、商业秘密、个人隐私的证据，应当保密。 凡是伪造证据、隐匿证据或者毁灭证据的，无论属于何方，必须受法律追究。 第五十五条 对一切案件的判处都要重证据，重调查研究，不轻信口供。只有被告人供述，没有其他证据的，不能认定被告人有罪和处以刑罚；没有被告人供述，证据确实、充分的，可以认定被告人有罪和处以刑罚。 证据确实、充分，应当符合以下条件： （一）定罪量刑的事实都有证据证明； （二）据以定案的证据均经法定程序查证属实； （三）综合全案证据，对所认定事实已排除合理怀疑。 第五十六条 采用刑讯逼供等非法方法收集的犯罪嫌疑人、被告人供述和采用暴力、威胁等非法方法收集的证人证言、被害人陈述，应当予以排除。收集物证、书证不符合法定程序，可能严重影响司法公正的，应当予以补正或者作出合理解释；不能补正或者作出合理解释的，对该证据应当予以排除。 在侦查、审查起诉、审判时发现有应当排除的证据的，应当依法予以排除，不得作为起诉意见、起诉决定和判决的依据。 第五十七条 人民检察院接到报案、控告、举报或者发现侦查人员以非法方法收集证据的，应当进行调查核实。对于确有以非法方法收集证据情形的，应当提出纠正意见；构成犯罪的，依法追究刑事责任。 第五十八条 法庭审理过程中，审判人员认为可能存在本法第五十六条规定的以非法方法收集证据情形的，应当对证据收集的合法性进行法庭调查。 当事人及其辩护人、诉讼代理人有权申请人民法院对以非法方法收集的证据依法予以排除。申请排除以非法方法收集的证据的，应当提供相关线索或者材料。 第五十九条 在对证据收集的合法性进行法庭调查的过程中，人民检察院应当对证据收集的合法性加以证明。 现有证据材料不能证明证据收集的合法性的，人民检察院可以提请人民法院通知有关侦查人员或者其他人员出庭说明情况；人民法院可以通知有关侦查人员或者其他人员出庭说明情况。有关侦查人员或者其他人员也可以要求出庭说明情况。经人民法院通知，有关人员应当出庭。 第六十条 对于经过法庭审理，确认或者不能排除存在本法第五十六条规定的以非法方法收集证据情形的，对有关证据应当予以排除。 第六十一条 证人证言必须在法庭上经过公诉人、被害人和被告人、辩护人双方质证并且查实以后，才能作为定案的根据。法庭查明证人有意作伪证或者隐匿罪证的时候，应当依法处理。 第六十二条 凡是知道案件情况的人，都有作证的义务。 生理上、精神上有缺陷或者年幼，不能辨别是非、不能正确表达的人，不能作证人。 第六十三条 人民法院、人民检察院和公安机关应当保障证人及其近亲属的安全。 对证人及其近亲属进行威胁、侮辱、殴打或者打击报复，构成犯罪的，依法追究刑事责任；尚不够刑事处罚的，依法给予治安管理处罚。 第六十四条 对于危害国家安全犯罪、恐怖活动犯罪、黑社会性质的组织犯罪、毒品犯罪等案件，证人、鉴定人、被害人因在诉讼中作证，本人或者其近亲属的人身安全面临危险的，人民法院、人民检察院和公安机关应当采取以下一项或者多项保护措施： （一）不公开真实姓名、住址和工作单位等个人信息； （二）采取不暴露外貌、真实声音等出庭作证措施； （三）禁止特定的人员接触证人、鉴定人、被害人及其近亲属； （四）对人身和住宅采取专门性保护措施； （五）其他必要的保护措施。 证人、鉴定人、被害人认为因在诉讼中作证，本人或者其近亲属的人身安全面临危险的，可以向人民法院、人民检察院、公安机关请求予以保护。 人民法院、人民检察院、公安机关依法采取保护措施，有关单位和个人应当配合。 第六十五条 证人因履行作证义务而支出的交通、住宿、就餐等费用，应当给予补助。证人作证的补助列入司法机关业务经费，由同级政府财政予以保障。 有工作单位的证人作证，所在单位不得克扣或者变相克扣其工资、奖金及其他福利待遇。 第六章 强制措施第六十六条 人民法院、人民检察院和公安机关根据案件情况，对犯罪嫌疑人、被告人可以拘传、取保候审或者监视居住。 第六十七条 人民法院、人民检察院和公安机关对有下列情形之一的犯罪嫌疑人、被告人，可以取保候审： （一）可能判处管制、拘役或者独立适用附加刑的； （二）可能判处有期徒刑以上刑罚，采取取保候审不致发生社会危险性的； （三）患有严重疾病、生活不能自理，怀孕或者正在哺乳自己婴儿的妇女，采取取保候审不致发生社会危险性的； （四）羁押期限届满，案件尚未办结，需要采取取保候审的。 取保候审由公安机关执行。 第六十八条 人民法院、人民检察院和公安机关决定对犯罪嫌疑人、被告人取保候审，应当责令犯罪嫌疑人、被告人提出保证人或者交纳保证金。 第六十九条 保证人必须符合下列条件： （一）与本案无牵连； （二）有能力履行保证义务； （三）享有政治权利，人身自由未受到限制； （四）有固定的住处和收入。 第七十条 保证人应当履行以下义务： （一）监督被保证人遵守本法第七十一条的规定； （二）发现被保证人可能发生或者已经发生违反本法第七十一条规定的行为的，应当及时向执行机关报告。 被保证人有违反本法第七十一条规定的行为，保证人未履行保证义务的，对保证人处以罚款，构成犯罪的，依法追究刑事责任。 第七十一条 被取保候审的犯罪嫌疑人、被告人应当遵守以下规定： （一）未经执行机关批准不得离开所居住的市、县； （二）住址、工作单位和联系方式发生变动的，在二十四小时以内向执行机关报告； （三）在传讯的时候及时到案； （四）不得以任何形式干扰证人作证； （五）不得毁灭、伪造证据或者串供。 人民法院、人民检察院和公安机关可以根据案件情况，责令被取保候审的犯嫌疑人、被告人遵守以下一项或者多项规定： （一）不得进入特定的场所； （二）不得与特定的人员会见或者通信； （三）不得从事特定的活动； （四）将护照等出入境证件、驾驶证件交执行机关保存。 被取保候审的犯罪嫌疑人、被告人违反前两款规定，已交纳保证金的，没收部分或者全部保证金，并且区别情形，责令犯罪嫌疑人、被告人具结悔过，重新交纳保证金、提出保证人，或者监视居住、予以逮捕。 对违反取保候审规定，需要予以逮捕的，可以对犯罪嫌疑人、被告人先行拘留。 第七十二条 取保候审的决定机关应当综合考虑保证诉讼活动正常进行的需要，被取保候审人的社会危险性，案件的性质、情节，可能判处刑罚的轻重，被取保候审人的经济状况等情况，确定保证金的数额。 提供保证金的人应当将保证金存入执行机关指定银行的专门账户。 第七十三条 犯罪嫌疑人、被告人在取保候审期间未违反本法第七十一条规定的，取保候审结束的时候，凭解除取保候审的通知或者有关法律文书到银行领取退还的保证金。 第七十四条 人民法院、人民检察院和公安机关对符合逮捕条件，有下列情形之一的犯罪嫌疑人、被告人，可以监视居住： （一）患有严重疾病、生活不能自理的； （二）怀孕或者正在哺乳自己婴儿的妇女； （三）系生活不能自理的人的唯一扶养人； （四）因为案件的特殊情况或者办理案件的需要，采取监视居住措施更为适宜的； （五）羁押期限届满，案件尚未办结，需要采取监视居住措施的。 对符合取保候审条件，但犯罪嫌疑人、被告人不能提出保证人，也不交纳保证金的，可以监视居住。 监视居住由公安机关执行。 第七十五条 监视居住应当在犯罪嫌疑人、被告人的住处执行；无固定住处的，可以在指定的居所执行。对于涉嫌危害国家安全犯罪、恐怖活动犯罪，在住处执行可能有碍侦查的，经上一级公安机关批准，也可以在指定的居所执行。但是，不得在羁押场所、专门的办案场所执行。 指定居所监视居住的，除无法通知的以外，应当在执行监视居住后二十四小时以内，通知被监视居住人的家属。 被监视居住的犯罪嫌疑人、被告人委托辩护人，适用本法第三十四条的规定。 人民检察院对指定居所监视居住的决定和执行是否合法实行监督。 第七十六条 指定居所监视居住的期限应当折抵刑期。被判处管制的，监视居住一日折抵刑期一日；被判处拘役、有期徒刑的，监视居住二日折抵刑期一日。 第七十七条 被监视居住的犯罪嫌疑人、被告人应当遵守以下规定： （一）未经执行机关批准不得离开执行监视居住的处所； （二）未经执行机关批准不得会见他人或者通信； （三）在传讯的时候及时到案； （四）不得以任何形式干扰证人作证； （五）不得毁灭、伪造证据或者串供； （六）将护照等出入境证件、身份证件、驾驶证件交执行机关保存。 被监视居住的犯罪嫌疑人、被告人违反前款规定，情节严重的，可以予以逮捕；需要予以逮捕的，可以对犯罪嫌疑人、被告人先行拘留。 第七十八条 执行机关对被监视居住的犯罪嫌疑人、被告人，可以采取电子监控、不定期检查等监视方法对其遵守监视居住规定的情况进行监督；在侦查期间，可以对被监视居住的犯罪嫌疑人的通信进行监控。 第七十九条 人民法院、人民检察院和公安机关对犯罪嫌疑人、被告人取保候审最长不得超过十二个月，监视居住最长不得超过六个月。 在取保候审、监视居住期间，不得中断对案件的侦查、起诉和审理。对于发现不应当追究刑事责任或者取保候审、监视居住期限届满的，应当及时解除取保候审、监视居住。解除取保候审、监视居住，应当及时通知被取保候审、监视居住人和有关单位。 第八十条 逮捕犯罪嫌疑人、被告人，必须经过人民检察院批准或者人民法院决定，由公安机关执行。 第八十一条 对有证据证明有犯罪事实，可能判处徒刑以上刑罚的犯罪嫌疑人、被告人，采取取保候审尚不足以防止发生下列社会危险性的，应当予以逮捕： （一）可能实施新的犯罪的； （二）有危害国家安全、公共安全或者社会秩序的现实危险的； （三）可能毁灭、伪造证据，干扰证人作证或者串供的； （四）可能对被害人、举报人、控告人实施打击报复的； （五）企图自杀或者逃跑的。 批准或者决定逮捕，应当将犯罪嫌疑人、被告人涉嫌犯罪的性质、情节，认罪认罚等情况，作为是否可能发生社会危险性的考虑因素。 对有证据证明有犯罪事实，可能判处十年有期徒刑以上刑罚的，或者有证据证明有犯罪事实，可能判处徒刑以上刑罚，曾经故意犯罪或者身份不明的，应当予以逮捕。 被取保候审、监视居住的犯罪嫌疑人、被告人违反取保候审、监视居住规定，情节严重的，可以予以逮捕。 第八十二条 公安机关对于现行犯或者重大嫌疑分子，如果有下列情形之一的，可以先行拘留： （一）正在预备犯罪、实行犯罪或者在犯罪后即时被发觉的； （二）被害人或者在场亲眼看见的人指认他犯罪的； （三）在身边或者住处发现有犯罪证据的； （四）犯罪后企图自杀、逃跑或者在逃的； （五）有毁灭、伪造证据或者串供可能的； （六）不讲真实姓名、住址，身份不明的； （七）有流窜作案、多次作案、结伙作案重大嫌疑的。 第八十三条 公安机关在异地执行拘留、逮捕的时候，应当通知被拘留、逮捕人所在地的公安机关，被拘留、逮捕人所在地的公安机关应当予以配合。 第八十四条 对于有下列情形的人，任何公民都可以立即扭送公安机关、人民检察院或者人民法院处理： （一）正在实行犯罪或者在犯罪后即时被发觉的； （二）通缉在案的； （三）越狱逃跑的； （四）正在被追捕的。 第八十五条 公安机关拘留人的时候，必须出示拘留证。 拘留后，应当立即将被拘留人送看守所羁押，至迟不得超过二十四小时。除无法通知或者涉嫌危害国家安全犯罪、恐怖活动犯罪通知可能有碍侦查的情形以外，应当在拘留后二十四小时以内，通知被拘留人的家属。有碍侦查的情形消失以后，应当立即通知被拘留人的家属。 第八十六条 公安机关对被拘留的人，应当在拘留后的二十四小时以内进行讯问。在发现不应当拘留的时候，必须立即释放，发给释放证明。 第八十七条 公安机关要求逮捕犯罪嫌疑人的时候，应当写出提请批准逮捕书，连同案卷材料、证据，一并移送同级人民检察院审查批准。必要的时候，人民检察院可以派人参加公安机关对于重大案件的讨论。 第八十八条 人民检察院审查批准逮捕，可以讯问犯罪嫌疑人；有下列情形之一的，应当讯问犯罪嫌疑人： （一）对是否符合逮捕条件有疑问的； （二）犯罪嫌疑人要求向检察人员当面陈述的； （三）侦查活动可能有重大违法行为的。 人民检察院审查批准逮捕，可以询问证人等诉讼参与人，听取辩护律师的意见；辩护律师提出要求的，应当听取辩护律师的意见。 第八十九条 人民检察院审查批准逮捕犯罪嫌疑人由检察长决定。重大案件应当提交检察委员会讨论决定。 第九十条 人民检察院对于公安机关提请批准逮捕的案件进行审查后，应当根据情况分别作出批准逮捕或者不批准逮捕的决定。对于批准逮捕的决定，公安机关应当立即执行，并且将执行情况及时通知人民检察院。对于不批准逮捕的，人民检察院应当说明理由，需要补充侦查的，应当同时通知公安机关。 第九十一条 公安机关对被拘留的人，认为需要逮捕的，应当在拘留后的三日以内，提请人民检察院审查批准。在特殊情况下，提请审查批准的时间可以延长一日至四日。 对于流窜作案、多次作案、结伙作案的重大嫌疑分子，提请审查批准的时间可以延长至三十日。 人民检察院应当自接到公安机关提请批准逮捕书后的七日以内，作出批准逮捕或者不批准逮捕的决定。人民检察院不批准逮捕的，公安机关应当在接到通知后立即释放，并且将执行情况及时通知人民检察院。对于需要继续侦查，并且符合取保候审、监视居住条件的，依法取保候审或者监视居住。 第九十二条 公安机关对人民检察院不批准逮捕的决定，认为有错误的时候，可以要求复议，但是必须将被拘留的人立即释放。如果意见不被接受，可以向上一级人民检察院提请复核。上级人民检察院应当立即复核，作出是否变更的决定，通知下级人民检察院和公安机关执行。 第九十三条 公安机关逮捕人的时候，必须出示逮捕证。 逮捕后，应当立即将被逮捕人送看守所羁押。除无法通知的以外，应当在逮捕后二十四小时以内，通知被逮捕人的家属。 第九十四条 人民法院、人民检察院对于各自决定逮捕的人，公安机关对于经人民检察院批准逮捕的人，都必须在逮捕后的二十四小时以内进行讯问。在发现不应当逮捕的时候，必须立即释放，发给释放证明。 第九十五条 犯罪嫌疑人、被告人被逮捕后，人民检察院仍应当对羁押的必要性进行审查。对不需要继续羁押的，应当建议予以释放或者变更强制措施。有关机关应当在十日以内将处理情况通知人民检察院。 第九十六条 人民法院、人民检察院和公安机关如果发现对犯罪嫌疑人、被告人采取强制措施不当的，应当及时撤销或者变更。公安机关释放被逮捕的人或者变更逮捕措施的，应当通知原批准的人民检察院。 第九十七条 犯罪嫌疑人、被告人及其法定代理人、近亲属或者辩护人有权申请变更强制措施。人民法院、人民检察院和公安机关收到申请后，应当在三日以内作出决定；不同意变更强制措施的，应当告知申请人，并说明不同意的理由。 第九十八条 犯罪嫌疑人、被告人被羁押的案件，不能在本法规定的侦查羁押、审查起诉、一审、二审期限内办结的，对犯罪嫌疑人、被告人应当予以释放；需要继续查证、审理的，对犯罪嫌疑人、被告人可以取保候审或者监视居住。 第九十九条 人民法院、人民检察院或者公安机关对被采取强制措施法定期限届满的犯罪嫌疑人、被告人，应当予以释放、解除取保候审、监视居住或者依法变更强制措施。犯罪嫌疑人、被告人及其法定代理人、近亲属或者辩护人对于人民法院、人民检察院或者公安机关采取强制措施法定期限届满的，有权要求解除强制措施。 第一百条 人民检察院在审查批准逮捕工作中，如果发现公安机关的侦查活动有违法情况，应当通知公安机关予以纠正，公安机关应当将纠正情况通知人民检察院。 第七章 附带民事诉讼第一百零一条 被害人由于被告人的犯罪行为而遭受物质损失的，在刑事诉讼过程中，有权提起附带民事诉讼。被害人死亡或者丧失行为能力的，被害人的法定代理人、近亲属有权提起附带民事诉讼。 如果是国家财产、集体财产遭受损失的，人民检察院在提起公诉的时候，可以提起附带民事诉讼。 第一百零二条 人民法院在必要的时候，可以采取保全措施，查封、扣押或者冻结被告人的财产。附带民事诉讼原告人或者人民检察院可以申请人民法院采取保全措施。人民法院采取保全措施，适用民事诉讼法的有关规定。 第一百零三条 人民法院审理附带民事诉讼案件，可以进行调解，或者根据物质损失情况作出判决、裁定。 第一百零四条 附带民事诉讼应当同刑事案件一并审判，只有为了防止刑事案件审判的过分迟延，才可以在刑事案件审判后，由同一审判组织继续审理附带民事诉讼。 第八章 期间、送达第一百零五条 期间以时、日、月计算。 期间开始的时和日不算在期间以内。 法定期间不包括路途上的时间。上诉状或者其他文件在期满前已经交邮的，不算过期。 期间的最后一日为节假日的，以节假日后的第一日为期满日期，但犯罪嫌疑人、被告人或者罪犯在押期间，应当至期满之日为止，不得因节假日而延长。 第一百零六条 当事人由于不能抗拒的原因或者有其他正当理由而耽误期限的，在障碍消除后五日以内，可以申请继续进行应当在期满以前完成的诉讼活动。 前款申请是否准许，由人民法院裁定。 第一百零七条 送达传票、通知书和其他诉讼文件应当交给收件人本人；如果本人不在，可以交给他的成年家属或者所在单位的负责人员代收。 收件人本人或者代收人拒绝接收或者拒绝签名、盖章的时候，送达人可以邀请他的邻居或者其他见证人到场，说明情况，把文件留在他的住处，在送达证上记明拒绝的事由、送达的日期，由送达人签名，即认为已经送达。 第九章 其他规定第一百零八条 本法下列用语的含意是： （一）“侦查”是指公安机关、人民检察院对于刑事案件，依照法律进行的收集证据、查明案情的工作和有关的强制性措施； （二）“当事人”是指被害人、自诉人、犯罪嫌疑人、被告人、附带民事诉讼的原告人和被告人； （三）“法定代理人”是指被代理人的父母、养父母、监护人和负有保护责任的机关、团体的代表； （四）“诉讼参与人”是指当事人、法定代理人、诉讼代理人、辩护人、证人、鉴定人和翻译人员； （五）“诉讼代理人”是指公诉案件的被害人及其法定代理人或者近亲属、自诉案件的自诉人及其法定代理人委托代为参加诉讼的人和附带民事诉讼的当事人及其法定代理人委托代为参加诉讼的人； （六）“近亲属”是指夫、妻、父、母、子、女、同胞兄弟姊妹。 第二编 立案、侦查和提起公诉第一章 立案第一百零九条 公安机关或者人民检察院发现犯罪事实或者犯罪嫌疑人，应当按照管辖范围，立案侦查。 第一百一十条 任何单位和个人发现有犯罪事实或者犯罪嫌疑人，有权利也有义务向公安机关、人民检察院或者人民法院报案或者举报。 被害人对侵犯其人身、财产权利的犯罪事实或者犯罪嫌疑人，有权向公安机关、人民检察院或者人民法院报案或者控告。 公安机关、人民检察院或者人民法院对于报案、控告、举报，都应当接受。对于不属于自己管辖的，应当移送主管机关处理，并且通知报案人、控告人、举报人；对于不属于自己管辖而又必须采取紧急措施的，应当先采取紧急措施，然后移送主管机关。 犯罪人向公安机关、人民检察院或者人民法院自首的，适用第三款规定。 第一百一十一条 报案、控告、举报可以用书面或者口头提出。接受口头报案、控告、举报的工作人员，应当写成笔录，经宣读无误后，由报案人、控告人、举报人签名或者盖章。 接受控告、举报的工作人员，应当向控告人、举报人说明诬告应负的法律责任。但是，只要不是捏造事实，伪造证据，即使控告、举报的事实有出入，甚至是错告的，也要和诬告严格加以区别。 公安机关、人民检察院或者人民法院应当保障报案人、控告人、举报人及其近亲属的安全。报案人、控告人、举报人如果不愿公开自己的姓名和报案、控告、举报的行为，应当为他保守秘密。 第一百一十二条 人民法院、人民检察院或者公安机关对于报案、控告、举报和自首的材料，应当按照管辖范围，迅速进行审查，认为有犯罪事实需要追究刑事责任的时候，应当立案；认为没有犯罪事实，或者犯罪事实显著轻微，不需要追究刑事责任的时候，不予立案，并且将不立案的原因通知控告人。控告人如果不服，可以申请复议。 第一百一十三条 人民检察院认为公安机关对应当立案侦查的案件而不立案侦查的，或者被害人认为公安机关对应当立案侦查的案件而不立案侦查，向人民检察院提出的，人民检察院应当要求公安机关说明不立案的理由。人民检察院认为公安机关不立案理由不能成立的，应当通知公安机关立案，公安机关接到通知后应当立案。 第一百一十四条 对于自诉案件，被害人有权向人民法院直接起诉。被害人死亡或者丧失行为能力的，被害人的法定代理人、近亲属有权向人民法院起诉。人民法院应当依法受理。 第二章 侦查第一百一十五条 公安机关对已经立案的刑事案件，应当进行侦查，收集、调取犯罪嫌疑人有罪或者无罪、罪轻或者罪重的证据材料。对现行犯或者重大嫌疑分子可以依法先行拘留，对符合逮捕条件的犯罪嫌疑人，应当依法逮捕。 第一百一十六条 公安机关经过侦查，对有证据证明有犯罪事实的案件，应当进行预审，对收集、调取的证据材料予以核实。 第一百一十七条 当事人和辩护人、诉讼代理人、利害关系人对于司法机关及其工作人员有下列行为之一的，有权向该机关申诉或者控告 （一）采取强制措施法定期限届满，不予以释放、解除或者变更的； （二）应当退还取保候审保证金不退还的； （三）对与案件无关的财物采取查封、扣押、冻结措施的； （四）应当解除查封、扣押、冻结不解除的； （五）贪污、挪用、私分、调换、违反规定使用查封、扣押、冻结的财物的。 受理申诉或者控告的机关应当及时处理。对处理不服的，可以向同级人民检察院申诉；人民检察院直接受理的案件，可以向上一级人民检察院申诉。人民检察院对申诉应当及时进行审查，情况属实的，通知有关机关予以纠正。 第一百一十八条 讯问犯罪嫌疑人必须由人民检察院或者公安机关的侦查人员负责进行。讯问的时候，侦查人员不得少于二人。 犯罪嫌疑人被送交看守所羁押以后，侦查人员对其进行讯问，应当在看守所内进行。 第一百一十九条 对不需要逮捕、拘留的犯罪嫌疑人，可以传唤到犯罪嫌疑人所在市、县内的指定地点或者到他的住处进行讯问，但是应当出示人民检察院或者公安机关的证明文件。对在现场发现的犯罪嫌疑人，经出示工作证件，可以口头传唤，但应当在讯问笔录中注明。 传唤、拘传持续的时间不得超过十二小时；案情特别重大、复杂，需要采取拘留、逮捕措施的，传唤、拘传持续的时间不得超过二十四小时。 不得以连续传唤、拘传的形式变相拘禁犯罪嫌疑人。传唤、拘传犯罪嫌疑人，应当保证犯罪嫌疑人的饮食和必要的休息时间。 第一百二十条 侦查人员在讯问犯罪嫌疑人的时候，应当首先讯问犯罪嫌疑人是否有犯罪行为，让他陈述有罪的情节或者无罪的辩解，然后向他提出问题。犯罪嫌疑人对侦查人员的提问，应当如实回答。但是对与本案无关的问题，有拒绝回答的权利。 侦查人员在讯问犯罪嫌疑人的时候，应当告知犯罪嫌疑人享有的诉讼权利，如实供述自己罪行可以从宽处理和认罪认罚的法律规定。 第一百二十一条 讯问聋、哑的犯罪嫌疑人，应当有通晓聋、哑手势的人参加，并且将这种情况记明笔录。 第一百二十二条 讯问笔录应当交犯罪嫌疑人核对，对于没有阅读能力的，应当向他宣读。如果记载有遗漏或者差错，犯罪嫌疑人可以提出补充或者改正。犯罪嫌疑人承认笔录没有错误后，应当签名或者盖章。侦查人员也应当在笔录上签名。犯罪嫌疑人请求自行书写供述的，应当准许。必要的时候，侦查人员也可以要犯罪嫌疑人亲笔书写供词。 第一百二十三条 侦查人员在讯问犯罪嫌疑人的时候，可以对讯问过程进行录音或者录像；对于可能判处无期徒刑、死刑的案件或者其他重大犯罪案件，应当对讯问过程进行录音或者录像。 录音或者录像应当全程进行，保持完整性。 第一百二十四条 侦查人员询问证人，可以在现场进行，也可以到证人所在单位、住处或者证人提出的地点进行，在必要的时候，可以通知证人到人民检察院或者公安机关提供证言。在现场询问证人，应当出示工作证件，到证人所在单位、住处或者证人提出的地点询问证人，应当出示人民检察院或者公安机关的证明文件。 询问证人应当个别进行。 第一百二十五条 询问证人，应当告知他应当如实地提供证据、证言和有意作伪证或者隐匿罪证要负的法律责任。 第一百二十六条 本法第一百二十二条的规定，也适用于询问证人。 第一百二十七条 询问被害人，适用本节各条规定。 第一百二十八条 侦查人员对于与犯罪有关的场所、物品、人身、尸体应当进行勘验或者检查。在必要的时候，可以指派或者聘请具有专门知识的人，在侦查人员的主持下进行勘验、检查。 第一百二十九条 任何单位和个人，都有义务保护犯罪现场，并且立即通知公安机关派员勘验。 第一百三十条 侦查人员执行勘验、检查，必须持有人民检察院或者公安机关的证明文件。 第一百三十一条 对于死因不明的尸体，公安机关有权决定解剖，并且通知死者家属到场。 第一百三十二条 为了确定被害人、犯罪嫌疑人的某些特征、伤害情况或者生理状态，可以对人身进行检查，可以提取指纹信息，采集血液、尿液等生物样本。 犯罪嫌疑人如果拒绝检查，侦查人员认为必要的时候，可以强制检查。 检查妇女的身体，应当由女工作人员或者医师进行。 第一百三十三条 勘验、检查的情况应当写成笔录，由参加勘验、检查的人和见证人签名或者盖章。 第一百三十四条 人民检察院审查案件的时候，对公安机关的勘验、检查，认为需要复验、复查时，可以要求公安机关复验、复查，并且可以派检察人员参加。 第一百三十五条 为了查明案情，在必要的时候，经公安机关负责人批准，可以进行侦查实验。 侦查实验的情况应当写成笔录，由参加实验的人签名或者盖章。 侦查实验，禁止一切足以造成危险、侮辱人格或者有伤风化的行为。 第一百三十六条 为了收集犯罪证据、查获犯罪人，侦查人员可以对犯罪嫌疑人以及可能隐藏罪犯或者犯罪证据的人的身体、物品、住处和其他有关的地方进行搜查。 第一百三十七条 任何单位和个人，有义务按照人民检察院和公安机关的要求，交出可以证明犯罪嫌疑人有罪或者无罪的物证、书证、视听资料等证据。 第一百三十八条 进行搜查，必须向被搜查人出示搜查证。 在执行逮捕、拘留的时候，遇有紧急情况，不另用搜查证也可以进行搜查。 第一百三十九条 在搜查的时候，应当有被搜查人或者他的家属，邻居或者其他见证人在场。 搜查妇女的身体，应当由女工作人员进行。 第一百四十条 搜查的情况应当写成笔录，由侦查人员和被搜查人或者他的家属，邻居或者其他见证人签名或者盖章。如果被搜查人或者他的家属在逃或者拒绝签名、盖章，应当在笔录上注明。 第一百四十一条 在侦查活动中发现的可用以证明犯罪嫌疑人有罪或者无罪的各种财物、文件，应当查封、扣押；与案件无关的财物、文件，不得查封、扣押。 对查封、扣押的财物、文件，要妥善保管或者封存，不得使用、调换或者损毁。 第一百四十二条 对查封、扣押的财物、文件，应当会同在场见证人和被查封、扣押财物、文件持有人查点清楚，当场开列清单一式二份，由侦查人员、见证人和持有人签名或者盖章，一份交给持有人，另一份附卷备查。 第一百四十三条 侦查人员认为需要扣押犯罪嫌疑人的邮件、电报的时候，经公安机关或者人民检察院批准，即可通知邮电机关将有关的邮件、电报检交扣押。 不需要继续扣押的时候，应即通知邮电机关。 第一百四十四条 人民检察院、公安机关根据侦查犯罪的需要，可以依照规定查询、冻结犯罪嫌疑人的存款、汇款、债券、股票、基金份额等财产。有关单位和个人应当配合。 犯罪嫌疑人的存款、汇款、债券、股票、基金份额等财产已被冻结的，不得重复冻结。 第一百四十五条 对查封、扣押的财物、文件、邮件、电报或者冻结的存款、汇款、债券、股票、基金份额等财产，经查明确实与案件无关的，应当在三日以内解除查封、扣押、冻结，予以退还。 第一百四十六条 为了查明案情，需要解决案件中某些专门性问题的时候，应当指派、聘请有专门知识的人进行鉴定。 第一百四十七条 鉴定人进行鉴定后，应当写出鉴定意见，并且签名。 鉴定人故意作虚假鉴定的，应当承担法律责任。 第一百四十八条 侦查机关应当将用作证据的鉴定意见告知犯罪嫌疑人、被害人。如果犯罪嫌疑人、被害人提出申请，可以补充鉴定或者重新鉴定。 第一百四十九条 对犯罪嫌疑人作精神病鉴定的期间不计入办案期限。 第一百五十条 公安机关在立案后，对于危害国家安全犯罪、恐怖活动犯罪、黑社会性质的组织犯罪、重大毒品犯罪或者其他严重危害社会的犯罪案件，根据侦查犯罪的需要，经过严格的批准手续，可以采取技术侦查措施。 人民检察院在立案后，对于利用职权实施的严重侵犯公民人身权利的重大犯罪案件，根据侦查犯罪的需要，经过严格的批准手续，可以采取技术侦查措施，按照规定交有关机关执行。 追捕被通缉或者批准、决定逮捕的在逃的犯罪嫌疑人、被告人，经过批准，可以采取追捕所必需的技术侦查措施。 第一百五十一条 批准决定应当根据侦查犯罪的需要，确定采取技术侦查措施的种类和适用对象。批准决定自签发之日起三个月以内有效。对于不需要继续采取技术侦查措施的，应当及时解除；对于复杂、疑难案件，期限届满仍有必要继续采取技术侦查措施的，经过批准，有效期可以延长，每次不得超过三个月。 第一百五十二条 采取技术侦查措施，必须严格按照批准的措施种类、适用对象和期限执行。 侦查人员对采取技术侦查措施过程中知悉的国家秘密、商业秘密和个人隐私，应当保密；对采取技术侦查措施获取的与案件无关的材料，必须及时销毁。 采取技术侦查措施获取的材料，只能用于对犯罪的侦查、起诉和审判，不得用于其他用途。 公安机关依法采取技术侦查措施，有关单位和个人应当配合，并对有关情况予以保密。 第一百五十三条 为了查明案情，在必要的时候，经公安机关负责人决定，可以由有关人员隐匿其身份实施侦查。但是，不得诱使他人犯罪，不得采用可能危害公共安全或者发生重大人身危险的方法。 对涉及给付毒品等违禁品或者财物的犯罪活动，公安机关根据侦查犯罪的需要，可以依照规定实施控制下交付。 第一百五十四条 依照本节规定采取侦查措施收集的材料在刑事诉讼中可以作为证据使用。如果使用该证据可能危及有关人员的人身安全，或者可能产生其他严重后果的，应当采取不暴露有关人员身份、技术方法等保护措施，必要的时候，可以由审判人员在庭外对证据进行核实。 第一百五十五条 应当逮捕的犯罪嫌疑人如果在逃，公安机关可以发布通缉令，采取有效措施，追捕归案。 各级公安机关在自己管辖的地区以内，可以直接发布通缉令；超出自己管辖的地区，应当报请有权决定的上级机关发布。 第一百五十六条 对犯罪嫌疑人逮捕后的侦查羁押期限不得超过二个月。案情复杂、期限届满不能终结的案件，可以经上一级人民检察院批准延长一个月。 第一百五十七条 因为特殊原因，在较长时间内不宜交付审判的特别重大复杂的案件，由最高人民检察院报请全国人民代表大会常务委员会批准延期审理。 第一百五十八条 下列案件在本法第一百五十六条规定的期限届满不能侦查终结的，经省、自治区、直辖市人民检察院批准或者决定，可以延长二个月： （一）交通十分不便的边远地区的重大复杂案件； （二）重大的犯罪集团案件； （三）流窜作案的重大复杂案件； （四）犯罪涉及面广，取证困难的重大复杂案件。 第一百五十九条 对犯罪嫌疑人可能判处十年有期徒刑以上刑罚，依照本法第一百五十八条规定延长期限届满，仍不能侦查终结的，经省、自治区、直辖市人民检察院批准或者决定，可以再延长二个月。 第一百六十条 在侦查期间，发现犯罪嫌疑人另有重要罪行的，自发现之日起依照本法第一百五十六条的规定重新计算侦查羁押期限。 犯罪嫌疑人不讲真实姓名、住址，身份不明的，应当对其身份进行调查，侦查羁押期限自查清其身份之日起计算，但是不得停止对其犯罪行为的侦查取证。对于犯罪事实清楚，证据确实、充分，确实无法查明其身份的，也可以按其自报的姓名起诉、审判。 第一百六十一条 在案件侦查终结前，辩护律师提出要求的，侦查机关应当听取辩护律师的意见，并记录在案。辩护律师提出书面意见的，应当附卷。 第一百六十二条 公安机关侦查终结的案件，应当做到犯罪事实清楚，证据确实、充分，并且写出起诉意见书，连同案卷材料、证据一并移送同级人民检察院审查决定；同时将案件移送情况告知犯罪嫌疑人及其辩护律师。 犯罪嫌疑人自愿认罪的，应当记录在案，随案移送，并在起诉意见书中写明有关情况。 第一百六十三条 在侦查过程中，发现不应对犯罪嫌疑人追究刑事责任的，应当撤销案件；犯罪嫌疑人已被逮捕的，应当立即释放，发给释放证明，并且通知原批准逮捕的人民检察院。 第一百六十四条 人民检察院对直接受理的案件的侦查适用本章规定。 第一百六十五条 人民检察院直接受理的案件中符合本法第八十一条、第八十二条第四项、第五项规定情形，需要逮捕、拘留犯罪嫌疑人的，由人民检察院作出决定，由公安机关执行。 第一百六十六条 人民检察院对直接受理的案件中被拘留的人，应当在拘留后的二十四小时以内进行讯问。在发现不应当拘留的时候，必须立即释放，发给释放证明。 第一百六十七条 人民检察院对直接受理的案件中被拘留的人，认为需要逮捕的，应当在十四日以内作出决定。在特殊情况下，决定逮捕的时间可以延长一日至三日。对不需要逮捕的，应当立即释放；对需要继续侦查，并且符合取保候审、监视居住条件的，依法取保候审或者监视居住。 第一百六十八条 人民检察院侦查终结的案件，应当作出提起公诉、不起诉或者撤销案件的决定。 第三章 提起公诉第一百六十九条 凡需要提起公诉的案件，一律由人民检察院审查决定。 第一百七十条 人民检察院对于监察机关移送起诉的案件，依照本法和监察法的有关规定进行审查。人民检察院经审查，认为需要补充核实的，应当退回监察机关补充调查，必要时可以自行补充侦查。 对于监察机关移送起诉的已采取留置措施的案件，人民检察院应当对犯罪嫌疑人先行拘留，留置措施自动解除。人民检察院应当在拘留后的十日以内作出是否逮捕、取保候审或者监视居住的决定。在特殊情况下，决定的时间可以延长一日至四日。人民检察院决定采取强制措施的期间不计入审查起诉期限。 第一百七十一条 人民检察院审查案件的时候，必须查明： （一）犯罪事实、情节是否清楚，证据是否确实、充分，犯罪性质和罪名的认定是否正确； （二）有无遗漏罪行和其他应当追究刑事责任的人； （三）是否属于不应追究刑事责任的； （四）有无附带民事诉讼； （五）侦查活动是否合法。 第一百七十二条 人民检察院对于监察机关、公安机关移送起诉的案件，应当在一个月以内作出决定，重大、复杂的案件，可以延长十五日；犯罪嫌疑人认罪认罚，符合速裁程序适用条件的，应当在十日以内作出决定，对可能判处的有期徒刑超过一年的，可以延长至十五日。 人民检察院审查起诉的案件，改变管辖的，从改变后的人民检察院收到案件之日起计算审查起诉期限。 第一百七十三条 人民检察院审查案件，应当讯问犯罪嫌疑人，听取辩护人或者值班律师、被害人及其诉讼代理人的意见，并记录在案。辩护人或者值班律师、被害人及其诉讼代理人提出书面意见的，应当附卷。 犯罪嫌疑人认罪认罚的，人民检察院应当告知其享有的诉讼权利和认罪认罚的法律规定，听取犯罪嫌疑人、辩护人或者值班律师、被害人及其诉讼代理人对下列事项的意见，并记录在案： （一）涉嫌的犯罪事实、罪名及适用的法律规定； （二）从轻、减轻或者免除处罚等从宽处罚的建议； （三）认罪认罚后案件审理适用的程序； （四）其他需要听取意见的事项。 人民检察院依照前两款规定听取值班律师意见的，应当提前为值班律师了解案件有关情况提供必要的便利。 第一百七十四条 犯罪嫌疑人自愿认罪，同意量刑建议和程序适用的，应当在辩护人或者值班律师在场的情况下签署认罪认罚具结书。 犯罪嫌疑人认罪认罚，有下列情形之一的，不需要签署认罪认罚具结书： （一）犯罪嫌疑人是盲、聋、哑人，或者是尚未完全丧失辨认或者控制自己行为能力的精神病人的； （二）未成年犯罪嫌疑人的法定代理人、辩护人对未成年人认罪认罚有异议的； （三）其他不需要签署认罪认罚具结书的情形。 第一百七十五条 人民检察院审查案件，可以要求公安机关提供法庭审判所必需的证据材料；认为可能存在本法第五十六条规定的以非法方法收集证据情形的，可以要求其对证据收集的合法性作出说明。 人民检察院审查案件，对于需要补充侦查的，可以退回公安机关补充侦查，也可以自行侦查。 对于补充侦查的案件，应当在一个月以内补充侦查完毕。补充侦查以二次为限。补充侦查完毕移送人民检察院后，人民检察院重新计算审查起诉期限。 对于二次补充侦查的案件，人民检察院仍然认为证据不足，不符合起诉条件的，应当作出不起诉的决定。 第一百七十六条 人民检察院认为犯罪嫌疑人的犯罪事实已经查清，证据确实、充分，依法应当追究刑事责任的，应当作出起诉决定，按照审判管辖的规定，向人民法院提起公诉，并将案卷材料、证据移送人民法院。 犯罪嫌疑人认罪认罚的，人民检察院应当就主刑、附加刑、是否适用缓刑等提出量刑建议，并随案移送认罪认罚具结书等材料。 第一百七十七条 犯罪嫌疑人没有犯罪事实，或者有本法第十六条规定的情形之一的，人民检察院应当作出不起诉决定。 对于犯罪情节轻微，依照刑法规定不需要判处刑罚或者免除刑罚的，人民检察院可以作出不起诉决定。 人民检察院决定不起诉的案件，应当同时对侦查中查封、扣押、冻结的财物解除查封、扣押、冻结。对被不起诉人需要给予行政处罚、处分或者需要没收其违法所得的，人民检察院应当提出检察意见，移送有关主管机关处理。有关主管机关应当将处理结果及时通知人民检察院。 第一百七十八条 不起诉的决定，应当公开宣布，并且将不起诉决定书送达被不起诉人和他的所在单位。如果被不起诉人在押，应当立即释放。 第一百七十九条 对于公安机关移送起诉的案件，人民检察院决定不起诉的，应当将不起诉决定书送达公安机关。公安机关认为不起诉的决定有错误的时候，可以要求复议，如果意见不被接受，可以向上一级人民检察院提请复核。 第一百八十条 对于有被害人的案件，决定不起诉的，人民检察院应当将不起诉决定书送达被害人。被害人如果不服，可以自收到决定书后七日以内向上一级人民检察院申诉，请求提起公诉。人民检察院应当将复查决定告知被害人。对人民检察院维持不起诉决定的，被害人可以向人民法院起诉。被害人也可以不经申诉，直接向人民法院起诉。人民法院受理案件后，人民检察院应当将有关案件材料移送人民法院。 第一百八十一条 对于人民检察院依照本法第一百七十七条第二款规定作出的不起诉决定，被不起诉人如果不服，可以自收到决定书后七日以内向人民检察院申诉。人民检察院应当作出复查决定，通知被不起诉的人，同时抄送公安机关。 第一百八十二条 犯罪嫌疑人自愿如实供述涉嫌犯罪的事实，有重大立功或者案件涉及国家重大利益的，经最高人民检察院核准，公安机关可以撤销案件，人民检察院可以作出不起诉决定，也可以对涉嫌数罪中的一项或者多项不起诉。 根据前款规定不起诉或者撤销案件的，人民检察院、公安机关应当及时对查封、扣押、冻结的财物及其孳息作出处理。 第三编 审 判第一章 审判组织第一百八十三条 基层人民法院、中级人民法院审判第一审案件，应当由审判员三人或者由审判员和人民陪审员共三人或者七人组成合议庭进行，但是基层人民法院适用简易程序、速裁程序的案件可以由审判员一人独任审判。 高级人民法院审判第一审案件，应当由审判员三人至七人或者由审判员和人民陪审员共三人或者七人组成合议庭进行。 最高人民法院审判第一审案件，应当由审判员三人至七人组成合议庭进行。 人民法院审判上诉和抗诉案件，由审判员三人或者五人组成合议庭进行。 合议庭的成员人数应当是单数。 第一百八十四条 合议庭进行评议的时候，如果意见分歧，应当按多数人的意见作出决定，但是少数人的意见应当写入笔录。评议笔录由合议庭的组成人员签名。 第一百八十五条 合议庭开庭审理并且评议后，应当作出判决。对于疑难、复杂、重大的案件，合议庭认为难以作出决定的，由合议庭提请院长决定提交审判委员会讨论决定。审判委员会的决定，合议庭应当执行。 第二章 第一审程序第一百八十六条 人民法院对提起公诉的案件进行审查后，对于起诉书中有明确的指控犯罪事实的，应当决定开庭审判。 第一百八十七条 人民法院决定开庭审判后，应当确定合议庭的组成人员，将人民检察院的起诉书副本至迟在开庭十日以前送达被告人及其辩护人。 在开庭以前，审判人员可以召集公诉人、当事人和辩护人、诉讼代理人，对回避、出庭证人名单、非法证据排除等与审判相关的问题，了解情况，听取意见。 人民法院确定开庭日期后，应当将开庭的时间、地点通知人民检察院，传唤当事人，通知辩护人、诉讼代理人、证人、鉴定人和翻译人员，传票和通知书至迟在开庭三日以前送达。公开审判的案件，应当在开庭三日以前先期公布案由、被告人姓名、开庭时间和地点。 上述活动情形应当写入笔录，由审判人员和书记员签名。 第一百八十八条 人民法院审判第一审案件应当公开进行。但是有关国家秘密或者个人隐私的案件，不公开审理；涉及商业秘密的案件，当事人申请不公开审理的，可以不公开审理。 不公开审理的案件，应当当庭宣布不公开审理的理由。 第一百八十九条 人民法院审判公诉案件，人民检察院应当派员出席法庭支持公诉。 第一百九十条 开庭的时候，审判长查明当事人是否到庭，宣布案由；宣布合议庭的组成人员、书记员、公诉人、辩护人、诉讼代理人、鉴定人和翻译人员的名单；告知当事人有权对合议庭组成人员、书记员、公诉人、鉴定人和翻译人员申请回避；告知被告人享有辩护权利。 被告人认罪认罚的，审判长应当告知被告人享有的诉讼权利和认罪认罚的法律规定，审查认罪认罚的自愿性和认罪认罚具结书内容的真实性、合法性。 第一百九十一条 公诉人在法庭上宣读起诉书后，被告人、被害人可以就起诉书指控的犯罪进行陈述，公诉人可以讯问被告人。 被害人、附带民事诉讼的原告人和辩护人、诉讼代理人，经审判长许可，可以向被告人发问。 审判人员可以讯问被告人。 第一百九十二条 公诉人、当事人或者辩护人、诉讼代理人对证人证言有异议，且该证人证言对案件定罪量刑有重大影响，人民法院认为证人有必要出庭作证的，证人应当出庭作证。 人民警察就其执行职务时目击的犯罪情况作为证人出庭作证，适用前款规定。 公诉人、当事人或者辩护人、诉讼代理人对鉴定意见有异议，人民法院认为鉴定人有必要出庭的，鉴定人应当出庭作证。经人民法院通知，鉴定人拒不出庭作证的，鉴定意见不得作为定案的根据。 第一百九十三条 经人民法院通知，证人没有正当理由不出庭作证的，人民法院可以强制其到庭，但是被告人的配偶、父母、子女除外。 证人没有正当理由拒绝出庭或者出庭后拒绝作证的，予以训诫，情节严重的，经院长批准，处以十日以下的拘留。被处罚人对拘留决定不服的，可以向上一级人民法院申请复议。复议期间不停止执行。 第一百九十四条 证人作证，审判人员应当告知他要如实地提供证言和有意作伪证或者隐匿罪证要负的法律责任。公诉人、当事人和辩护人、诉讼代理人经审判长许可，可以对证人、鉴定人发问。审判长认为发问的内容与案件无关的时候，应当制止。 审判人员可以询问证人、鉴定人。 第一百九十五条 公诉人、辩护人应当向法庭出示物证，让当事人辨认，对未到庭的证人的证言笔录、鉴定人的鉴定意见、勘验笔录和其他作为证据的文书，应当当庭宣读。审判人员应当听取公诉人、当事人和辩护人、诉讼代理人的意见。 第一百九十六条 法庭审理过程中，合议庭对证据有疑问的，可以宣布休庭，对证据进行调查核实。 人民法院调查核实证据，可以进行勘验、检查、查封、扣押、鉴定和查询、冻结。 第一百九十七条 法庭审理过程中，当事人和辩护人、诉讼代理人有权申请通知新的证人到庭，调取新的物证，申请重新鉴定或者勘验。 公诉人、当事人和辩护人、诉讼代理人可以申请法庭通知有专门知识的人出庭，就鉴定人作出的鉴定意见提出意见。 法庭对于上述申请，应当作出是否同意的决定。 第二款规定的有专门知识的人出庭，适用鉴定人的有关规定。 第一百九十八条 法庭审理过程中，对与定罪、量刑有关的事实、证据都应当进行调查、辩论。 经审判长许可，公诉人、当事人和辩护人、诉讼代理人可以对证据和案件情况发表意见并且可以互相辩论。 审判长在宣布辩论终结后，被告人有最后陈述的权利。 第一百九十九条 在法庭审判过程中，如果诉讼参与人或者旁听人员违反法庭秩序，审判长应当警告制止。对不听制止的，可以强行带出法庭；情节严重的，处以一千元以下的罚款或者十五日以下的拘留。罚款、拘留必须经院长批准。被处罚人对罚款、拘留的决定不服的，可以向上一级人民法院申请复议。复议期间不停止执行。 对聚众哄闹、冲击法庭或者侮辱、诽谤、威胁、殴打司法工作人员或者诉讼参与人，严重扰乱法庭秩序，构成犯罪的，依法追究刑事责任。 第二百条 在被告人最后陈述后，审判长宣布休庭，合议庭进行评议，根据已经查明的事实、证据和有关的法律规定，分别作出以下判决： （一）案件事实清楚，证据确实、充分，依据法律认定被告人有罪的，应当作出有罪判决； （二）依据法律认定被告人无罪的，应当作出无罪判决； （三）证据不足，不能认定被告人有罪的，应当作出证据不足、指控的犯罪不能成立的无罪判决。 第二百零一条 对于认罪认罚案件，人民法院依法作出判决时，一般应当采纳人民检察院指控的罪名和量刑建议，但有下列情形的除外： （一）被告人的行为不构成犯罪或者不应当追究其刑事责任的； （二）被告人违背意愿认罪认罚的； （三）被告人否认指控的犯罪事实的； （四）起诉指控的罪名与审理认定的罪名不一致的； （五）其他可能影响公正审判的情形。 人民法院经审理认为量刑建议明显不当，或者被告人、辩护人对量刑建议提出异议的，人民检察院可以调整量刑建议。人民检察院不调整量刑建议或者调整量刑建议后仍然明显不当的，人民法院应当依法作出判决。 第二百零二条 宣告判决，一律公开进行。 当庭宣告判决的，应当在五日以内将判决书送达当事人和提起公诉的人民检察院；定期宣告判决的，应当在宣告后立即将判决书送达当事人和提起公诉的人民检察院。判决书应当同时送达辩护人、诉讼代理人。 第二百零三条 判决书应当由审判人员和书记员署名，并且写明上诉的期限和上诉的法院。 第二百零四条 在法庭审判过程中，遇有下列情形之一，影响审判进行的，可以延期审理： （一）需要通知新的证人到庭，调取新的物证，重新鉴定或者勘验的； （二）检察人员发现提起公诉的案件需要补充侦查，提出建议的； （三）由于申请回避而不能进行审判的。 第二百零五条 依照本法第二百零四条第二项的规定延期审理的案件，人民检察院应当在一个月以内补充侦查完毕。 第二百零六条 在审判过程中，有下列情形之一，致使案件在较长时间内无法继续审理的，可以中止审理： （一）被告人患有严重疾病，无法出庭的； （二）被告人脱逃的； （三）自诉人患有严重疾病，无法出庭，未委托诉讼代理人出庭的； （四）由于不能抗拒的原因。 中止审理的原因消失后，应当恢复审理。中止审理的期间不计入审理期限。 第二百零七条 法庭审判的全部活动，应当由书记员写成笔录，经审判长审阅后，由审判长和书记员签名。 法庭笔录中的证人证言部分，应当当庭宣读或者交给证人阅读。证人在承认没有错误后，应当签名或者盖章。 法庭笔录应当交给当事人阅读或者向他宣读。当事人认为记载有遗漏或者差错的，可以请求补充或者改正。当事人承认没有错误后，应当签名或者盖章。 第二百零八条 人民法院审理公诉案件，应当在受理后二个月以内宣判，至迟不得超过三个月。对于可能判处死刑的案件或者附带民事诉讼的案件，以及有本法第一百五十八条规定情形之一的，经上一级人民法院批准，可以延长三个月；因特殊情况还需要延长的，报请最高人民法院批准。 人民法院改变管辖的案件，从改变后的人民法院收到案件之日起计算审理期限。 人民检察院补充侦查的案件，补充侦查完毕移送人民法院后，人民法院重新计算审理期限。 第二百零九条 人民检察院发现人民法院审理案件违反法律规定的诉讼程序，有权向人民法院提出纠正意见。 第二百一十条 自诉案件包括下列案件： （一）告诉才处理的案件； （二）被害人有证据证明的轻微刑事案件； （三）被害人有证据证明对被告人侵犯自己人身、财产权利的行为应当依法追究刑事责任，而公安机关或者人民检察院不予追究被告人刑事责任的案件。 第二百一十一条 人民法院对于自诉案件进行审查后，按照下列情形分别处理： （一）犯罪事实清楚，有足够证据的案件，应当开庭审判； （二）缺乏罪证的自诉案件，如果自诉人提不出补充证据，应当说服自诉人撤回自诉，或者裁定驳回。 自诉人经两次依法传唤，无正当理由拒不到庭的，或者未经法庭许可中途退庭的，按撤诉处理。 法庭审理过程中，审判人员对证据有疑问，需要调查核实的，适用本法第一百九十六条的规定。 第二百一十二条 人民法院对自诉案件，可以进行调解；自诉人在宣告判决前，可以同被告人自行和解或者撤回自诉。本法第二百一十条第三项规定的案件不适用调解。 人民法院审理自诉案件的期限，被告人被羁押的，适用本法第二百零八条第一款、第二款的规定；未被羁押的，应当在受理后六个月以内宣判。 第二百一十三条 自诉案件的被告人在诉讼过程中，可以对自诉人提起反诉。反诉适用自诉的规定。 第二百一十四条 基层人民法院管辖的案件，符合下列条件的，可以适用简易程序审判： （一）案件事实清楚、证据充分的； （二）被告人承认自己所犯罪行，对指控的犯罪事实没有异议的； （三）被告人对适用简易程序没有异议的。 人民检察院在提起公诉的时候，可以建议人民法院适用简易程序。 第二百一十五条 有下列情形之一的，不适用简易程序： （一）被告人是盲、聋、哑人，或者是尚未完全丧失辨认或者控制自己行为能力的精神病人的； （二）有重大社会影响的； （三）共同犯罪案件中部分被告人不认罪或者对适用简易程序有异议的； （四）其他不宜适用简易程序审理的。 第二百一十六条 适用简易程序审理案件，对可能判处三年有期徒刑以下刑罚的，可以组成合议庭进行审判，也可以由审判员一人独任审判；对可能判处的有期徒刑超过三年的，应当组成合议庭进行审判。 适用简易程序审理公诉案件，人民检察院应当派员出席法庭。 第二百一十七条 适用简易程序审理案件，审判人员应当询问被告人对指控的犯罪事实的意见，告知被告人适用简易程序审理的法律规定，确认被告人是否同意适用简易程序审理。 第二百一十八条 适用简易程序审理案件，经审判人员许可，被告人及其辩护人可以同公诉人、自诉人及其诉讼代理人互相辩论。 第二百一十九条 适用简易程序审理案件，不受本章第一节关于送达期限、讯问被告人、询问证人、鉴定人、出示证据、法庭辩论程序规定的限制。但在判决宣告前应当听取被告人的最后陈述意见。 第二百二十条 适用简易程序审理案件，人民法院应当在受理后二十日以内审结；对可能判处的有期徒刑超过三年的，可以延长至一个半月。 第二百二十一条 人民法院在审理过程中，发现不宜适用简易程序的，应当按照本章第一节或者第二节的规定重新审理。 第二百二十二条 基层人民法院管辖的可能判处三年有期徒刑以下刑罚的案件，案件事实清楚，证据确实、充分，被告人认罪认罚并同意适用速裁程序的，可以适用速裁程序，由审判员一人独任审判。 人民检察院在提起公诉的时候，可以建议人民法院适用速裁程序。 第二百二十三条 有下列情形之一的，不适用速裁程序： （一）被告人是盲、聋、哑人，或者是尚未完全丧失辨认或者控制自己行为能力的精神病人的； （二）被告人是未成年人的； （三）案件有重大社会影响的； （四）共同犯罪案件中部分被告人对指控的犯罪事实、罪名、量刑建议或者适用速裁程序有异议的； （五）被告人与被害人或者其法定代理人没有就附带民事诉讼赔偿等事项达成调解或者和解协议的； （六）其他不宜适用速裁程序审理的。 第二百二十四条 适用速裁程序审理案件，不受本章第一节规定的送达期限的限制，一般不进行法庭调查、法庭辩论，但在判决宣告前应当听取辩护人的意见和被告人的最后陈述意见。 适用速裁程序审理案件，应当当庭宣判。 第二百二十五条 适用速裁程序审理案件，人民法院应当在受理后十日以内审结；对可能判处的有期徒刑超过一年的，可以延长至十五日。 第二百二十六条 人民法院在审理过程中，发现有被告人的行为不构成犯罪或者不应当追究其刑事责任、被告人违背意愿认罪认罚、被告人否认指控的犯罪事实或者其他不宜适用速裁程序审理的情形的，应当按照本章第一节或者第三节的规定重新审理。 第三章 第二审程序第二百二十七条 被告人、自诉人和他们的法定代理人，不服地方各级人民法院第一审的判决、裁定，有权用书状或者口头向上一级人民法院上诉。被告人的辩护人和近亲属，经被告人同意，可以提出上诉。 附带民事诉讼的当事人和他们的法定代理人，可以对地方各级人民法院第一审的判决、裁定中的附带民事诉讼部分，提出上诉。 对被告人的上诉权，不得以任何借口加以剥夺。 第二百二十八条 地方各级人民检察院认为本级人民法院第一审的判决、裁定确有错误的时候，应当向上一级人民法院提出抗诉。 第二百二十九条 被害人及其法定代理人不服地方各级人民法院第一审的判决的，自收到判决书后五日以内，有权请求人民检察院提出抗诉。人民检察院自收到被害人及其法定代理人的请求后五日以内，应当作出是否抗诉的决定并且答复请求人。 第二百三十条 不服判决的上诉和抗诉的期限为十日，不服裁定的上诉和抗诉的期限为五日，从接到判决书、裁定书的第二日起算。 第二百三十一条 被告人、自诉人、附带民事诉讼的原告人和被告人通过原审人民法院提出上诉的，原审人民法院应当在三日以内将上诉状连同案卷、证据移送上一级人民法院，同时将上诉状副本送交同级人民检察院和对方当事人。 被告人、自诉人、附带民事诉讼的原告人和被告人直接向第二审人民法院提出上诉的，第二审人民法院应当在三日以内将上诉状交原审人民法院送交同级人民检察院和对方当事人。 第二百三十二条 地方各级人民检察院对同级人民法院第一审判决、裁定的抗诉，应当通过原审人民法院提出抗诉书，并且将抗诉书抄送上一级人民检察院。原审人民法院应当将抗诉书连同案卷、证据移送上一级人民法院，并且将抗诉书副本送交当事人。 上级人民检察院如果认为抗诉不当，可以向同级人民法院撤回抗诉，并且通知下级人民检察院。 第二百三十三条 第二审人民法院应当就第一审判决认定的事实和适用法律进行全面审查，不受上诉或者抗诉范围的限制。 共同犯罪的案件只有部分被告人上诉的，应当对全案进行审查，一并处理。 第二百三十四条 第二审人民法院对于下列案件，应当组成合议庭，开庭审理： （一）被告人、自诉人及其法定代理人对第一审认定的事实、证据提出异议，可能影响定罪量刑的上诉案件； （二）被告人被判处死刑的上诉案件； （三）人民检察院抗诉的案件； （四）其他应当开庭审理的案件。 第二审人民法院决定不开庭审理的，应当讯问被告人，听取其他当事人、辩护人、诉讼代理人的意见。 第二审人民法院开庭审理上诉、抗诉案件，可以到案件发生地或者原审人民法院所在地进行。 第二百三十五条 人民检察院提出抗诉的案件或者第二审人民法院开庭审理的公诉案件，同级人民检察院都应当派员出席法庭。第二审人民法院应当在决定开庭审理后及时通知人民检察院查阅案卷。人民检察院应当在一个月以内查阅完毕。人民检察院查阅案卷的时间不计入审理期限。 第二百三十六条 第二审人民法院对不服第一审判决的上诉、抗诉案件，经过审理后，应当按照下列情形分别处理： （一）原判决认定事实和适用法律正确、量刑适当的，应当裁定驳回上诉或者抗诉，维持原判； （二）原判决认定事实没有错误，但适用法律有错误，或者量刑不当的，应当改判； （三）原判决事实不清楚或者证据不足的，可以在查清事实后改判；也可以裁定撤销原判，发回原审人民法院重新审判。 原审人民法院对于依照前款第三项规定发回重新审判的案件作出判决后，被告人提出上诉或者人民检察院提出抗诉的，第二审人民法院应当依法作出判决或者裁定，不得再发回原审人民法院重新审判。 第二百三十七条 第二审人民法院审理被告人或者他的法定代理人、辩护人、近亲属上诉的案件，不得加重被告人的刑罚。第二审人民法院发回原审人民法院重新审判的案件，除有新的犯罪事实，人民检察院补充起诉的以外，原审人民法院也不得加重被告人的刑罚。 人民检察院提出抗诉或者自诉人提出上诉的，不受前款规定的限制。 第二百三十八条 第二审人民法院发现第一审人民法院的审理有下列违反法律规定的诉讼程序的情形之一的，应当裁定撤销原判，发回原审人民法院重新审判： （一）违反本法有关公开审判的规定的； （二）违反回避制度的； （三）剥夺或者限制了当事人的法定诉讼权利，可能影响公正审判的； （四）审判组织的组成不合法的； （五）其他违反法律规定的诉讼程序，可能影响公正审判的。 第二百三十九条 原审人民法院对于发回重新审判的案件，应当另行组成合议庭，依照第一审程序进行审判。对于重新审判后的判决，依照本法第二百二十七条、第二百二十八条、第二百二十九条的规定可以上诉、抗诉。 第二百四十条 第二审人民法院对不服第一审裁定的上诉或者抗诉，经过审查后，应当参照本法第二百三十六条、第二百三十八条和第二百三十九条的规定，分别情形用裁定驳回上诉、抗诉，或者撤销、变更原裁定。 第二百四十一条 第二审人民法院发回原审人民法院重新审判的案件，原审人民法院从收到发回的案件之日起，重新计算审理期限。 第二百四十二条 第二审人民法院审判上诉或者抗诉案件的程序，除本章已有规定的以外，参照第一审程序的规定进行。 第二百四十三条 第二审人民法院受理上诉、抗诉案件，应当在二个月以内审结。对于可能判处死刑的案件或者附带民事诉讼的案件，以及有本法第一百五十八条规定情形之一的，经省、自治区、直辖市高级人民法院批准或者决定，可以延长二个月；因特殊情况还需要延长的，报请最高人民法院批准。 最高人民法院受理上诉、抗诉案件的审理期限，由最高人民法院决定。 第二百四十四条 第二审的判决、裁定和最高人民法院的判决、裁定，都是终审的判决、裁定。 第二百四十五条 公安机关、人民检察院和人民法院对查封、扣押、冻结的犯罪嫌疑人、被告人的财物及其孳息，应当妥善保管，以供核查，并制作清单，随案移送。任何单位和个人不得挪用或者自行处理。对被害人的合法财产，应当及时返还。对违禁品或者不宜长期保存的物品，应当依照国家有关规定处理。 对作为证据使用的实物应当随案移送，对不宜移送的，应当将其清单、照片或者其他证明文件随案移送。 人民法院作出的判决，应当对查封、扣押、冻结的财物及其孳息作出处理。 人民法院作出的判决生效以后，有关机关应当根据判决对查封、扣押、冻结的财物及其孳息进行处理。对查封、扣押、冻结的赃款赃物及其孳息，除依法返还被害人的以外，一律上缴国库。 司法工作人员贪污、挪用或者私自处理查封、扣押、冻结的财物及其孳息的，依法追究刑事责任；不构成犯罪的，给予处分。 第四章 死刑复核程序第二百四十六条 死刑由最高人民法院核准。 第二百四十七条 中级人民法院判处死刑的第一审案件，被告人不上诉的，应当由高级人民法院复核后，报请最高人民法院核准。高级人民法院不同意判处死刑的，可以提审或者发回重新审判。 高级人民法院判处死刑的第一审案件被告人不上诉的，和判处死刑的第二审案件，都应当报请最高人民法院核准。 第二百四十八条 中级人民法院判处死刑缓期二年执行的案件，由高级人民法院核准。 第二百四十九条 最高人民法院复核死刑案件，高级人民法院复核死刑缓期执行的案件，应当由审判员三人组成合议庭进行。 第二百五十条 最高人民法院复核死刑案件，应当作出核准或者不核准死刑的裁定。对于不核准死刑的，最高人民法院可以发回重新审判或者予以改判。 第二百五十一条 最高人民法院复核死刑案件，应当讯问被告人，辩护律师提出要求的，应当听取辩护律师的意见。 在复核死刑案件过程中，最高人民检察院可以向最高人民法院提出意见。最高人民法院应当将死刑复核结果通报最高人民检察院。 第五章 审判监督程序第二百五十二条 当事人及其法定代理人、近亲属，对已经发生法律效力的判决、裁定，可以向人民法院或者人民检察院提出申诉，但是不能停止判决、裁定的执行。 第二百五十三条 当事人及其法定代理人、近亲属的申诉符合下列情形之一的，人民法院应当重新审判： （一）有新的证据证明原判决、裁定认定的事实确有错误，可能影响定罪量刑的； （二）据以定罪量刑的证据不确实、不充分、依法应当予以排除，或者证明案件事实的主要证据之间存在矛盾的； （三）原判决、裁定适用法律确有错误的； （四）违反法律规定的诉讼程序，可能影响公正审判的； （五）审判人员在审理该案件的时候，有贪污受贿，徇私舞弊，枉法裁判行为的。 第二百五十四条 各级人民法院院长对本院已经发生法律效力的判决和裁定，如果发现在认定事实上或者在适用法律上确有错误，必须提交审判委员会处理。 最高人民法院对各级人民法院已经发生法律效力的判决和裁定，上级人民法院对下级人民法院已经发生法律效力的判决和裁定，如果发现确有错误，有权提审或者指令下级人民法院再审。 最高人民检察院对各级人民法院已经发生法律效力的判决和裁定，上级人民检察院对下级人民法院已经发生法律效力的判决和裁定，如果发现确有错误，有权按照审判监督程序向同级人民法院提出抗诉。 人民检察院抗诉的案件，接受抗诉的人民法院应当组成合议庭重新审理，对于原判决事实不清楚或者证据不足的，可以指令下级人民法院再审。 第二百五十五条 上级人民法院指令下级人民法院再审的，应当指令原审人民法院以外的下级人民法院审理；由原审人民法院审理更为适宜的，也可以指令原审人民法院审理。 第二百五十六条 人民法院按照审判监督程序重新审判的案件，由原审人民法院审理的，应当另行组成合议庭进行。如果原来是第一审案件，应当依照第一审程序进行审判，所作的判决、裁定，可以上诉、抗诉；如果原来是第二审案件，或者是上级人民法院提审的案件，应当依照第二审程序进行审判，所作的判决、裁定，是终审的判决、裁定。 人民法院开庭审理的再审案件，同级人民检察院应当派员出席法庭。 第二百五十七条 人民法院决定再审的案件，需要对被告人采取强制措施的，由人民法院依法决定；人民检察院提出抗诉的再审案件，需要对被告人采取强制措施的，由人民检察院依法决定。 人民法院按照审判监督程序审判的案件，可以决定中止原判决、裁定的执行。 第二百五十八条 人民法院按照审判监督程序重新审判的案件，应当在作出提审、再审决定之日起三个月以内审结，需要延长期限的，不得超过六个月。 接受抗诉的人民法院按照审判监督程序审判抗诉的案件，审理期限适用前款规定；对需要指令下级人民法院再审的，应当自接受抗诉之日起一个月以内作出决定，下级人民法院审理案件的期限适用前款规定。 第四编 执 行第二百五十九条 判决和裁定在发生法律效力后执行。 下列判决和裁定是发生法律效力的判决和裁定： （一）已过法定期限没有上诉、抗诉的判决和裁定； （二）终审的判决和裁定； （三）最高人民法院核准的死刑的判决和高级人民法院核准的死刑缓期二年执行的判决。 第二百六十条 第一审人民法院判决被告人无罪、免除刑事处罚的，如果被告人在押，在宣判后应当立即释放。 第二百六十一条 最高人民法院判处和核准的死刑立即执行的判决，应当由最高人民法院院长签发执行死刑的命令。 被判处死刑缓期二年执行的罪犯，在死刑缓期执行期间，如果没有故意犯罪，死刑缓期执行期满，应当予以减刑的，由执行机关提出书面意见，报请高级人民法院裁定；如果故意犯罪，情节恶劣，查证属实，应当执行死刑的，由高级人民法院报请最高人民法院核准；对于故意犯罪未执行死刑的，死刑缓期执行的期间重新计算，并报最高人民法院备案。 第二百六十二条 下级人民法院接到最高人民法院执行死刑的命令后，应当在七日以内交付执行。但是发现有下列情形之一的，应当停止执行，并且立即报告最高人民法院，由最高人民法院作出裁定： （一）在执行前发现判决可能有错误的； （二）在执行前罪犯揭发重大犯罪事实或者有其他重大立功表现，可能需要改判的； （三）罪犯正在怀孕。 前款第一项、第二项停止执行的原因消失后，必须报请最高人民法院院长再签发执行死刑的命令才能执行；由于前款第三项原因停止执行的，应当报请最高人民法院依法改判。 第二百六十三条 人民法院在交付执行死刑前，应当通知同级人民检察院派员临场监督。 死刑采用枪决或者注射等方法执行。 死刑可以在刑场或者指定的羁押场所内执行。 指挥执行的审判人员，对罪犯应当验明正身，讯问有无遗言、信札，然后交付执行人员执行死刑。在执行前，如果发现可能有错误，应当暂停执行，报请最高人民法院裁定。 执行死刑应当公布，不应示众。 执行死刑后，在场书记员应当写成笔录。交付执行的人民法院应当将执行死刑情况报告最高人民法院。 执行死刑后，交付执行的人民法院应当通知罪犯家属。 第二百六十四条 罪犯被交付执行刑罚的时候，应当由交付执行的人民法院在判决生效后十日以内将有关的法律文书送达公安机关、监狱或者其他执行机关。 对被判处死刑缓期二年执行、无期徒刑、有期徒刑的罪犯，由公安机关依法将该罪犯送交监狱执行刑罚。对被判处有期徒刑的罪犯，在被交付执行刑罚前，剩余刑期在三个月以下的，由看守所代为执行。对被判处拘役的罪犯，由公安机关执行。 对未成年犯应当在未成年犯管教所执行刑罚。 执行机关应当将罪犯及时收押，并且通知罪犯家属。 判处有期徒刑、拘役的罪犯，执行期满，应当由执行机关发给释放证明书。 第二百六十五条 对被判处有期徒刑或者拘役的罪犯，有下列情形之一的，可以暂予监外执行： （一）有严重疾病需要保外就医的； （二）怀孕或者正在哺乳自己婴儿的妇女； （三）生活不能自理，适用暂予监外执行不致危害社会的。 对被判处无期徒刑的罪犯，有前款第二项规定情形的，可以暂予监外执行。 对适用保外就医可能有社会危险性的罪犯，或者自伤自残的罪犯，不得保外就医。 对罪犯确有严重疾病，必须保外就医的，由省级人民政府指定的医院诊断并开具证明文件。 在交付执行前，暂予监外执行由交付执行的人民法院决定；在交付执行后，暂予监外执行由监狱或者看守所提出书面意见，报省级以上监狱管理机关或者设区的市一级以上公安机关批准。 第二百六十六条 监狱、看守所提出暂予监外执行的书面意见的，应当将书面意见的副本抄送人民检察院。人民检察院可以向决定或者批准机关提出书面意见。 第二百六十七条 决定或者批准暂予监外执行的机关应当将暂予监外执行决定抄送人民检察院。人民检察院认为暂予监外执行不当的，应当自接到通知之日起一个月以内将书面意见送交决定或者批准暂予监外执行的机关，决定或者批准暂予监外执行的机关接到人民检察院的书面意见后，应当立即对该决定进行重新核查。 第二百六十八条 对暂予监外执行的罪犯，有下列情形之一的，应当及时收监： （一）发现不符合暂予监外执行条件的； （二）严重违反有关暂予监外执行监督管理规定的； （三）暂予监外执行的情形消失后，罪犯刑期未满的。 对于人民法院决定暂予监外执行的罪犯应当予以收监的，由人民法院作出决定，将有关的法律文书送达公安机关、监狱或者其他执行机关。 不符合暂予监外执行条件的罪犯通过贿赂等非法手段被暂予监外执行的，在监外执行的期间不计入执行刑期。罪犯在暂予监外执行期间脱逃的，脱逃的期间不计入执行刑期。 罪犯在暂予监外执行期间死亡的，执行机关应当及时通知监狱或者看守所。 第二百六十九条 对被判处管制、宣告缓刑、假释或者暂予监外执行的罪犯，依法实行社区矫正，由社区矫正机构负责执行。 第二百七十条 对被判处剥夺政治权利的罪犯，由公安机关执行。执行期满，应当由执行机关书面通知本人及其所在单位、居住地基层组织。 第二百七十一条 被判处罚金的罪犯，期满不缴纳的，人民法院应当强制缴纳；如果由于遭遇不能抗拒的灾祸等原因缴纳确实有困难的，经人民法院裁定，可以延期缴纳、酌情减少或者免除。 第二百七十二条 没收财产的判决，无论附加适用或者独立适用，都由人民法院执行；在必要的时候，可以会同公安机关执行。 第二百七十三条 罪犯在服刑期间又犯罪的，或者发现了判决的时候所没有发现的罪行，由执行机关移送人民检察院处理。 被判处管制、拘役、有期徒刑或者无期徒刑的罪犯，在执行期间确有悔改或者立功表现，应当依法予以减刑、假释的时候，由执行机关提出建议书，报请人民法院审核裁定，并将建议书副本抄送人民检察院。人民检察院可以向人民法院提出书面意见。 第二百七十四条 人民检察院认为人民法院减刑、假释的裁定不当，应当在收到裁定书副本后二十日以内，向人民法院提出书面纠正意见。人民法院应当在收到纠正意见后一个月以内重新组成合议庭进行审理，作出最终裁定。 第二百七十五条 监狱和其他执行机关在刑罚执行中，如果认为判决有错误或者罪犯提出申诉，应当转请人民检察院或者原判人民法院处理。 第二百七十六条 人民检察院对执行机关执行刑罚的活动是否合法实行监督。如果发现有违法的情况，应当通知执行机关纠正。 第五编 特别程序第一章 未成年人刑事案件诉讼程序第二百七十七条 对犯罪的未成年人实行教育、感化、挽救的方针，坚持教育为主、惩罚为辅的原则。 人民法院、人民检察院和公安机关办理未成年人刑事案件，应当保障未成年人行使其诉讼权利，保障未成年人得到法律帮助，并由熟悉未成年人身心特点的审判人员、检察人员、侦查人员承办。 第二百七十八条 未成年犯罪嫌疑人、被告人没有委托辩护人的，人民法院、人民检察院、公安机关应当通知法律援助机构指派律师为其提供辩护。 第二百七十九条 公安机关、人民检察院、人民法院办理未成年人刑事案件，根据情况可以对未成年犯罪嫌疑人、被告人的成长经历、犯罪原因、监护教育等情况进行调查。 第二百八十条 对未成年犯罪嫌疑人、被告人应当严格限制适用逮捕措施。人民检察院审查批准逮捕和人民法院决定逮捕，应当讯问未成年犯罪嫌疑人、被告人，听取辩护律师的意见。 对被拘留、逮捕和执行刑罚的未成年人与成年人应当分别关押、分别管理、分别教育。 第二百八十一条 对于未成年人刑事案件，在讯问和审判的时候，应当通知未成年犯罪嫌疑人、被告人的法定代理人到场。无法通知、法定代理人不能到场或者法定代理人是共犯的，也可以通知未成年犯罪嫌疑人、被告人的其他成年亲属，所在学校、单位、居住地基层组织或者未成年人保护组织的代表到场，并将有关情况记录在案。到场的法定代理人可以代为行使未成年犯罪嫌疑人、被告人的诉讼权利。 到场的法定代理人或者其他人员认为办案人员在讯问、审判中侵犯未成年人合法权益的，可以提出意见。讯问笔录、法庭笔录应当交给到场的法定代理人或者其他人员阅读或者向他宣读。 讯问女性未成年犯罪嫌疑人，应当有女工作人员在场。 审判未成年人刑事案件，未成年被告人最后陈述后，其法定代理人可以进行补充陈述。 询问未成年被害人、证人，适用第一款、第二款、第三款的规定。 第二百八十二条 对于未成年人涉嫌刑法分则第四章、第五章、第六章规定的犯罪，可能判处一年有期徒刑以下刑罚，符合起诉条件，但有悔罪表现的，人民检察院可以作出附条件不起诉的决定。人民检察院在作出附条件不起诉的决定以前，应当听取公安机关、被害人的意见。 对附条件不起诉的决定，公安机关要求复议、提请复核或者被害人申诉的，适用本法第一百七十九条、第一百八十条的规定。 未成年犯罪嫌疑人及其法定代理人对人民检察院决定附条件不起诉有异议的，人民检察院应当作出起诉的决定。 第二百八十三条 在附条件不起诉的考验期内，由人民检察院对被附条件不起诉的未成年犯罪嫌疑人进行监督考察。未成年犯罪嫌疑人的监护人，应当对未成年犯罪嫌疑人加强管教，配合人民检察院做好监督考察工作。 附条件不起诉的考验期为六个月以上一年以下，从人民检察院作出附条件不起诉的决定之日起计算。 被附条件不起诉的未成年犯罪嫌疑人，应当遵守下列规定： （一）遵守法律法规，服从监督； （二）按照考察机关的规定报告自己的活动情况； （三）离开所居住的市、县或者迁居，应当报经考察机关批准； （四）按照考察机关的要求接受矫治和教育。 第二百八十四条 被附条件不起诉的未成年犯罪嫌疑人，在考验期内有下列情形之一的，人民检察院应当撤销附条件不起诉的决定，提起公诉： （一）实施新的犯罪或者发现决定附条件不起诉以前还有其他犯罪需要追诉的； （二）违反治安管理规定或者考察机关有关附条件不起诉的监督管理规定，情节严重的。 被附条件不起诉的未成年犯罪嫌疑人，在考验期内没有上述情形，考验期满的，人民检察院应当作出不起诉的决定。 第二百八十五条 审判的时候被告人不满十八周岁的案件，不公开审理。但是，经未成年被告人及其法定代理人同意，未成年被告人所在学校和未成年人保护组织可以派代表到场。 第二百八十六条 犯罪的时候不满十八周岁，被判处五年有期徒刑以下刑罚的，应当对相关犯罪记录予以封存。 犯罪记录被封存的，不得向任何单位和个人提供，但司法机关为办案需要或者有关单位根据国家规定进行查询的除外。依法进行查询的单位，应当对被封存的犯罪记录的情况予以保密。 第二百八十七条 办理未成年人刑事案件，除本章已有规定的以外，按照本法的其他规定进行。 第二章 当事人和解的公诉案件诉讼程序第二百八十八条 下列公诉案件，犯罪嫌疑人、被告人真诚悔罪，通过向被害人赔偿损失、赔礼道歉等方式获得被害人谅解，被害人自愿和解的，双方当事人可以和解： （一）因民间纠纷引起，涉嫌刑法分则第四章、第五章规定的犯罪案件，可能判处三年有期徒刑以下刑罚的； （二）除渎职犯罪以外的可能判处七年有期徒刑以下刑罚的过失犯罪案件。 犯罪嫌疑人、被告人在五年以内曾经故意犯罪的，不适用本章规定的程序。 第二百八十九条 双方当事人和解的，公安机关、人民检察院、人民法院应当听取当事人和其他有关人员的意见，对和解的自愿性、合法性进行审查，并主持制作和解协议书。 第二百九十条 对于达成和解协议的案件，公安机关可以向人民检察院提出从宽处理的建议。人民检察院可以向人民法院提出从宽处罚的建议；对于犯罪情节轻微，不需要判处刑罚的，可以作出不起诉的决定。人民法院可以依法对被告人从宽处罚。 第三章 缺席审判程序第二百九十一条 对于贪污贿赂犯罪案件，以及需要及时进行审判，经最高人民检察院核准的严重危害国家安全犯罪、恐怖活动犯罪案件，犯罪嫌疑人、被告人在境外，监察机关、公安机关移送起诉，人民检察院认为犯罪事实已经查清，证据确实、充分，依法应当追究刑事责任的，可以向人民法院提起公诉。人民法院进行审查后，对于起诉书中有明确的指控犯罪事实，符合缺席审判程序适用条件的，应当决定开庭审判。 前款案件，由犯罪地、被告人离境前居住地或者最高人民法院指定的中级人民法院组成合议庭进行审理。 第二百九十二条 人民法院应当通过有关国际条约规定的或者外交途径提出的司法协助方式，或者被告人所在地法律允许的其他方式，将传票和人民检察院的起诉书副本送达被告人。传票和起诉书副本送达后，被告人未按要求到案的，人民法院应当开庭审理，依法作出判决，并对违法所得及其他涉案财产作出处理。 第二百九十三条 人民法院缺席审判案件，被告人有权委托辩护人，被告人的近亲属可以代为委托辩护人。被告人及其近亲属没有委托辩护人的，人民法院应当通知法律援助机构指派律师为其提供辩护。 第二百九十四条 人民法院应当将判决书送达被告人及其近亲属、辩护人。被告人或者其近亲属不服判决的，有权向上一级人民法院上诉。辩护人经被告人或者其近亲属同意，可以提出上诉。 人民检察院认为人民法院的判决确有错误的，应当向上一级人民法院提出抗诉。 第二百九十五条 在审理过程中，被告人自动投案或者被抓获的，人民法院应当重新审理。 罪犯在判决、裁定发生法律效力后到案的，人民法院应当将罪犯交付执行刑罚。交付执行刑罚前，人民法院应当告知罪犯有权对判决、裁定提出异议。罪犯对判决、裁定提出异议的，人民法院应当重新审理。 依照生效判决、裁定对罪犯的财产进行的处理确有错误的，应当予以返还、赔偿。 第二百九十六条 因被告人患有严重疾病无法出庭，中止审理超过六个月，被告人仍无法出庭，被告人及其法定代理人、近亲属申请或者同意恢复审理的，人民法院可以在被告人不出庭的情况下缺席审理，依法作出判决。 第二百九十七条 被告人死亡的，人民法院应当裁定终止审理，但有证据证明被告人无罪，人民法院经缺席审理确认无罪的，应当依法作出判决。 人民法院按照审判监督程序重新审判的案件，被告人死亡的，人民法院可以缺席审理，依法作出判决。 第四章 犯罪嫌疑人、被告人逃匿、死亡案件违法所得的没收程序第二百九十八条 对于贪污贿赂犯罪、恐怖活动犯罪等重大犯罪案件，犯罪嫌疑人、被告人逃匿，在通缉一年后不能到案，或者犯罪嫌疑人、被告人死亡，依照刑法规定应当追缴其违法所得及其他涉案财产的，人民检察院可以向人民法院提出没收违法所得的申请。 公安机关认为有前款规定情形的，应当写出没收违法所得意见书，移送人民检察院。 没收违法所得的申请应当提供与犯罪事实、违法所得相关的证据材料，并列明财产的种类、数量、所在地及查封、扣押、冻结的情况。 人民法院在必要的时候，可以查封、扣押、冻结申请没收的财产。 第二百九十九条 没收违法所得的申请，由犯罪地或者犯罪嫌疑人、被告人居住地的中级人民法院组成合议庭进行审理。 人民法院受理没收违法所得的申请后，应当发出公告。公告期间为六个月。犯罪嫌疑人、被告人的近亲属和其他利害关系人有权申请参加诉讼，也可以委托诉讼代理人参加诉讼。 人民法院在公告期满后对没收违法所得的申请进行审理。利害关系人参加诉讼的，人民法院应当开庭审理。 第三百条 人民法院经审理，对经查证属于违法所得及其他涉案财产，除依法返还被害人的以外，应当裁定予以没收；对不属于应当追缴的财产的，应当裁定驳回申请，解除查封、扣押、冻结措施。 对于人民法院依照前款规定作出的裁定，犯罪嫌疑人、被告人的近亲属和其他利害关系人或者人民检察院可以提出上诉、抗诉。 第三百零一条 在审理过程中，在逃的犯罪嫌疑人、被告人自动投案或者被抓获的，人民法院应当终止审理。 没收犯罪嫌疑人、被告人财产确有错误的，应当予以返还、赔偿。 第五章 依法不负刑事责任的精神病人的强制医疗程序第三百零二条 实施暴力行为，危害公共安全或者严重危害公民人身安全，经法定程序鉴定依法不负刑事责任的精神病人，有继续危害社会可能的，可以予以强制医疗。 第三百零三条 根据本章规定对精神病人强制医疗的，由人民法院决定。 公安机关发现精神病人符合强制医疗条件的，应当写出强制医疗意见书，移送人民检察院。对于公安机关移送的或者在审查起诉过程中发现的精神病人符合强制医疗条件的，人民检察院应当向人民法院提出强制医疗的申请。人民法院在审理案件过程中发现被告人符合强制医疗条件的，可以作出强制医疗的决定。 对实施暴力行为的精神病人，在人民法院决定强制医疗前，公安机关可以采取临时的保护性约束措施。 第三百零四条 人民法院受理强制医疗的申请后，应当组成合议庭进行审理。 人民法院审理强制医疗案件，应当通知被申请人或者被告人的法定代理人到场。被申请人或者被告人没有委托诉讼代理人的，人民法院应当通知法律援助机构指派律师为其提供法律帮助。 第三百零五条 人民法院经审理，对于被申请人或者被告人符合强制医疗条件的，应当在一个月以内作出强制医疗的决定。 被决定强制医疗的人、被害人及其法定代理人、近亲属对强制医疗决定不服的，可以向上一级人民法院申请复议。 第三百零六条 强制医疗机构应当定期对被强制医疗的人进行诊断评估。对于已不具有人身危险性，不需要继续强制医疗的，应当及时提出解除意见，报决定强制医疗的人民法院批准。 被强制医疗的人及其近亲属有权申请解除强制医疗。 第三百零七条 人民检察院对强制医疗的决定和执行实行监督。 附则第三百零八条 军队保卫部门对军队内部发生的刑事案件行使侦查权。 中国海警局履行海上维权执法职责，对海上发生的刑事案件行使侦查权。 对罪犯在监狱内犯罪的案件由监狱进行侦查。 军队保卫部门、中国海警局、监狱办理刑事案件，适用本法的有关规定。","link":"/2019/08/21/中华人民共和国刑事诉讼法.html"},{"title":"中华人民共和国劳动法","text":"《中华人民共和国劳动法》已由中华人民共和国第八届全国人民代表大会常务委员会第八次会议于１９９４年７月５日通过，现予公布，自１９９５年１月１日起施行。 中华人民共和国主席令 （第二十八号） 《中华人民共和国劳动法》已由中华人民共和国第八届全国人民代表大会常务委员会第八次会议于１９９４年７月５日通过，现予公布，自１９９５年１月１日起施行。 中华人民共和国主席 江泽民 １９９４年７月５日 中华人民共和国劳动法 （１９９４年７月５日第八届全国人民代表大会常务委员会第八次会议通过） 目录 第一章 总则 第二章 促进就业 第三章 劳动合同和集体合同 第四章 工作时间和休息休假 第五章 工资 第六章 劳动安全卫生 第七章 女职工和未成年工特殊保护 第八章 职业培训 第九章 社会保险和福利 第十章 劳动争议 第十一章 监督检查 第十二章 法律责任 第十三章 附则 第一章 总则 第一 为了保护劳动者的合法权益，调整劳动关系，建立和维护适应社会主义市场经济的劳动制度，促进经济发展和社会进步，根据宪法，制定本法。 第二 在中华人民共和国境内的企业、个体经济组织（以下统称用人单位）和与之形成劳动关系的劳动者，适用本法。 国家机关、事业组织、社会团体和与之建立劳动合同关系的劳动者，依照本法执行。 第三 劳动者享有平等就业和选择职业的权利、取得劳动报酬的权利、休息休假的权利、获得劳动安全卫生保护的权利、接受职业技能培训的权利、享受社会保险和福利的权利、提请劳动争议处理的权利以及法律规定的其他劳动权利。 劳动者应当完成劳动任务，提高职业技能，执行劳动安全卫生规程，遵守劳动纪律和职业道德。 第四 用人单位应当依法建立和完善规章制度，保障劳动者享有劳动权利和履行劳动义务。 第五 国家采取各种措施，促进劳动就业，发展职业教育，制定劳动标准，调节社会收入，完善社会保险，协调劳动关系，逐步提高劳动者的生活水平。 第六 国家提倡劳动者参加社会义务劳动，开展劳动竞赛和合理化建议活动，鼓励和保护劳动者进行科学研究、技术革新和发明创造，表彰和奖励劳动模范和先进工作者。 第七条 劳动者有权依法参加和组织工会。 工会代表和维护劳动者的合法权益，依法独立自主地开展活动。 第八 劳动者依照法律规定，通过职工大会、职工代表大会或者其他形式，参与民主管理或者就保护劳动者合法权益与用人单位进行平等协商。 第九条 国务院劳动行政部门主管全国劳动工作。 县级以上地方人民政府劳动行政部门主管本行政区域内的劳动工作。 第二章 促进就业 第十 国家通过促进经济和社会发展，创造就业条件，扩大就业机会。 国家鼓励企业、事业组织、社会团体在法律、行政法规规定的范围内兴办产业或者拓展经营，增加就业。 国家支持劳动者自愿组织起来就业和从事个体经营实现就业。 第十一 地方各级人民政府应当采取措施，发展多种类型的职业介绍机构，提供就业服务。 第十二 劳动者就业，不因民族、种族、性别、宗教信仰不同而受歧视。 第十三 妇女享有与男子平等的就业权利。在录用职工时，除国家规定的不适合妇女的工种或者岗位外，不得以性别为由拒绝录用妇女或者提高对妇女的录用标准。 第十四 残疾人、少数民族人员、退出现役的军人的就业，法律、法规有特别规定的，从其规定。 第十五条 禁止用人单位招用未满十六周岁的未成年人。 文艺、体育和特种工艺单位招用未满十六周岁的未成年人，必须依照国家有关规定，履行审批手续，并保障其接受义务教育的权利。 第三章 劳动合同和集体合同 第十六 劳动合同是劳动者与用人单位确立劳动关系、明确双方权利和义务的协议。 建立劳动关系应当订立劳动合同。 第十七 订立和变更劳动合同，应当遵循平等自愿、协商一致的原则，不得违反法律、行政法规的规定。 劳动合同依法订立即具有法律约束力，当事人必须履行劳动合同规定的义务。 第十八条 下列劳动合同无效： （一）违反法律、行政法规的劳动合同； （二）采取欺诈、威胁等手段订立的劳动合同。 无效的劳动合同，从订立的时候起，就没有法律约束力。确认劳动合同部分无效的，如果不影响其余部分的效力，其余部分仍然有效。 劳动合同的无效，由劳动争议仲裁委员会或者人民法院确认。 第十九条 劳动合同应当以书面形式订立，并具备以下条款： （一）劳动合同期限； （二）工作内容； （三）劳动保护和劳动条件； （四）劳动报酬； （五）劳动纪律； （六）劳动合同终止的条件； （七）违反劳动合同的责任。 劳动合同除前款规定的必备条款外，当事人可以协商约定其他内容。 第二十 劳动合同的期限分为有固定期限、无固定期限和以完成一定的工作为期限。 劳动者在同一用人单位连续工作满十年以上，当事人双方同意延续劳动合同的，如果劳动者提出订立无固定期限的劳动合同，应当订立无固定期限的劳动合同。 第二十一 劳动合同可以约定试用期。试用期最长不得超过六个月。 第二十二 劳动合同当事人可以在劳动合同中约定保守用人单位商业秘密的有关事项。 第二十三 劳动合同期满或者当事人约定的劳动合同终止条件出现，劳动合同即行终止。 第二十四条 经劳动合同当事人协商一致，劳动合同可以解除。 第二十五 劳动者有下列情形之一的，用人单位可以解除劳动合同： （一）在试用期间被证明不符合录用条件的； （二）严重违反劳动纪律或者用人单位规章制度的； （三）严重失职，营私舞弊，对用人单位利益造成重大损害的； （四）被依法追究刑事责任的。 第二十六 有下列情形之一的，用人单位可以解除劳动合同，但是应当提前三十日以书面形式通知劳动者本人： （一）劳动者患病或者非因工负伤，医疗期满后，不能从事原工作也不能从事由用人单位另行安排的工作的； （二）劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的； （三）劳动合同订立时所依据的客观情况发生重大变化，致使原劳动合同无法履行，经当事人协商不能就变更劳动合同达成协议的。 第二十七 用人单位濒临破产进行法定整顿期间或者生产经营状况发生严重困难，确需裁减人员的，应当提前三十日向工会或者全体职工说明情况，听取工会或者职工的意见，经向劳动行政部门报告后，可以裁减人员。 用人单位依据本条规定裁减人员，在六个月内录用人员的，应当优先录用被裁减的人员。 第二十八 用人单位依据本法第二十四条、第二十六条、第二十七条的规定解除劳动合同的，应当依照国家有关规定给予经济补偿。 第二十九 劳动者有下列情形之一的，用人单位不得依据本法第二十六条、第二十七条的规定解除劳动合同： （一）患职业病或者因工负伤并被确认丧失或者部分丧失劳动能力的； （二）患病或者负伤，在规定的医疗期内的； （三）女职工在孕期、产假、哺乳期内的； （四）法律、行政法规规定的其他情形。 第三十 用人单位解除劳动合同，工会认为不适当的，有权提出意见。如果用人单位违反法律、法规或者劳动合同，工会有权要求重新处理；劳动者申请仲裁或者提起诉讼的，工会应当依法给予支持和帮助。 第三十一 劳动者解除劳动合同，应当提前三十日以书面形式通知用人单位。 第三十二 有下列情形之一的，劳动者可以随时通知用人单位解除劳动合同： （一）在试用期内的； （二）用人单位以暴力、威胁或者非法限制人身自由的手段强迫劳动的； （三）用人单位未按照劳动合同约定支付劳动报酬或者提供劳动条件的。 第三十三 企业职工一方与企业可以就劳动报酬、工作时间、休息休假、劳动安全卫生、保险福利等事项，签订集体合同。集体合同草案应当提交职工代表大会或者全体职工讨论通过。 集体合同由工会代表职工与企业签订；没有建立工会的企业，由职工推举的代表与企业签订。 第三十四 集体合同签订后应当报送劳动行政部门；劳动行政部门自收到集体合同文本之日起十五日内未提出异议的，集体合同即行生效。 第三十五 依法签订的集体合同对企业和企业全体职工具有约束力。职工个人与企业订立的劳动合同中劳动条件和劳动报酬等标准不得低于集体合同的规定。 第四章 工作时间和休息休假 第三十六 国家实行劳动者每日工作时间不超过八小时、平均每周工作时间不超过四十四小时的工时制度。 第三十七 对实行计件工作的劳动者，用人单位应当根据本法第三十六条规定的工时制度合理确定其劳动定额和计件报酬标准。 第三十八条 用人单位应当保证劳动者每周至少休息一日。 第三十九 企业因生产特点不能实行本法第三十六条、第三十八条规定的，经劳动行政部门批准，可以实行其他工作和休息办法。 第四十条 用人单位在下列节日期间应当依法安排劳动者休假： （一）元旦； （二）春节； （三）国际劳动节； （四）国庆节； （五）法律、法规规定的其他休假节日。 第四十一 用人单位由于生产经营需要，经与工会和劳动者协商后可以延长工作时间，一般每日不得超过一小时；因特殊原因需要延长工作时间的，在保障劳动者身体健康的条件下延长工作时间每日不得超过三小时，但是每月不得超过三十六小时。 第四十二 有下列情形之一的，延长工作时间不受本法第四十一条规定的限制： （一）发生自然灾害、事故或者因其他原因，威胁劳动者生命健康和财产安全，需要紧急处理的； （二）生产设备、交通运输线路、公共设施发生故障，影响生产和公众利益，必须及时抢修的； （三）法律、行政法规规定的其他情形。 第四十三条 用人单位不得违反本法规定延长劳动者的工作时间。 第四十四 有下列情形之一的，用人单位应当按照下列标准支付高于劳动者正常工作时间工资的工资报酬： （一）安排劳动者延长工作时间的，支付不低于工资的百分之一百五十的工资报酬； （二）休息日安排劳动者工作又不能安排补休的，支付不低于工资的百分之二百的工资报酬； （三）法定休假日安排劳动者工作的，支付不低于工资的百分之三百的工资报酬。 第四十五条 国家实行带薪年休假制度。 劳动者连续工作一年以上的，享受带薪年休假。具体办法由国务院规定。 第五章 工资 第四十六条 工资分配应当遵循按劳分配原则，实行同工同酬。 工资水平在经济发展的基础上逐步提高。国家对工资总量实行宏观调控。 第四十七 用人单位根据本单位的生产经营特点和经济效益，依法自主确定本单位的工资分配方式和工资水平。 第四十八 国家实行最低工资保障制度。最低工资的具体标准由省、自治区、直辖市人民政府规定，报国务院备案。 用人单位支付劳动者的工资不得低于当地最低工资标准。 第四十九条 确定和调整最低工资标准应当综合参考下列因素： （一）劳动者本人及平均赡养人口的最低生活费用； （二）社会平均工资水平； （三）劳动生产率； （四）就业状况； （五）地区之间经济发展水平的差异。 第五十 工资应当以货币形式按月支付给劳动者本人。不得克扣或者无故拖欠劳动者的工资。 第五十一 劳动者在法定休假日和婚丧假期间以及依法参加社会活动期间，用人单位应当依法支付工资。 第六章 劳动安全卫生 第五十二 用人单位必须建立、健全劳动安全卫生制度，严格执行国家劳动安全卫生规程和标准，对劳动者进行劳动安全卫生教育，防止劳动过程中的事故，减少职业危害。 第五十三条 劳动安全卫生设施必须符合国家规定的标准。 新建、改建、扩建工程的劳动安全卫生设施必须与主体工程同时设计、同时施工、同时投入生产和使用。 第五十四 用人单位必须为劳动者提供符合国家规定的劳动安全卫生条件和必要的劳动防护用品，对从事有职业危害作业的劳动者应当定期进行健康检查。 第五十五 从事特种作业的劳动者必须经过专门培训并取得特种作业资格。 第五十六条 劳动者在劳动过程中必须严格遵守安全操作规程。 劳动者对用人单位管理人员违章指挥、强令冒险作业，有权拒绝执行；对危害生命安全和身体健康的行为，有权提出批评、检举和控告。 第五十七 国家建立伤亡事故和职业病统计报告和处理制度。县级以上各级人民政府劳动行政部门、有关部门和用人单位应当依法对劳动者在劳动过程中发生的伤亡事故和劳动者的职业病状况，进行统计、报告和处理。 第七章 女职工和未成年工特殊保护 第五十八条 国家对女职工和未成年工实行特殊劳动保护。 未成年工是指年满十六周岁未满十八周岁的劳动者。 第五十九 禁止安排女职工从事矿山井下、国家规定的第四级体力劳动强度的劳动和其他禁忌从事的劳动。 第六十 不得安排女职工在经期从事高处、低温、冷水作业和国家规定的第三级体力劳动强度的劳动。 第六十一 不得安排女职工在怀孕期间从事国家规定的第三级体力劳动强度的劳动和孕期禁忌从事的活动。对怀孕七个月以上的女职工，不得安排其延长工作时间和夜班劳动。 第六十二条 女职工生育享受不少于九十天的产假。 第六十三 不得安排女职工在哺乳未满一周岁的婴儿期间从事国家规定的第三级体力劳动强度的劳动和哺乳期禁忌从事的其他劳动，不得安排其延长工作时间和夜班劳动。 第六十四 不得安排未成年工从事矿山井下、有毒有害、国家规定的第四级体力劳动强度的劳动和其他禁忌从事的劳动。 第六十五条 用人单位应当对未成年工定期进行健康检查。 第八章 职业培训 第六十六 国家通过各种途径，采取各种措施，发展职业培训事业，开发劳动者的职业技能，提高劳动者素质，增强劳动者的就业能力和工作能力。 第六十七 各级人民政府应当把发展职业培训纳入社会经济发展的规划，鼓励和支持有条件的企业、事业组织、社会团体和个人进行各种形式的职业培训。 第六十八 用人单位应当建立职业培训制度，按照国家规定提取和使用职业培训经费，根据本单位实际，有计划地对劳动者进行职业培训。 从事技术工种的劳动者，上岗前必须经过培训。 第六十九 国家确定职业分类，对规定的职业制定职业技能标准，实行职业资格证书制度，由经过政府批准的考核鉴定机构负责对劳动者实施职业技能考核鉴定。 第九章 社会保险和福利 第七十 国家发展社会保险事业，建立社会保险制度，设立社会保险基金，使劳动者在年老、患病、工伤、失业、生育等情况下获得帮助和补偿。 第七十一 社会保险水平应当与社会经济发展水平和社会承受能力相适应。 第七十二 社会保险基金按照保险类型确定资金来源，逐步实行社会统筹。用人单位和劳动者必须依法参加社会保险，缴纳社会保险费。 第七十三条 劳动者在下列情形下，依法享受社会保险待遇： （一）退休； （二）患病、负伤； （三）因工伤残或者患职业病； （四）失业； （五）生育。 劳动者死亡后，其遗属依法享受遗属津贴。 劳动者享受社会保险待遇的条件和标准由法律、法规规定。 劳动者享受的社会保险金必须按时足额支付。 第七十四 社会保险基金经办机构依照法律规定收支、管理和运营社会保险基金，并负有使社会保险基金保值增值的责任。 社会保险基金监督机构依照法律规定，对社会保险基金的收支、管理和运营实施监督。 社会保险基金经办机构和社会保险基金监督机构的设立和职能由法律规定。 任何组织和个人不得挪用社会保险基金。 第七十五 国家鼓励用人单位根据本单位实际情况为劳动者建立补充保险。 国家提倡劳动者个人进行储蓄性保险。 第七十六 国家发展社会福利事业，兴建公共福利设施，为劳动者休息、休养和疗养提供条件。 用人单位应当创造条件，改善集体福利，提高劳动者的福利待遇。 第十章 劳动争议 第七十七 用人单位与劳动者发生劳动争议，当事人可以依法申请调解、仲裁、提起诉讼，也可以协商解决。 调解原则适用于仲裁和诉讼程序。 第七十八 解决劳动争议，应当根据合法、公正、及时处理的原则，依法维护劳动争议当事人的合法权益。 第七十九 劳动争议发生后，当事人可以向本单位劳动争议调解委员会申请调解；调解不成，当事人一方要求仲裁的，可以向劳动争议仲裁委员会申请仲裁。当事人一方也可以直接向劳动争议仲裁委员会申请仲裁。对仲裁裁决不服的，可以向人民法院提起诉讼。 第八十 在用人单位内，可以设立劳动争议调解委员会。劳动争议调解委员会由职工代表、用人单位代表和工会代表组成。劳动争议调解委员会主任由工会代表担任。 劳动争议经调解达成协议的，当事人应当履行。 第八十一 劳动争议仲裁委员会由劳动行政部门代表、同级工会代表、用人单位方面的代表组成。劳动争议仲裁委员会主任由劳动行政部门代表担任。 第八十二 提出仲裁要求的一方应当自劳动争议发生之日起六十日内向劳动争议仲裁委员会提出书面申请。仲裁裁决一般应在收到仲裁申请的六十日内作出。对仲裁裁决无异议的，当事人必须履行。 第八十三 劳动争议当事人对仲裁裁决不服的，可以自收到仲裁裁决书之日起十五日内向人民法院提起诉讼。一方当事人在法定期限内不起诉又不履行仲裁裁决的，另一方当事人可以申请人民法院强制执行。 第八十四 因签订集体合同发生争议，当事人协商解决不成的，当地人民政府劳动行政部门可以组织有关各方协调处理。 因履行集体合同发生争议，当事人协商解决不成的，可以向劳动争议仲裁委员会申请仲裁；对仲裁裁决不服的，可以自收到仲裁裁决书之日起十五日内向人民法院提起诉讼。 第十一章 监督检查 第八十五 县级以上各级人民政府劳动行政部门依法对用人单位遵守劳动法律、法规的情况进行监督检查，对违反劳动法律、法规的行为有权制止，并责令改正。 第八十六 县级以上各级人民政府劳动行政部门监督检查人员执行公务，有权进入用人单位了解执行劳动法律、法规的情况，查阅必要的资料，并对劳动场所进行检查。 县级以上各级人民政府劳动行政部门监督检查人员执行公务，必须出示证件，秉公执法并遵守有关规定。 第八十七 县级以上各级人民政府有关部门在各自职责范围内，对用人单位遵守劳动法律、法规的情况进行监督。 第八十八 各级工会依法维护劳动者的合法权益，对用人单位遵守劳动法律、法规的情况进行监督。 任何组织和个人对于违反劳动法律、法规的行为有权检举和控告。 第十二章 法律责任 第八十九 用人单位制定的劳动规章制度违反法律、法规规定的，由劳动行政部门给予警告，责令改正；对劳动者造成损害的，应当承担赔偿责任。 第九十 用人单位违反本法规定，延长劳动者工作时间的，由劳动行政部门给予警告，责令改正，并可以处以罚款。 第九十一 用人单位有下列侵害劳动者合法权益情形之一的，由劳动行政部门责令支付劳动者的工资报酬、经济补偿，并可以责令支付赔偿金： （一）克扣或者无故拖欠劳动者工资的； （二）拒不支付劳动者延长工作时间工资报酬的； （三）低于当地最低工资标准支付劳动者工资的； （四）解除劳动合同后，未依照本法规定给予劳动者经济补偿的。 第九十二 用人单位的劳动安全设施和劳动卫生条件不符合国家规定或者未向劳动者提供必要的劳动防护用品和劳动保护设施的，由劳动行政部门或者有关部门责令改正，可以处以罚款；情节严重的，提请县级以上人民政府决定责令停产整顿；对事故隐患不采取措施，致使发生重大事故，造成劳动者生命和财产损失的，对责任人员比照刑法第一百八十七条的规定追究刑事责任。 第九十三 用人单位强令劳动者违章冒险作业，发生重大伤亡事故，造成严重后果的，对责任人员依法追究刑事责任。 第九十四 用人单位非法招用未满十六周岁的未成年人的，由劳动行政部门责令改正，处以罚款；情节严重的，由工商行政管理部门吊销营业执照。 第九十五 用人单位违反本法对女职工和未成年工的保护规定，侵害其合法权益的，由劳动行政部门责令改正，处以罚款；对女职工或者未成年工造成损害的，应当承担赔偿责任。 第九十六 用人单位有下列行为之一，由公安机关对责任人员处以十五日以下拘留、罚款或者警告；构成犯罪的，对责任人员依法追究刑事责任： （一）以暴力、威胁或者非法限制人身自由的手段强迫劳动的； （二）侮辱、体罚、殴打、非法搜查和拘禁劳动者的。 第九十七 由于用人单位的原因订立的无效合同，对劳动者造成损害的，应当承担赔偿责任。 第九十八 用人单位违反本法规定的条件解除劳动合同或者故意拖延不订立劳动合同的，由劳动行政部门责令改正；对劳动者造成损害的，应当承担赔偿责任。 第九十九 用人单位招用尚未解除劳动合同的劳动者，对原用人单位造成经济损失的，该用人单位应当依法承担连带赔偿责任。 第一百 用人单位无故不缴纳社会保险费的，由劳动行政部门责令其限期缴纳；逾期不缴的，可以加收滞纳金。 第一百零一 用人单位无理阻挠劳动行政部门、有关部门及其工作人员行使监督检查权，打击报复举报人员的，由劳动行政部门或者有关部门处以罚款；构成犯罪的，对责任人员依法追究刑事责任。 第一百零二 劳动者违反本法规定的条件解除劳动合同或者违反劳动合同中约定的保密事项，对用人单位造成经济损失的，应当依法承担赔偿责任。 第一百零三 劳动行政部门或者有关部门的工作人员滥用职权、玩忽职守、徇私舞弊，构成犯罪的，依法追究刑事责任；不构成犯罪的，给予行政处分。 第一百零四 国家工作人员和社会保险基金经办机构的工作人员挪用社会保险基金，构成犯罪的，依法追究刑事责任。 第一百零五 违反本法规定侵害劳动者合法权益，其他法律、行政法规已规定处罚的，依照该法律、行政法规的规定处罚。 第十三章 附则 第一百零六 省、自治区、直辖市人民政府根据本法和本地区的实际情况，规定劳动合同制度的实施步骤，报国务院备案。 第一百零七条 本法自１９９５年１月１日起施行","link":"/2019/08/21/中华人民共和国劳动法.html"},{"title":"中华人民共和国婚姻法","text":"基本信息 效力级别法律：时效性现行有效 发布日期：2001-04-28 实施日期：2001-04-28 发布机关：全国人大常委会 法律修订 １９８０年９月１０日第五届全国人民代表大会第三次会议通过 根据２００１年４月２８日第九届全国人民代表大会常务委员会第二十一次会议《关于修改〈中华人民共和国婚姻法〉的决定》修正 中华人民共和国婚姻法（1980修正） 中华人民共和国婚姻法（1950修正） 正文 第一章 总则第一条 立法目的 本法是婚姻家庭关系的基本准则。 第二条 婚姻制度 实行婚姻自由、一夫一妻、男女平等的婚姻制度。 保护妇女、儿童和老人的合法权益。 实行计划生育。 第三条 禁止的婚姻行为 禁止包办、买卖婚姻和其他干涉婚姻自由的行为。禁止借婚姻索取财物。 禁止重婚。禁止有配偶者与他人同居。禁止家庭暴力。禁止家庭成员间的虐待和遗弃。 第四条 家庭关系 夫妻应当互相忠实，互相尊重；家庭成员间应当敬老爱幼，互相帮助，维护平等、和睦、文明的婚姻家庭关系。 第二章 结婚第五条 结婚自愿 结婚必须男女双方完全自愿，不许任何一方对他方加以强迫或任何第三者加以干涉。 第六条 法定婚龄 结婚年龄，男不得早于二十二周岁，女不得早于二十周岁。晚婚晚育应予鼓励。 第七条 禁止结婚 有下列情形之一的，禁止结婚： （一）直系血亲和三代以内的旁系血亲； （二）患有医学上认为不应当结婚的疾病。 第八条 结婚登记 要求结婚的男女双方必须亲自到婚姻登记机关进行结婚登记。符合本法规定的，予以登记，发给结婚证。取得结婚证，即确立夫妻关系。未办理结婚登记的，应当补办登记。 第九条 互为家庭成员 登记结婚后，根据男女双方约定，女方可以成为男方家庭的成员，男方可以成为女方家庭的成员。 第十条 婚姻无效 有下列情形之一的，婚姻无效： （一）重婚的； （二）有禁止结婚的亲属关系的； （三）婚前患有医学上认为不应当结婚的疾病，婚后尚未治愈的； （四）未到法定婚龄的。 第十一条 胁迫结婚 因胁迫结婚的，受胁迫的一方可以向婚姻登记机关或人民法院请求撤销该婚姻。受胁迫的一方撤销婚姻的请求，应当自结婚登记之日起一年内提出。被非法限制人身自由的当事人请求撤销婚姻的，应当自恢复人身自由之日起一年内提出。 第十二条 婚姻的无效 无效或被撤销的婚姻，自始无效。当事人不具有夫妻的权利和义务。同居期间所得的财产，由当事人协议处理；协议不成时，由人民法院根据照顾无过错方的原则判决。对重婚导致的婚姻无效的财产处理，不得侵害合法婚姻当事人的财产权益。当事人所生的子女，适用本法有关父母子女的规定。 第三章 家庭关系第十三条 夫妻平等 夫妻在家庭中地位平等。 第十四条 夫妻姓名权 夫妻双方都有各用自己姓名的权利。 第十五条 夫妻的自由 夫妻双方都有参加生产、工作、学习和社会活动的自由，一方不得对他方加以限制或干涉。 第十六条 计划生育义务 夫妻双方都有实行计划生育的义务。 第十七条 夫妻共有财产 夫妻在婚姻关系存续期间所得的下列财产，归夫妻共同所有： （一）工资、奖金； （二）生产、经营的收益； （三）知识产权的收益； （四）继承或赠与所得的财产，但本法第十八条第三项规定的除外； （五）其他应当归共同所有的财产。 夫妻对共同所有的财产，有平等的处理权。 第十八条 夫妻一方的财产 有下列情形之一的，为夫妻一方的财产： （一）一方的婚前财产； （二）一方因身体受到伤害获得的医疗费、残疾人生活补助费等费用； （三）遗嘱或赠与合同中确定只归夫或妻一方的财产； （四）一方专用的生活用品； （五）其他应当归一方的财产。 第十九条 夫妻财产约定 夫妻可以约定婚姻关系存续期间所得的财产以及婚前财产归各自所有、共同所有或部分各自所有、部分共同所有。约定应当采用书面形式。没有约定或约定不明确的，适用本法第十七条、第十八条的规定。 夫妻对婚姻关系存续期间所得的财产以及婚前财产的约定，对双方具有约束力。 夫妻对婚姻关系存续期间所得的财产约定归各自所有的，夫或妻一方对外所负的债务，第三人知道该约定的，以夫或妻一方所有的财产清偿。 第二十条 夫妻扶养义务 夫妻有互相扶养的义务。 一方不履行扶养义务时，需要扶养的一方，有要求对方付给扶养费的权利。 第二十一条 父母与子女 父母对子女有抚养教育的义务；子女对父母有赡养扶助的义务。 父母不履行抚养义务时，未成年的或不能独立生活的子女，有要求父母付给抚养费的权利。 子女不履行赡养义务时，无劳动能力的或生活困难的父母，有要求子女付给赡养费的权利。 禁止溺婴、弃婴和其他残害婴儿的行为。 第二十二条 子女的姓 子女可以随父姓，可以随母姓。 第二十三条 父母对子女的保护和教育 父母有保护和教育未成年子女的权利和义务。在未成年子女对国家、集体或他人造成损害时，父母有承担民事责任的义务。 第二十四条 继承遗产 夫妻有相互继承遗产的权利。 父母和子女有相互继承遗产的权利。 第二十五条 非婚生子女 非婚生子女享有与婚生子女同等的权利，任何人不得加以危害和歧视。 不直接抚养非婚生子女的生父或生母，应当负担子女的生活费和教育费，直至子女能独立生活为止。 第二十六条 收养关系 国家保护合法的收养关系。养父母和养子女间的权利和义务，适用本法对父母子女关系的有关规定。 养子女和生父母间的权利和义务，因收养关系的成立而消除。 第二十七条 继父母与继子女 继父母与继子女间，不得虐待或歧视。 继父或继母和受其抚养教育的继子女间的权利和义务，适用本法对父母子女关系的有关规定。 第二十八条 祖与孙 有负担能力的祖父母、外祖父母，对于父母已经死亡或父母无力抚养的未成年的孙子女、外孙子女，有抚养的义务。有负担能力的孙子女、外孙子女，对于子女已经死亡或子女无力赡养的祖父母、外祖父母，有赡养的义务。 第二十九条 兄姐与弟妹 有负担能力的兄、姐，对于父母已经死亡或父母无力抚养的未成年的弟、妹，有扶养的义务。由兄、姐扶养长大的有负担能力的弟、妹，对于缺乏劳动能力又缺乏生活来源的兄、姐，有扶养的义务。 第三十条 尊重父母婚姻 子女应当尊重父母的婚姻权利，不得干涉父母再婚以及婚后的生活。子女对父母的赡养义务，不因父母的婚姻关系变化而终止。 第四章 离婚第三十一条 自愿离婚 男女双方自愿离婚的，准予离婚。双方必须到婚姻登记机关申请离婚。婚姻登记机关查明双方确实是自愿并对子女和财产问题已有适当处理时，发给离婚证。 第三十二条 离婚诉讼 男女一方要求离婚的，可由有关部门进行调解或直接向人民法院提出离婚诉讼。 人民法院审理离婚案件，应当进行调解；如感情确已破裂，调解无效，应准予离婚。 有下列情形之一，调解无效的，应准予离婚： （一）重婚或有配偶者与他人同居的； （二）实施家庭暴力或虐待、遗弃家庭成员的； （三）有赌博、吸毒等恶习屡教不改的； （四）因感情不和分居满二年的； （五）其他导致夫妻感情破裂的情形。 一方被宣告失踪，另一方提出离婚诉讼的，应准予离婚。 第三十三条 军人配偶要求离婚 现役军人的配偶要求离婚，须得军人同意，但军人一方有重大过错的除外。 第三十四条 不得提出离婚 女方在怀孕期间、分娩后一年内或中止妊娠后六个月内，男方不得提出离婚。女方提出离婚的，或人民法院认为确有必要受理男方离婚请求的，不在此限。 第三十五条 复婚 离婚后，男女双方自愿恢复夫妻关系的，必须到婚姻登记机关进行复婚登记。 第三十六条 离婚与子女 父母与子女间的关系，不因父母离婚而消除。离婚后，子女无论由父或母直接抚养，仍是父母双方的子女。 离婚后，父母对于子女仍有抚养和教育的权利和义务。 离婚后，哺乳期内的子女，以随哺乳的母亲抚养为原则。哺乳期后的子女，如双方因抚养问题发生争执不能达成协议时，由人民法院根据子女的权益和双方的具体情况判决。 第三十七条 离婚后的子女抚养 离婚后，一方抚养的子女，另一方应负担必要的生活费和教育费的一部或全部，负担费用的多少和期限的长短，由双方协议；协议不成时，由人民法院判决。 关于子女生活费和教育费的协议或判决，不妨碍子女在必要时向父母任何一方提出超过协议或判决原定数额的合理要求。 第三十八条 离婚后的子女探望 离婚后，不直接抚养子女的父或母，有探望子女的权利，另一方有协助的义务。 行使探望权利的方式、时间由当事人协议；协议不成时，由人民法院判决。 父或母探望子女，不利于子女身心健康的，由人民法院依法中止探望的权利；中止的事由消失后，应当恢复探望的权利。 第三十九条 夫妻共同财产的离婚处理 离婚时，夫妻的共同财产由双方协议处理；协议不成时，由人民法院根据财产的具体情况，照顾子女和女方权益的原则判决。 夫或妻在家庭土地承包经营中享有的权益等，应当依法予以保护。 第四十条 补偿 夫妻书面约定婚姻关系存续期间所得的财产归各自所有，一方因抚育子女、照料老人、协助另一方工作等付出较多义务的，离婚时有权向另一方请求补偿，另一方应当予以补偿。 第四十一条 共同债务 离婚时，原为夫妻共同生活所负的债务，应当共同偿还。共同财产不足清偿的，或财产归各自所有的，由双方协议清偿；协议不成时，由人民法院判决。 第四十二条 适当帮助 离婚时，如一方生活困难，另一方应从其住房等个人财产中给予适当帮助。具体办法由双方协议；协议不成时，由人民法院判决。 第五章 救助措施与法律责任第四十三条 家庭暴力与虐待 实施家庭暴力或虐待家庭成员，受害人有权提出请求，居民委员会、村民委员会以及所在单位应当予以劝阻、调解。 对正在实施的家庭暴力，受害人有权提出请求，居民委员会、村民委员会应当予以劝阻；公安机关应当予以制止。 实施家庭暴力或虐待家庭成员，受害人提出请求的，公安机关应当依照治安管理处罚的法律规定予以行政处罚。 第四十四条 遗弃 对遗弃家庭成员，受害人有权提出请求，居民委员会、村民委员会以及所在单位应当予以劝阻、调解。 对遗弃家庭成员，受害人提出请求的，人民法院应当依法作出支付扶养费、抚养费、赡养费的判决。 第四十五条 家庭暴力、虐待、遗弃犯罪 对重婚的，对实施家庭暴力或虐待、遗弃家庭成员构成犯罪的，依法追究刑事责任。受害人可以依照刑事诉讼法的有关规定，向人民法院自诉；公安机关应当依法侦查，人民检察院应当依法提起公诉。 第四十六条 损害赔偿 有下列情形之一，导致离婚的，无过错方有权请求损害赔偿： （一）重婚的； （二）有配偶者与他人同居的； （三）实施家庭暴力的； （四）虐待、遗弃家庭成员的。 第四十七条 隐藏、转移共同财产等 离婚时，一方隐藏、转移、变卖、毁损夫妻共同财产，或伪造债务企图侵占另一方财产的，分割夫妻共同财产时，对隐藏、转移、变卖、毁损夫妻共同财产或伪造债务的一方，可以少分或不分。离婚后，另一方发现有上述行为的，可以向人民法院提起诉讼，请求再次分割夫妻共同财产。 人民法院对前款规定的妨害民事诉讼的行为，依照民事诉讼法的规定予以制裁。 第四十八条 强制执行 对拒不执行有关扶养费、抚养费、赡养费、财产分割、遗产继承、探望子女等判决或裁定的，由人民法院依法强制执行。有关个人和单位应负协助执行的责任。 第四十九条 婚姻家庭的其他违法 其他法律对有关婚姻家庭的违法行为和法律责任另有规定的，依照其规定。 第六章 附则第五十条 变通规定 民族自治地方的人民代表大会有权结合当地民族婚姻家庭的具体情况，制定变通规定。自治州、自治县制定的变通规定，报省、自治区、直辖市人民代表大会常务委员会批准后生效。自治区制定的变通规定，报全国人民代表大会常务委员会批准后生效。","link":"/2019/08/21/中华人民共和国婚姻法.html"},{"title":"mysql高性能优化规范方法","text":"数据库命令规范 所有数据库对象名称必须使用小写字母并用下划线分割 所有数据库对象名称禁止使用mysql保留关键字（如果表名中包含关键字查询时，需要将其用单引号括起来） 数据库对象的命名要能做到见名识意，并且最后不要超过32个字符 临时库表必须以tmp_为前缀并以日期为后缀，备份表必须以bak_为前缀并以日期(时间戳)为后缀 所有存储相同数据的列名和列类型必须一致（一般作为关联列，如果查询时关联列类型不一致会自动进行数据类型隐式转换，会造成列上的索引失效，导致查询效率降低） 数据库基本设计规范所有表必须使用Innodb存储引擎没有特殊要求（即Innodb无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用Innodb存储引擎（mysql5.5之前默认使用Myisam，5.6以后默认的为Innodb）。 Innodb 支持事务，支持行级锁，更好的恢复性，高并发下性能更好。 数据库和表的字符集统一使用UTF8兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效，如果数据库中有存储emoji表情的需要，字符集需要采用utf8mb4字符集。 所有表和字段都需要添加注释使用comment从句添加表和列的备注，从一开始就进行数据字典的维护 尽量控制单表数据量的大小，建议控制在500万以内。500万并不是Mysql数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。 可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小 谨慎使用Mysql分区表分区表在物理上表现为多个文件，在逻辑上表现为一个表； 谨慎选择分区键，跨分区查询效率可能更低； 建议采用物理分表的方式管理大数据。 尽量做到冷热数据分离，减小表的宽度Mysql限制每个表最多存储4096列，并且每一行数据的大小不能超过65535字节。 减少磁盘IO,保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的IO）； 更有效的利用缓存，避免读入无用的冷数据； 经常一起使用的列放到一个表中（避免更多的关联操作）。 禁止在表中建立预留字段预留字段的命名很难做到见名识义。 预留字段无法确认存储的数据类型，所以无法选择合适的类型。 对预留字段类型的修改，会对表进行锁定。 禁止在数据库中存储图片，文件等大的二进制数据通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机IO操作，文件很大时，IO操作很耗时。 通常存储于文件服务器，数据库只存储文件地址信息 禁止在线上做数据库压力测试禁止从开发环境，测试环境直接连接生产环境数据库 数据库字段设计规范优先选择符合存储需要的最小的数据类型原因： 列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少也越少，在遍历时所需要的IO次数也就越多，索引的性能也就越差。 方法： 将字符串转换成数字类型存储，如：将IP地址转换成整形数据mysql提供了两个方法来处理ip地址 inet_aton 把ip转为无符号整型(4-8位) inet_ntoa 把整型的ip转为地址 插入数据前，先用inet_aton把ip地址转为整型，可以节省空间，显示数据时，使用inet_ntoa把整型的ip地址转为地址显示即可。 对于非负型的数据（如自增ID、整型IP）来说，要优先使用无符号整型来存储原因： 无符号相对于有符号可以多出一倍的存储空间 12SIGNED INT -2147483648~2147483647UNSIGNED INT 0~4294967295 VARCHAR(N)中的N代表的是字符数，而不是字节数，使用UTF8存储255个汉字 Varchar(255)=765个字节。过大的长度会消耗更多的内存。 避免使用TEXT、BLOB数据类型，最常见的TEXT类型可以存储64k的数据建议把BLOB或是TEXT列分离到单独的扩展表中Mysql内存临时表不支持TEXT、BLOB这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，Mysql还是要进行二次查询，会使sql性能变得很差，但是不是说一定不能使用这样的数据类型。 如果一定要使用，建议把BLOB或是TEXT列分离到单独的扩展表中，查询时一定不要使用select * 而只需要取出必要的列，不需要TEXT列的数据时不要对该列进行查询。 TEXT或BLOB类型只能使用前缀索引因为MySQL对索引字段长度是有限制的，所以TEXT类型只能使用前缀索引，并且TEXT列上是不能有默认值的 避免使用ENUM类型修改ENUM值需要使用ALTER语句 ENUM类型的ORDER BY操作效率低，需要额外操作 禁止使用数值作为ENUM的枚举值 尽可能把所有列定义为NOT NULL原因： 索引NULL列需要额外的空间来保存，所以要占用更多的空间 进行比较和计算时要对NULL值做特别的处理 使用TIMESTAMP（4个字节）或DATETIME类型（8个字节）存储时间TIMESTAMP 存储的时间范围 1970-01-01 00:00:01 ~ 2038-01-19-03:14:07 TIMESTAMP 占用4字节和INT相同，但比INT可读性高 超出TIMESTAMP取值范围的使用DATETIME类型存储 经常会有人用字符串存储日期型的数据（不正确的做法） 缺点1：无法用日期函数进行计算和比较 缺点2：用字符串存储日期要占用更多的空间 同财务相关的金额类数据必须使用decimal类型 非精准浮点：float,double 精准浮点：decimal Decimal类型为精准浮点数，在计算时不会丢失精度 占用空间由定义的宽度决定，每4个字节可以存储9位数字，并且小数点要占用一个字节 可用于存储比bigint更大的整型数据 索引设计规范限制每张表上的索引数量，建议单张表索引不超过5个索引并不是越多越好！索引可以提高效率同样可以降低效率。 索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。 因为mysql优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加mysql优化器生成执行计划的时间，同样会降低查询性能。 禁止给表中的每一列都建立单独的索引5.6版本之前，一个sql只能使用到一个表中的一个索引，5.6以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好。 每个Innodb表必须有个主键Innodb是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。 Innodb是按照主键索引的顺序来组织表的 不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引） 不要使用UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长） 主键建议使用自增ID值 常见索引列建议 出现在SELECT、UPDATE、DELETE语句的WHERE从句中的列 包含在ORDER BY、GROUP BY、DISTINCT中的字段 并不要将符合1和2中的字段的列都建立一个索引， 通常将1、2中的字段建立联合索引效果更好 多表join的关联列 如何选择索引列的顺序建立索引的目的是：希望通过索引进行数据查找，减少随机IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。 区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数） 尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO性能也就越好） 使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引） 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间） 重复索引示例：primary key(id)、index(id)、unique index(id) 冗余索引示例：index(a,b,c)、index(a,b)、index(a) 对于频繁的查询优先考虑使用覆盖索引覆盖索引：就是包含了所有查询字段(where,select,ordery by,group by包含的字段)的索引 覆盖索引的好处： 避免Innodb表进行索引的二次查询Innodb是以聚集索引的顺序来存储的，对于Innodb来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。 而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了IO操作，提升了查询效率。 可以把随机IO变成顺序IO加快查询效率由于覆盖索引是按键值的顺序存储的，对于IO密集型的范围查找来说，对比随机从磁盘读取每一行的数据IO要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的IO转变成索引查找的顺序IO。 索引SET规范尽量避免使用外键约束 不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引 外键可用于保证数据的参照完整性，但建议在业务端实现 外键会影响父表和子表的写操作从而降低性能 数据库SQL开发规范建议使用预编译语句进行数据库操作预编译语句可以重复使用这些计划，减少SQL编译所需要的时间，还可以解决动态SQL所带来的SQL注入的问题。 只传参数，比传递SQL语句更高效。 相同语句可以一次解析，多次使用，提高处理效率。 避免数据类型的隐式转换隐式转换会导致索引失效如: 1select name,phone from customer where id = '111'; 充分利用表上已经存在的索引s避免使用双%号的查询条件。如：a like '%123%'，（如果无前置%,只有后置%，是可以用到列上的索引的） 一个SQL只能利用到复合索引中的一列进行范围查询。如：有 a,b,c列的联合索引，在查询条件中有a列的范围查询，则在b,c列上的索引将不会被用到。 在定义联合索引时，如果a列要用到范围查找的话，就要把a列放到联合索引的右侧，使用left join 或 not exists来优化not in 操作，因为not in 也通常会使用索引失效。 数据库设计时，应该要对以后扩展进行考虑程序连接不同的数据库使用不同的账号，进制跨库查询 为数据库迁移和分库分表留出余地 降低业务耦合度 避免权限过大而产生的安全风险 禁止使用SELECT * 必须使用SELECT &lt;字段列表&gt; 查询原因： 消耗更多的CPU和IO以网络带宽资源 无法使用覆盖索引 可减少表结构变更带来的影响 禁止使用不含字段列表的INSERT语句如： 1insert into values ('a','b','c'); 应使用： 1insert into t(c1,c2,c3) values ('a','b','c'); 避免使用子查询，可以把子查询优化为join操作通常子查询在in子句中，且b中为简单SQL(不包含union、group by、order by、limit从句)时,才可以把子查询转化为关联查询进行优化。 子查询性能差的原因： 子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大。 由于子查询会产生大量的临时表也没有索引，所以会消耗过多的CPU和IO资源，产生大量的慢查询。 避免使用JOIN关联太多的表对于Mysql来说，是存在关联缓存的，缓存的大小可以由join_buffer_size参数进行设置。 在Mysql中，对于同一个SQL多关联（join）一个表，就会多分配一个关联缓存，如果在一个SQL中关联的表越多，所占用的内存也就越大。 如果程序中大量的使用了多表关联的操作，同时join_buffer_size设置的也不合理的情况下，就容易造成服务器内存溢出的情况，就会影响到服务器数据库性能的稳定性。 同时对于关联操作来说，会产生临时表操作，影响查询效率，Mysql最多允许关联61个表，建议不超过5个。 减少同数据库的交互次数数据库更适合处理批量操作，合并多个相同的操作到一起，可以提高处理效率。 对应同一列进行or判断时，使用in代替orin 的值不要超过500个，in 操作可以更有效的利用索引，or大多数情况下很少能利用到索引。 禁止使用order by rand() 进行随机排序order by rand()会把表中所有符合条件的数据装载到内存中，然后在内存中对所有数据根据随机生成的值进行排序，并且可能会对每一行都生成一个随机值，如果满足条件的数据集非常大，就会消耗大量的CPU和IO及内存资源。 推荐在程序中获取一个随机值，然后从数据库中获取数据的方式。 WHERE从句中禁止对列进行函数转换和计算对列进行函数转换或计算时会导致无法使用索引 不推荐： 1where date(create_time)='20190101' 推荐： 1where create_time &gt;= '20190101' and create_time &lt; '20190102' 在明显不会有重复值时使用UNION ALL 而不是UNION UNION 会把两个结果集的所有数据放到临时表中后再进行去重操作 UNION ALL 不会再对结果集进行去重操作 拆分复杂的大SQL为多个小SQL 大SQL逻辑上比较复杂，需要占用大量CPU进行计算的SQL MySQL中，一个SQL只能使用一个CPU进行计算 SQL拆分后可以通过并行执行来提高处理效率 数据库操作行为规范超100万行的批量写（UPDATE、DELETE、INSERT）操作，要分批多次进行操作大批量操作可能会造成严重的主从延迟 主从环境中,大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间，而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况 binlog日志为row格式时会产生大量的日志 大批量写操作会产生大量日志，特别是对于row格式二进制数据而言，由于在row格式中会记录每一行数据的修改，我们一次修改的数据越多，产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因。 避免产生大事务操作 大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对MySQL的性能产生非常大的影响。 特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批 对于大表使用pt-online-schema-change修改表结构 避免大表修改产生的主从延迟 避免在对表字段进行修改时进行锁表 对大表数据结构的修改一定要谨慎，会造成严重的锁表操作，尤其是生产环境，是不能容忍的。 pt-online-schema-change它会首先建立一个与原表结构相同的新表，并且在新表上进行表结构的修改，然后再把原表中的数据复制到新表中，并在原表中增加一些触发器。把原表中新增的数据也复制到新表中，在行所有数据复制完成之后，把新表命名成原表，并把原来的表删除掉。把原来一个DDL操作，分解成多个小的批次进行。 禁止为程序使用的账号赋予super权限 当达到最大连接数限制时，还运行1个有super权限的用户连接 super权限只能留给DBA处理问题的账号使用 对于程序连接数据库账号，遵循权限最小原则 程序使用数据库账号只能在一个DB下使用，不准跨库 程序使用的账号原则上不准有drop权限 文章来源 .","link":"/2019/08/21/mysql高性能优化规范方法.html"},{"title":"Java容器集合","text":"容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对（两个对象）的映射表。 概览容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对（两个对象）的映射表。 Collection 1. Set TreeSet：基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。 HashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。 LinkedHashSet：具有 HashSet 的查找效率，且内部使用双向链表维护元素的插入顺序。 2. List ArrayList：基于动态数组实现，支持随机访问。 Vector：和 ArrayList 类似，但它是线程安全的。 LinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。 3. Queue LinkedList：可以用它来实现双向队列。 PriorityQueue：基于堆结构实现，可以用它来实现优先队列。 Map TreeMap：基于红黑树实现。 HashMap：基于哈希表实现。 HashTable：和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程可以同时写入 HashTable 并且不会导致数据不一致。它是遗留类，不应该去使用它。现在可以使用 ConcurrentHashMap 来支持线程安全，并且 ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。 LinkedHashMap：使用双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。 容器中的设计模式迭代器模式 Collection 继承了 Iterable 接口，其中的 iterator() 方法能够产生一个 Iterator 对象，通过这个对象就可以迭代遍历 Collection 中的元素。 从 JDK 1.5 之后可以使用 foreach 方法来遍历实现了 Iterable 接口的聚合对象。 123456List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(\"a\");list.add(\"b\");for (String item : list) { System.out.println(item);} 适配器模式java.util.Arrays#asList() 可以把数组类型转换为 List 类型。 12@SafeVarargspublic static &lt;T&gt; List&lt;T&gt; asList(T... a) 应该注意的是 asList() 的参数为泛型的变长参数，不能使用基本类型数组作为参数，只能使用相应的包装类型数组。 12Integer[] arr = {1, 2, 3};List list = Arrays.asList(arr); 也可以使用以下方式调用 asList()： 1List list = Arrays.asList(1, 2, 3); 源码分析如果没有特别说明，以下源码分析基于 JDK 1.8。 在 IDEA 中 double shift 调出 Search EveryWhere，查找源码文件，找到之后就可以阅读源码。 ArrayList1. 概览因为 ArrayList 是基于数组实现的，所以支持快速随机访问。RandomAccess 接口标识着该类支持快速随机访问。 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 数组的默认大小为 10。 1private static final int DEFAULT_CAPACITY = 10; 2. 扩容添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)，也就是旧容量的 1.5 倍。 扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。 12345678910111213141516171819202122232425262728293031public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;}private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity);}private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);}private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);} 3. 删除元素需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，可以看出 ArrayList 删除元素的代价是非常高的。 12345678910public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;} 4. Fail-FastmodCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。 在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。 123456789101112131415161718private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{ // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) { s.writeObject(elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); }} 5. 序列化ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。 保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。 1transient Object[] elementData; // non-private to simplify nested class access ArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。 123456789101112131415161718192021222324252627282930313233343536373839private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) { // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) { a[i] = s.readObject(); } }}private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{ // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) { s.writeObject(elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); }} 序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。 123ArrayList list = new ArrayList();ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file));oos.writeObject(list); Vector1. 同步它的实现与 ArrayList 类似，但是使用了 synchronized 进行同步。 12345678910111213public synchronized boolean add(E e) { modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;}public synchronized E get(int index) { if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);} 2. 与 ArrayList 的比较 Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制； Vector 每次扩容请求其大小的 2 倍空间，而 ArrayList 是 1.5 倍。 3. 替代方案可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList。 12List&lt;String&gt; list = new ArrayList&lt;&gt;();List&lt;String&gt; synList = Collections.synchronizedList(list); 也可以使用 concurrent 并发包下的 CopyOnWriteArrayList 类。 1List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); CopyOnWriteArrayList读写分离写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响。 写操作需要加锁，防止并发写入时导致写入数据丢失。 写操作结束之后需要把原始数组指向新的复制数组。 12345678910111213141516171819202122public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; } finally { lock.unlock(); }}final void setArray(Object[] a) { array = a;}@SuppressWarnings(\"unchecked\")private E get(Object[] a, int index) { return (E) a[index];} 适用场景CopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。 但是 CopyOnWriteArrayList 有其缺陷： 内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右； 数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中。 所以 CopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景。 LinkedList1. 概览基于双向链表实现，使用 Node 存储链表节点信息。 12345private static class Node&lt;E&gt; { E item; Node&lt;E&gt; next; Node&lt;E&gt; prev;} 每个链表存储了 first 和 last 指针： 12transient Node&lt;E&gt; first;transient Node&lt;E&gt; last; 2. 与 ArrayList 的比较 ArrayList 基于动态数组实现，LinkedList 基于双向链表实现； ArrayList 支持随机访问，LinkedList 不支持； LinkedList 在任意位置添加删除元素更快。 HashMap为了便于理解，以下源码分析以 JDK 1.7 为主。 1. 存储结构内部包含了一个 Entry 类型的数组 table。 1transient Entry[] table; Entry 存储着键值对。它包含了四个字段，从 next 字段我们可以看出 Entry 是一个链表。即数组中的每个位置被当成一个桶，一个桶存放一个链表。HashMap 使用拉链法来解决冲突，同一个链表中存放哈希值和散列桶取模运算结果相同的 Entry。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final K key; V value; Entry&lt;K,V&gt; next; int hash; Entry(int h, K k, V v, Entry&lt;K,V&gt; n) { value = v; next = n; key = k; hash = h; } public final K getKey() { return key; } public final V getValue() { return value; } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) { Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; } return false; } public final int hashCode() { return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); } public final String toString() { return getKey() + \"=\" + getValue(); }} 2. 拉链法的工作原理1234HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put(\"K1\", \"V1\");map.put(\"K2\", \"V2\");map.put(\"K3\", \"V3\"); 新建一个 HashMap，默认大小为 16； 插入 &lt;K1,V1&gt; 键值对，先计算 K1 的 hashCode 为 115，使用除留余数法得到所在的桶下标 115%16=3。 插入 &lt;K2,V2&gt; 键值对，先计算 K2 的 hashCode 为 118，使用除留余数法得到所在的桶下标 118%16=6。 插入 &lt;K3,V3&gt; 键值对，先计算 K3 的 hashCode 为 118，使用除留余数法得到所在的桶下标 118%16=6，插在 &lt;K2,V2&gt; 前面。 应该注意到链表的插入是以头插法方式进行的，例如上面的 &lt;K3,V3&gt; 不是插在 &lt;K2,V2&gt; 后面，而是插入在链表头部。 查找需要分成两步进行： 计算键值对所在的桶； 在链表上顺序查找，时间复杂度显然和链表的长度成正比。 3. put 操作1234567891011121314151617181920212223242526public V put(K key, V value) { if (table == EMPTY_TABLE) { inflateTable(threshold); } // 键为 null 单独处理 if (key == null) return putForNullKey(value); int hash = hash(key); // 确定桶下标 int i = indexFor(hash, table.length); // 先找出是否已经存在键为 key 的键值对，如果存在的话就更新这个键值对的值为 value for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; // 插入新键值对 addEntry(hash, key, value, i); return null;} HashMap 允许插入键为 null 的键值对。但是因为无法调用 null 的 hashCode() 方法，也就无法确定该键值对的桶下标，只能通过强制指定一个桶下标来存放。HashMap 使用第 0 个桶存放键为 null 的键值对。 12345678910111213private V putForNullKey(V value) { for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) { if (e.key == null) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(0, null, value, 0); return null;} 使用链表的头插法，也就是新的键值对插在链表的头部，而不是链表的尾部。 12345678910111213141516171819202122void addEntry(int hash, K key, V value, int bucketIndex) { if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex);}void createEntry(int hash, K key, V value, int bucketIndex) { Entry&lt;K,V&gt; e = table[bucketIndex]; // 头插法，链表头部指向新的键值对 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;}Entry(int h, K k, V v, Entry&lt;K,V&gt; n) { value = v; next = n; key = k; hash = h;} 4. 确定桶下标很多操作都需要先确定一个键值对所在的桶下标。 12int hash = hash(key);int i = indexFor(hash, table.length); 4.1 计算 hash 值 1234567891011121314151617final int hash(Object k) { int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) { return sun.misc.Hashing.stringHash32((String) k); } h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);}public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value);} 4.2 取模 令 x = 1&lt;&lt;4，即 x 为 2 的 4 次方，它具有以下性质： 12x : 00010000x-1 : 00001111 令一个数 y 与 x-1 做与运算，可以去除 y 位级表示的第 4 位以上数： 123y : 10110010x-1 : 00001111y&amp;(x-1) : 00000010 这个性质和 y 对 x 取模效果是一样的： 123y : 10110010x : 00010000y%x : 00000010 我们知道，位运算的代价比求模运算小的多，因此在进行这种计算时用位运算的话能带来更高的性能。 确定桶下标的最后一步是将 key 的 hash 值对桶个数取模：hash%capacity，如果能保证 capacity 为 2 的 n 次方，那么就可以将这个操作转换为位运算。 123static int indexFor(int h, int length) { return h &amp; (length-1);} 5. 扩容-基本原理设 HashMap 的 table 长度为 M，需要存储的键值对数量为 N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为 N/M，因此平均查找次数的复杂度为 O(N/M)。 为了让查找的成本降低，应该尽可能使得 N/M 尽可能小，因此需要保证 M 尽可能大，也就是说 table 要尽可能大。HashMap 采用动态扩容来根据当前的 N 值来调整 M 值，使得空间效率和时间效率都能得到保证。 和扩容相关的参数主要有：capacity、size、threshold 和 load_factor。 参数 含义 capacity table 的容量大小，默认为 16。需要注意的是 capacity 必须保证为 2 的 n 次方。 size 键值对数量。 threshold size 的临界值，当 size 大于等于 threshold 就必须进行扩容操作。 loadFactor 装载因子，table 能够使用的比例，threshold = capacity * loadFactor。 123456789101112131415static final int DEFAULT_INITIAL_CAPACITY = 16;static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;transient Entry[] table;transient int size;int threshold;final float loadFactor;transient int modCount; 从下面的添加元素代码中可以看出，当需要扩容时，令 capacity 为原来的两倍。 123456void addEntry(int hash, K key, V value, int bucketIndex) { Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); if (size++ &gt;= threshold) resize(2 * table.length);} 扩容使用 resize() 实现，需要注意的是，扩容操作同样需要把 oldTable 的所有键值对重新插入 newTable 中，因此这一步是很费时的。 123456789101112131415161718192021222324252627282930void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);}void transfer(Entry[] newTable) { Entry[] src = table; int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) { Entry&lt;K,V&gt; e = src[j]; if (e != null) { src[j] = null; do { Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } while (e != null); } }} 6. 扩容-重新计算桶下标在进行扩容时，需要把键值对重新放到对应的桶上。HashMap 使用了一个特殊的机制，可以降低重新计算桶下标的操作。 假设原数组长度 capacity 为 16，扩容之后 new capacity 为 32： 12capacity : 00010000new capacity : 00100000 对于一个 Key， 它的哈希值如果在第 5 位上为 0，那么取模得到的结果和之前一样； 如果为 1，那么得到的结果为原来的结果 +16。 7. 计算数组容量HashMap 构造函数允许用户传入的容量不是 2 的 n 次方，因为它可以自动地将传入的容量转换为 2 的 n 次方。 先考虑如何求一个数的掩码，对于 10010000，它的掩码为 11111111，可以使用以下方法得到： 123mask |= mask &gt;&gt; 1 11011000mask |= mask &gt;&gt; 2 11111110mask |= mask &gt;&gt; 4 11111111 mask+1 是大于原始数字的最小的 2 的 n 次方。 12num 10010000mask+1 100000000 以下是 HashMap 中计算数组容量的代码： 123456789static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 8. 链表转红黑树从 JDK 1.8 开始，一个桶存储的链表长度大于 8 时会将链表转换为红黑树。 应该是：从 JDK 1.8 开始， table的长度也就是HashMap的capacity(不是size)不能小于64而且在桶存储的链表长度为8时(准确的说是长度为7并且在继续塞第8个时),转换成红黑树,而不是超过8。 9. 与 HashTable 的比较 HashTable 使用 synchronized 来进行同步。 HashMap 可以插入键为 null 的 Entry。 HashMap 的迭代器是 fail-fast 迭代器。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。 ConcurrentHashMap1. 存储结构123456static final class HashEntry&lt;K,V&gt; { final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;} ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。 Segment 继承自 ReentrantLock。 123456789101112131415161718static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable { private static final long serialVersionUID = 2249069246763182397L; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor;}final Segment&lt;K,V&gt;[] segments; 默认的并发级别为 16，也就是说默认创建 16 个 Segment。 1static final int DEFAULT_CONCURRENCY_LEVEL = 16; 2. size 操作每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数。 12345/** * The number of elements. Accessed only either within locks * or among other volatile reads that maintain visibility. */transient int count; 在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。 ConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。 尝试次数使用 RETRIES_BEFORE_LOCK 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3。 如果尝试的次数超过 3 次，就需要对每个 Segment 加锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Number of unsynchronized retries in size and containsValue * methods before resorting to locking. This is used to avoid * unbounded retries if tables undergo continuous modification * which would make it impossible to obtain an accurate result. */static final int RETRIES_BEFORE_LOCK = 2;public int size() { // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try { for (;;) { // 超过尝试次数，则对每个 Segment 加锁 if (retries++ == RETRIES_BEFORE_LOCK) { for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation } sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) { Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) { sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; } } // 连续两次得到的结果一致，则认为这个结果是正确的 if (sum == last) break; last = sum; } } finally { if (retries &gt; RETRIES_BEFORE_LOCK) { for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); } } return overflow ? Integer.MAX_VALUE : size;} 3. JDK 1.8 的改动JDK 1.7 使用分段锁机制来实现并发更新操作，核心类为 Segment，它继承自重入锁 ReentrantLock，并发度与 Segment 数量相等。 JDK 1.8 使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。 并且 JDK 1.8 的实现也在链表过长时会转换为红黑树。 LinkedHashMap存储结构继承自 HashMap，因此具有和 HashMap 一样的快速查找特性。 1public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt; 内部维护了一个双向链表，用来维护插入顺序或者 LRU 顺序。 123456789/** * The head (eldest) of the doubly linked list. */transient LinkedHashMap.Entry&lt;K,V&gt; head;/** * The tail (youngest) of the doubly linked list. */transient LinkedHashMap.Entry&lt;K,V&gt; tail; accessOrder 决定了顺序，默认为 false，此时维护的是插入顺序。 1final boolean accessOrder; LinkedHashMap 最重要的是以下用于维护顺序的函数，它们会在 put、get 等方法中调用。 12void afterNodeAccess(Node&lt;K,V&gt; p) { }void afterNodeInsertion(boolean evict) { } afterNodeAccess()当一个节点被访问时，如果 accessOrder 为 true，则会将该节点移到链表尾部。也就是说指定为 LRU 顺序之后，在每次访问一个节点时，会将这个节点移到链表尾部，保证链表尾部是最近访问的节点，那么链表首部就是最近最久未使用的节点。 123456789101112131415161718192021222324void afterNodeAccess(Node&lt;K,V&gt; e) { // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) { LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else { p.before = last; last.after = p; } tail = p; ++modCount; }} afterNodeInsertion()在 put 等操作之后执行，当 removeEldestEntry() 方法返回 true 时会移除最晚的节点，也就是链表首部节点 first。 evict 只有在构建 Map 的时候才为 false，在这里为 true。 1234567void afterNodeInsertion(boolean evict) { // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) { K key = first.key; removeNode(hash(key), key, null, false, true); }} removeEldestEntry() 默认为 false，如果需要让它为 true，需要继承 LinkedHashMap 并且覆盖这个方法的实现，这在实现 LRU 的缓存中特别有用，通过移除最近最久未使用的节点，从而保证缓存空间足够，并且缓存的数据都是热点数据。 123protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) { return false;} LRU 缓存以下是使用 LinkedHashMap 实现的一个 LRU 缓存： 设定最大缓存空间 MAX_ENTRIES 为 3； 使用 LinkedHashMap 的构造函数将 accessOrder 设置为 true，开启 LRU 顺序； 覆盖 removeEldestEntry() 方法实现，在节点多于 MAX_ENTRIES 就会将最近最久未使用的数据移除。 123456789101112131415161718192021class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; { private static final int MAX_ENTRIES = 3; protected boolean removeEldestEntry(Map.Entry eldest) { return size() &gt; MAX_ENTRIES; } LRUCache() { super(MAX_ENTRIES, 0.75f, true); }}public static void main(String[] args) { LRUCache&lt;Integer, String&gt; cache = new LRUCache&lt;&gt;(); cache.put(1, \"a\"); cache.put(2, \"b\"); cache.put(3, \"c\"); cache.get(1); cache.put(4, \"d\"); System.out.println(cache.keySet());}[3, 1, 4] WeakHashMap存储结构WeakHashMap 的 Entry 继承自 WeakReference，被 WeakReference 关联的对象在下一次垃圾回收时会被回收。 WeakHashMap 主要用来实现缓存，通过使用 WeakHashMap 来引用缓存对象，由 JVM 对这部分缓存进行回收。 1private static class Entry&lt;K,V&gt; extends WeakReference&lt;Object&gt; implements Map.Entry&lt;K,V&gt; ConcurrentCacheTomcat 中的 ConcurrentCache 使用了 WeakHashMap 来实现缓存功能。 ConcurrentCache 采取的是分代缓存： 经常使用的对象放入 eden 中，eden 使用 ConcurrentHashMap 实现，不用担心会被回收（伊甸园）； 不常用的对象放入 longterm，longterm 使用 WeakHashMap 实现，这些老对象会被垃圾收集器回收。 当调用 get() 方法时，会先从 eden 区获取，如果没有找到的话再到 longterm 获取，当从 longterm 获取到就把对象放入 eden 中，从而保证经常被访问的节点不容易被回收。 当调用 put() 方法时，如果 eden 的大小超过了 size，那么就将 eden 中的所有对象都放入 longterm 中，利用虚拟机回收掉一部分不经常使用的对象。 1234567891011121314151617181920212223242526272829303132public final class ConcurrentCache&lt;K, V&gt; { private final int size; private final Map&lt;K, V&gt; eden; private final Map&lt;K, V&gt; longterm; public ConcurrentCache(int size) { this.size = size; this.eden = new ConcurrentHashMap&lt;&gt;(size); this.longterm = new WeakHashMap&lt;&gt;(size); } public V get(K k) { V v = this.eden.get(k); if (v == null) { v = this.longterm.get(k); if (v != null) this.eden.put(k, v); } return v; } public void put(K k, V v) { if (this.eden.size() &gt;= size) { this.longterm.putAll(this.eden); this.eden.clear(); } this.eden.put(k, v); }} 文章来源) .","link":"/2019/08/16/Java容器集合.html"},{"title":"中华人民共和国网络安全法","text":"《中华人民共和国网络安全法》是为保障网络安全，维护网络空间主权和国家安全、社会公共利益，保护公民、法人和其他组织的合法权益，促进经济社会信息化健康发展制定。由全国人民代表大会常务委员会于2016年11月7日发布，自2017年6月1日起施行。 中华人民共和国网络安全法中文名：中华人民共和国网络安全法 外文名：People’s Republic of China Network Security Law 发布机构：全国人民代表大会常务委员会 发布日期：2016年11月7日 实施日期：2017年6月1日 ​ 第一章 总 则 ​ 第二章 网络安全支持与促进 ​ 第三章 网络运行安全 ​ 第一节 一般规定 ​ 第二节 关键信息基础设施的运行安全 ​ 第四章 网络信息安全 ​ 第五章 监测预警与应急处置 ​ 第六章 法律责任 ​ 第七章 附 则 第一章 总 则第一条 为了保障网络安全，维护网络空间主权和国家安全、社会公共利益，保护公民、法人和其他组织的合法权益，促进经济社会信息化健康发展，制定本法。 第二条 在中华人民共和国境内建设、运营、维护和使用网络，以及网络安全的监督管理，适用本法。 第三条 国家坚持网络安全与信息化发展并重，遵循积极利用、科学发展、依法管理、确保安全的方针，推进网络基础设施建设和互联互通，鼓励网络技术创新和应用，支持培养网络安全人才，建立健全网络安全保障体系，提高网络安全保护能力。 第四条 国家制定并不断完善网络安全战略，明确保障网络安全的基本要求和主要目标，提出重点领域的网络安全政策、工作任务和措施。 第五条 国家采取措施，监测、防御、处置来源于中华人民共和国境内外的网络安全风险和威胁，保护关键信息基础设施免受攻击、侵入、干扰和破坏，依法惩治网络违法犯罪活动，维护网络空间安全和秩序。 第六条 国家倡导诚实守信、健康文明的网络行为，推动传播社会主义核心价值观，采取措施提高全社会的网络安全意识和水平，形成全社会共同参与促进网络安全的良好环境。 第七条 国家积极开展网络空间治理、网络技术研发和标准制定、打击网络违法犯罪等方面的国际交流与合作，推动构建和平、安全、开放、合作的网络空间，建立多边、民主、透明的网络治理体系。 第八条 国家网信部门负责统筹协调网络安全工作和相关监督管理工作。国务院电信主管部门、公安部门和其他有关机关依照本法和有关法律、行政法规的规定，在各自职责范围内负责网络安全保护和监督管理工作。 县级以上地方人民政府有关部门的网络安全保护和监督管理职责，按照国家有关规定确定。 第九条 网络运营者开展经营和服务活动，必须遵守法律、行政法规，尊重社会公德，遵守商业道德，诚实信用，履行网络安全保护义务，接受政府和社会的监督，承担社会责任。 第十条 建设、运营网络或者通过网络提供服务，应当依照法律、行政法规的规定和国家标准的强制性要求，采取技术措施和其他必要措施，保障网络安全、稳定运行，有效应对网络安全事件，防范网络违法犯罪活动，维护网络数据的完整性、保密性和可用性。 第十一条 网络相关行业组织按照章程，加强行业自律，制定网络安全行为规范，指导会员加强网络安全保护，提高网络安全保护水平，促进行业健康发展。 第十二条 国家保护公民、法人和其他组织依法使用网络的权利，促进网络接入普及，提升网络服务水平，为社会提供安全、便利的网络服务，保障网络信息依法有序自由流动。 任何个人和组织使用网络应当遵守宪法法律，遵守公共秩序，尊重社会公德，不得危害网络安全，不得利用网络从事危害国家安全、荣誉和利益，煽动颠覆国家政权、推翻社会主义制度，煽动分裂国家、破坏国家统一，宣扬恐怖主义、极端主义，宣扬民族仇恨、民族歧视，传播暴力、淫秽色情信息，编造、传播虚假信息扰乱经济秩序和社会秩序，以及侵害他人名誉、隐私、知识产权和其他合法权益等活动。 第十三条 国家支持研究开发有利于未成年人健康成长的网络产品和服务，依法惩治利用网络从事危害未成年人身心健康的活动，为未成年人提供安全、健康的网络环境。 第十四条 任何个人和组织有权对危害网络安全的行为向网信、电信、公安等部门举报。收到举报的部门应当及时依法作出处理；不属于本部门职责的，应当及时移送有权处理的部门。 有关部门应当对举报人的相关信息予以保密，保护举报人的合法权益。 第二章 网络安全支持与促进第十五条 国家建立和完善网络安全标准体系。国务院标准化行政主管部门和国务院其他有关部门根据各自的职责，组织制定并适时修订有关网络安全管理以及网络产品、服务和运行安全的国家标准、行业标准。 国家支持企业、研究机构、高等学校、网络相关行业组织参与网络安全国家标准、行业标准的制定。 第十六条 国务院和省、自治区、直辖市人民政府应当统筹规划，加大投入，扶持重点网络安全技术产业和项目，支持网络安全技术的研究开发和应用，推广安全可信的网络产品和服务，保护网络技术知识产权，支持企业、研究机构和高等学校等参与国家网络安全技术创新项目。 第十七条 国家推进网络安全社会化服务体系建设，鼓励有关企业、机构开展网络安全认证、检测和风险评估等安全服务。 第十八条 国家鼓励开发网络数据安全保护和利用技术，促进公共数据资源开放，推动技术创新和经济社会发展。 国家支持创新网络安全管理方式，运用网络新技术，提升网络安全保护水平。 第十九条 各级人民政府及其有关部门应当组织开展经常性的网络安全宣传教育，并指导、督促有关单位做好网络安全宣传教育工作。 大众传播媒介应当有针对性地面向社会进行网络安全宣传教育。 第二十条 国家支持企业和高等学校、职业学校等教育培训机构开展网络安全相关教育与培训，采取多种方式培养网络安全人才，促进网络安全人才交流。 第三章 网络运行安全 第一节 一般规定第二十一条 国家实行网络安全等级保护制度。网络运营者应当按照网络安全等级保护制度的要求，履行下列安全保护义务，保障网络免受干扰、破坏或者未经授权的访问，防止网络数据泄露或者被窃取、篡改： （一）制定内部安全管理制度和操作规程，确定网络安全负责人，落实网络安全保护责任； （二）采取防范计算机病毒和网络攻击、网络侵入等危害网络安全行为的技术措施； （三）采取监测、记录网络运行状态、网络安全事件的技术措施，并按照规定留存相关的网络日志不少于六个月； （四）采取数据分类、重要数据备份和加密等措施； （五）法律、行政法规规定的其他义务。 第二十二条 网络产品、服务应当符合相关国家标准的强制性要求。网络产品、服务的提供者不得设置恶意程序；发现其网络产品、服务存在安全缺陷、漏洞等风险时，应当立即采取补救措施，按照规定及时告知用户并向有关主管部门报告。 网络产品、服务的提供者应当为其产品、服务持续提供安全维护；在规定或者当事人约定的期限内，不得终止提供安全维护。 网络产品、服务具有收集用户信息功能的，其提供者应当向用户明示并取得同意；涉及用户个人信息的，还应当遵守本法和有关法律、行政法规关于个人信息保护的规定。 第二十三条 网络关键设备和网络安全专用产品应当按照相关国家标准的强制性要求，由具备资格的机构安全认证合格或者安全检测符合要求后，方可销售或者提供。国家网信部门会同国务院有关部门制定、公布网络关键设备和网络安全专用产品目录，并推动安全认证和安全检测结果互认，避免重复认证、检测。 第二十四条 网络运营者为用户办理网络接入、域名注册服务，办理固定电话、移动电话等入网手续，或者为用户提供信息发布、即时通讯等服务，在与用户签订协议或者确认提供服务时，应当要求用户提供真实身份信息。用户不提供真实身份信息的，网络运营者不得为其提供相关服务。 国家实施网络可信身份战略，支持研究开发安全、方便的电子身份认证技术，推动不同电子身份认证之间的互认。 第二十五条 网络运营者应当制定网络安全事件应急预案，及时处置系统漏洞、计算机病毒、网络攻击、网络侵入等安全风险；在发生危害网络安全的事件时，立即启动应急预案，采取相应的补救措施，并按照规定向有关主管部门报告。 第二十六条 开展网络安全认证、检测、风险评估等活动，向社会发布系统漏洞、计算机病毒、网络攻击、网络侵入等网络安全信息，应当遵守国家有关规定。 第二十七条 任何个人和组织不得从事非法侵入他人网络、干扰他人网络正常功能、窃取网络数据等危害网络安全的活动；不得提供专门用于从事侵入网络、干扰网络正常功能及防护措施、窃取网络数据等危害网络安全活动的程序、工具；明知他人从事危害网络安全的活动的，不得为其提供技术支持、广告推广、支付结算等帮助。 第二十八条 网络运营者应当为公安机关、国家安全机关依法维护国家安全和侦查犯罪的活动提供技术支持和协助。 第二十九条 国家支持网络运营者之间在网络安全信息收集、分析、通报和应急处置等方面进行合作，提高网络运营者的安全保障能力。 有关行业组织建立健全本行业的网络安全保护规范和协作机制，加强对网络安全风险的分析评估，定期向会员进行风险警示，支持、协助会员应对网络安全风险。 第三十条 网信部门和有关部门在履行网络安全保护职责中获取的信息，只能用于维护网络安全的需要，不得用于其他用途。 第二节 关键信息基础设施的运行安全第三十一条 国家对公共通信和信息服务、能源、交通、水利、金融、公共服务、电子政务等重要行业和领域，以及其他一旦遭到破坏、丧失功能或者数据泄露，可能严重危害国家安全、国计民生、公共利益的关键信息基础设施，在网络安全等级保护制度的基础上，实行重点保护。关键信息基础设施的具体范围和安全保护办法由国务院制定。 国家鼓励关键信息基础设施以外的网络运营者自愿参与关键信息基础设施保护体系。 第三十二条 按照国务院规定的职责分工，负责关键信息基础设施安全保护工作的部门分别编制并组织实施本行业、本领域的关键信息基础设施安全规划，指导和监督关键信息基础设施运行安全保护工作。 第三十三条 建设关键信息基础设施应当确保其具有支持业务稳定、持续运行的性能，并保证安全技术措施同步规划、同步建设、同步使用。 第三十四条 除本法第二十一条的规定外，关键信息基础设施的运营者还应当履行下列安全保护义务： （一）设置专门安全管理机构和安全管理负责人，并对该负责人和关键岗位的人员进行安全背景审查； （二）定期对从业人员进行网络安全教育、技术培训和技能考核； （三）对重要系统和数据库进行容灾备份； （四）制定网络安全事件应急预案，并定期进行演练； （五）法律、行政法规规定的其他义务。 第三十五条 关键信息基础设施的运营者采购网络产品和服务，可能影响国家安全的，应当通过国家网信部门会同国务院有关部门组织的国家安全审查。 第三十六条 关键信息基础设施的运营者采购网络产品和服务，应当按照规定与提供者签订安全保密协议，明确安全和保密义务与责任。 第三十七条 关键信息基础设施的运营者在中华人民共和国境内运营中收集和产生的个人信息和重要数据应当在境内存储。因业务需要，确需向境外提供的，应当按照国家网信部门会同国务院有关部门制定的办法进行安全评估；法律、行政法规另有规定的，依照其规定。 第三十八条 关键信息基础设施的运营者应当自行或者委托网络安全服务机构对其网络的安全性和可能存在的风险每年至少进行一次检测评估，并将检测评估情况和改进措施报送相关负责关键信息基础设施安全保护工作的部门。 第三十九条 国家网信部门应当统筹协调有关部门对关键信息基础设施的安全保护采取下列措施： （一）对关键信息基础设施的安全风险进行抽查检测，提出改进措施，必要时可以委托网络安全服务机构对网络存在的安全风险进行检测评估； （二）定期组织关键信息基础设施的运营者进行网络安全应急演练，提高应对网络安全事件的水平和协同配合能力； （三）促进有关部门、关键信息基础设施的运营者以及有关研究机构、网络安全服务机构等之间的网络安全信息共享； （四）对网络安全事件的应急处置与网络功能的恢复等，提供技术支持和协助。 第四章 网络信息安全第四十条 网络运营者应当对其收集的用户信息严格保密，并建立健全用户信息保护制度。 第四十一条 网络运营者收集、使用个人信息，应当遵循合法、正当、必要的原则，公开收集、使用规则，明示收集、使用信息的目的、方式和范围，并经被收集者同意。 网络运营者不得收集与其提供的服务无关的个人信息，不得违反法律、行政法规的规定和双方的约定收集、使用个人信息，并应当依照法律、行政法规的规定和与用户的约定，处理其保存的个人信息。 第四十二条 网络运营者不得泄露、篡改、毁损其收集的个人信息；未经被收集者同意，不得向他人提供个人信息。但是，经过处理无法识别特定个人且不能复原的除外。 网络运营者应当采取技术措施和其他必要措施，确保其收集的个人信息安全，防止信息泄露、毁损、丢失。在发生或者可能发生个人信息泄露、毁损、丢失的情况时，应当立即采取补救措施，按照规定及时告知用户并向有关主管部门报告。 第四十三条 个人发现网络运营者违反法律、行政法规的规定或者双方的约定收集、使用其个人信息的，有权要求网络运营者删除其个人信息；发现网络运营者收集、存储的其个人信息有错误的，有权要求网络运营者予以更正。网络运营者应当采取措施予以删除或者更正。 第四十四条 任何个人和组织不得窃取或者以其他非法方式获取个人信息，不得非法出售或者非法向他人提供个人信息。 第四十五条 依法负有网络安全监督管理职责的部门及其工作人员，必须对在履行职责中知悉的个人信息、隐私和商业秘密严格保密，不得泄露、出售或者非法向他人提供。 第四十六条 任何个人和组织应当对其使用网络的行为负责，不得设立用于实施诈骗，传授犯罪方法，制作或者销售违禁物品、管制物品等违法犯罪活动的网站、通讯群组，不得利用网络发布涉及实施诈骗，制作或者销售违禁物品、管制物品以及其他违法犯罪活动的信息。 第四十七条 网络运营者应当加强对其用户发布的信息的管理，发现法律、行政法规禁止发布或者传输的信息的，应当立即停止传输该信息，采取消除等处置措施，防止信息扩散，保存有关记录，并向有关主管部门报告。 第四十八条 任何个人和组织发送的电子信息、提供的应用软件，不得设置恶意程序，不得含有法律、行政法规禁止发布或者传输的信息。 电子信息发送服务提供者和应用软件下载服务提供者，应当履行安全管理义务，知道其用户有前款规定行为的，应当停止提供服务，采取消除等处置措施，保存有关记录，并向有关主管部门报告。 第四十九条 网络运营者应当建立网络信息安全投诉、举报制度，公布投诉、举报方式等信息，及时受理并处理有关网络信息安全的投诉和举报。 网络运营者对网信部门和有关部门依法实施的监督检查，应当予以配合。 第五十条 国家网信部门和有关部门依法履行网络信息安全监督管理职责，发现法律、行政法规禁止发布或者传输的信息的，应当要求网络运营者停止传输，采取消除等处置措施，保存有关记录；对来源于中华人民共和国境外的上述信息，应当通知有关机构采取技术措施和其他必要措施阻断传播。 第五章 监测预警与应急处置第五十一条 国家建立网络安全监测预警和信息通报制度。国家网信部门应当统筹协调有关部门加强网络安全信息收集、分析和通报工作，按照规定统一发布网络安全监测预警信息。 第五十二条 负责关键信息基础设施安全保护工作的部门，应当建立健全本行业、本领域的网络安全监测预警和信息通报制度，并按照规定报送网络安全监测预警信息。 第五十三条 国家网信部门协调有关部门建立健全网络安全风险评估和应急工作机制，制定网络安全事件应急预案，并定期组织演练。 负责关键信息基础设施安全保护工作的部门应当制定本行业、本领域的网络安全事件应急预案，并定期组织演练。 网络安全事件应急预案应当按照事件发生后的危害程度、影响范围等因素对网络安全事件进行分级，并规定相应的应急处置措施。 第五十四条 网络安全事件发生的风险增大时，省级以上人民政府有关部门应当按照规定的权限和程序，并根据网络安全风险的特点和可能造成的危害，采取下列措施： （一）要求有关部门、机构和人员及时收集、报告有关信息，加强对网络安全风险的监测； （二）组织有关部门、机构和专业人员，对网络安全风险信息进行分析评估，预测事件发生的可能性、影响范围和危害程度； （三）向社会发布网络安全风险预警，发布避免、减轻危害的措施。 第五十五条 发生网络安全事件，应当立即启动网络安全事件应急预案，对网络安全事件进行调查和评估，要求网络运营者采取技术措施和其他必要措施，消除安全隐患，防止危害扩大，并及时向社会发布与公众有关的警示信息。 第五十六条 省级以上人民政府有关部门在履行网络安全监督管理职责中，发现网络存在较大安全风险或者发生安全事件的，可以按照规定的权限和程序对该网络的运营者的法定代表人或者主要负责人进行约谈。网络运营者应当按照要求采取措施，进行整改，消除隐患。 第五十七条 因网络安全事件，发生突发事件或者生产安全事故的，应当依照《中华人民共和国突发事件应对法》、《中华人民共和国安全生产法》等有关法律、行政法规的规定处置。 第五十八条 因维护国家安全和社会公共秩序，处置重大突发社会安全事件的需要，经国务院决定或者批准，可以在特定区域对网络通信采取限制等临时措施。 第六章 法律责任第五十九条 网络运营者不履行本法第二十一条、第二十五条规定的网络安全保护义务的，由有关主管部门责令改正，给予警告；拒不改正或者导致危害网络安全等后果的，处一万元以上十万元以下罚款，对直接负责的主管人员处五千元以上五万元以下罚款。 关键信息基础设施的运营者不履行本法第三十三条、第三十四条、第三十六条、第三十八条规定的网络安全保护义务的，由有关主管部门责令改正，给予警告；拒不改正或者导致危害网络安全等后果的，处十万元以上一百万元以下罚款，对直接负责的主管人员处一万元以上十万元以下罚款。 第六十条 违反本法第二十二条第一款、第二款和第四十八条第一款规定，有下列行为之一的，由有关主管部门责令改正，给予警告；拒不改正或者导致危害网络安全等后果的，处五万元以上五十万元以下罚款，对直接负责的主管人员处一万元以上十万元以下罚款： （一）设置恶意程序的； （二）对其产品、服务存在的安全缺陷、漏洞等风险未立即采取补救措施，或者未按照规定及时告知用户并向有关主管部门报告的； （三）擅自终止为其产品、服务提供安全维护的。 第六十一条 网络运营者违反本法第二十四条第一款规定，未要求用户提供真实身份信息，或者对不提供真实身份信息的用户提供相关服务的，由有关主管部门责令改正；拒不改正或者情节严重的，处五万元以上五十万元以下罚款，并可以由有关主管部门责令暂停相关业务、停业整顿、关闭网站、吊销相关业务许可证或者吊销营业执照，对直接负责的主管人员和其他直接责任人员处一万元以上十万元以下罚款。 第六十二条 违反本法第二十六条规定，开展网络安全认证、检测、风险评估等活动，或者向社会发布系统漏洞、计算机病毒、网络攻击、网络侵入等网络安全信息的，由有关主管部门责令改正，给予警告；拒不改正或者情节严重的，处一万元以上十万元以下罚款，并可以由有关主管部门责令暂停相关业务、停业整顿、关闭网站、吊销相关业务许可证或者吊销营业执照，对直接负责的主管人员和其他直接责任人员处五千元以上五万元以下罚款。 第六十三条 违反本法第二十七条规定，从事危害网络安全的活动，或者提供专门用于从事危害网络安全活动的程序、工具，或者为他人从事危害网络安全的活动提供技术支持、广告推广、支付结算等帮助，尚不构成犯罪的，由公安机关没收违法所得，处五日以下拘留，可以并处五万元以上五十万元以下罚款；情节较重的，处五日以上十五日以下拘留，可以并处十万元以上一百万元以下罚款。 单位有前款行为的，由公安机关没收违法所得，处十万元以上一百万元以下罚款，并对直接负责的主管人员和其他直接责任人员依照前款规定处罚。 违反本法第二十七条规定，受到治安管理处罚的人员，五年内不得从事网络安全管理和网络运营关键岗位的工作；受到刑事处罚的人员，终身不得从事网络安全管理和网络运营关键岗位的工作。 第六十四条 网络运营者、网络产品或者服务的提供者违反本法第二十二条第三款、第四十一条至第四十三条规定，侵害个人信息依法得到保护的权利的，由有关主管部门责令改正，可以根据情节单处或者并处警告、没收违法所得、处违法所得一倍以上十倍以下罚款，没有违法所得的，处一百万元以下罚款，对直接负责的主管人员和其他直接责任人员处一万元以上十万元以下罚款；情节严重的，并可以责令暂停相关业务、停业整顿、关闭网站、吊销相关业务许可证或者吊销营业执照。 违反本法第四十四条规定，窃取或者以其他非法方式获取、非法出售或者非法向他人提供个人信息，尚不构成犯罪的，由公安机关没收违法所得，并处违法所得一倍以上十倍以下罚款，没有违法所得的，处一百万元以下罚款。 第六十五条 关键信息基础设施的运营者违反本法第三十五条规定，使用未经安全审查或者安全审查未通过的网络产品或者服务的，由有关主管部门责令停止使用，处采购金额一倍以上十倍以下罚款；对直接负责的主管人员和其他直接责任人员处一万元以上十万元以下罚款。 第六十六条 关键信息基础设施的运营者违反本法第三十七条规定，在境外存储网络数据，或者向境外提供网络数据的，由有关主管部门责令改正，给予警告，没收违法所得，处五万元以上五十万元以下罚款，并可以责令暂停相关业务、停业整顿、关闭网站、吊销相关业务许可证或者吊销营业执照；对直接负责的主管人员和其他直接责任人员处一万元以上十万元以下罚款。 第六十七条 违反本法第四十六条规定，设立用于实施违法犯罪活动的网站、通讯群组，或者利用网络发布涉及实施违法犯罪活动的信息，尚不构成犯罪的，由公安机关处五日以下拘留，可以并处一万元以上十万元以下罚款；情节较重的，处五日以上十五日以下拘留，可以并处五万元以上五十万元以下罚款。关闭用于实施违法犯罪活动的网站、通讯群组。 单位有前款行为的，由公安机关处十万元以上五十万元以下罚款，并对直接负责的主管人员和其他直接责任人员依照前款规定处罚。 第六十八条 网络运营者违反本法第四十七条规定，对法律、行政法规禁止发布或者传输的信息未停止传输、采取消除等处置措施、保存有关记录的，由有关主管部门责令改正，给予警告，没收违法所得；拒不改正或者情节严重的，处十万元以上五十万元以下罚款，并可以责令暂停相关业务、停业整顿、关闭网站、吊销相关业务许可证或者吊销营业执照，对直接负责的主管人员和其他直接责任人员处一万元以上十万元以下罚款。 电子信息发送服务提供者、应用软件下载服务提供者，不履行本法第四十八条第二款规定的安全管理义务的，依照前款规定处罚。 第六十九条 网络运营者违反本法规定，有下列行为之一的，由有关主管部门责令改正；拒不改正或者情节严重的，处五万元以上五十万元以下罚款，对直接负责的主管人员和其他直接责任人员，处一万元以上十万元以下罚款： （一）不按照有关部门的要求对法律、行政法规禁止发布或者传输的信息，采取停止传输、消除等处置措施的； （二）拒绝、阻碍有关部门依法实施的监督检查的； （三）拒不向公安机关、国家安全机关提供技术支持和协助的。 第七十条 发布或者传输本法第十二条第二款和其他法律、行政法规禁止发布或者传输的信息的，依照有关法律、行政法规的规定处罚。 第七十一条 有本法规定的违法行为的，依照有关法律、行政法规的规定记入信用档案，并予以公示。 第七十二条 国家机关政务网络的运营者不履行本法规定的网络安全保护义务的，由其上级机关或者有关机关责令改正；对直接负责的主管人员和其他直接责任人员依法给予处分。 第七十三条 网信部门和有关部门违反本法第三十条规定，将在履行网络安全保护职责中获取的信息用于其他用途的，对直接负责的主管人员和其他直接责任人员依法给予处分。 网信部门和有关部门的工作人员玩忽职守、滥用职权、徇私舞弊，尚不构成犯罪的，依法给予处分。 第七十四条 违反本法规定，给他人造成损害的，依法承担民事责任。 违反本法规定，构成违反治安管理行为的，依法给予治安管理处罚；构成犯罪的，依法追究刑事责任。 第七十五条 境外的机构、组织、个人从事攻击、侵入、干扰、破坏等危害中华人民共和国的关键信息基础设施的活动，造成严重后果的，依法追究法律责任；国务院公安部门和有关部门并可以决定对该机构、组织、个人采取冻结财产或者其他必要的制裁措施。 第七章 附 则第七十六条 本法下列用语的含义： （一）网络，是指由计算机或者其他信息终端及相关设备组成的按照一定的规则和程序对信息进行收集、存储、传输、交换、处理的系统。 （二）网络安全，是指通过采取必要措施，防范对网络的攻击、侵入、干扰、破坏和非法使用以及意外事故，使网络处于稳定可靠运行的状态，以及保障网络数据的完整性、保密性、可用性的能力。 （三）网络运营者，是指网络的所有者、管理者和网络服务提供者。 （四）网络数据，是指通过网络收集、存储、传输、处理和产生的各种电子数据。 （五）个人信息，是指以电子或者其他方式记录的能够单独或者与其他信息结合识别自然人个人身份的各种信息，包括但不限于自然人的姓名、出生日期、身份证件号码、个人生物识别信息、住址、电话号码等。 第七十七条 存储、处理涉及国家秘密信息的网络的运行安全保护，除应当遵守本法外，还应当遵守保密法律、行政法规的规定。 第七十八条 军事网络的安全保护，由中央军事委员会另行规定。 第七十九条 本法自2017年6月1日起施行。","link":"/2019/08/08/中华人民共和国网络安全法.html"},{"title":"Java并发相关知识点","text":"互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。 互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。 并发零碎知识点 线程状态转换 新建（New） 创建后尚未启动。 可运行（Runnable） 可能正在运行，也可能正在等待 CPU 时间片。 包含了操作系统线程状态中的 Running 和 Ready。 阻塞（Blocked） 等待获取一个排它锁，如果其线程释放了锁就会结束此状态。 无限期等待（Waiting） 等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。 进入方法 退出方法 没有设置 Timeout 参数的 Object.wait() 方法 Object.notify() / Object.notifyAll() 没有设置 Timeout 参数的 Thread.join() 方法 被调用的线程执行完毕 LockSupport.park() 方法 LockSupport.unpark(Thread) 限期等待（Timed Waiting） 无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。 调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。 睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。 阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用 Thread.sleep() 和 Object.wait() 等方法进入。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 / Object.notify() / Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 / 被调用的线程执行完毕 LockSupport.parkNanos() 方法 LockSupport.unpark(Thread) LockSupport.parkUntil() 方法 LockSupport.unpark(Thread) 死亡（Terminated） 可以是线程结束任务之后自己结束，或者产生了异常而结束。 使用线程有三种使用线程的方法： 实现 Runnable 接口； 实现 Callable 接口； 继承 Thread 类。 实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以说任务是通过线程驱动从而执行的。 实现 Runnable 接口需要实现 run() 方法。 通过 Thread 调用 start() 方法来启动线程。 1234567891011public class MyRunnable implements Runnable { public void run() { // ... }}public static void main(String[] args) { MyRunnable instance = new MyRunnable(); Thread thread = new Thread(instance); thread.start(); //调用 thread.run()并不是开启新线程，而是在当前线程里马上调用run()方法} 实现 Callable 接口与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装。 123456789101112public class MyCallable implements Callable&lt;Integer&gt; { public Integer call() { return 123; }}public static void main(String[] args) throws ExecutionException, InterruptedException { MyCallable mc = new MyCallable(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get());} 继承 Thread 类同样也是需要实现 run() 方法，因为 Thread 类也实现了 Runable 接口。 当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。 123456789public class MyThread extends Thread { public void run() { // ... }}public static void main(String[] args) { MyThread mt = new MyThread(); mt.start();} 实现接口 VS 继承 Thread实现接口会更好一些，因为： Java 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口； 类可能只要求可执行就行，继承整个 Thread 类开销过大。 基础线程机制ExecutorExecutor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。 主要有三种 Executor： CachedThreadPool：一个任务创建一个线程； FixedThreadPool：所有任务只能使用固定大小的线程； SingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。 1234567public static void main(String[] args) { ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) { executorService.execute(new MyRunnable()); } executorService.shutdown();} Daemon守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。 当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。 main() 属于非守护线程。 在线程启动之前使用 setDaemon() 方法可以将一个线程设置为守护线程。 1234public static void main(String[] args) { Thread thread = new Thread(new MyRunnable()); thread.setDaemon(true);} sleep()Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。 sleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。 1234567public void run() { try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); }} yield()对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。 123public void run() { Thread.yield();} 中断一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。 InterruptedException通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。 对于以下代码，在 main() 中启动一个线程之后再中断它，由于线程中调用了 Thread.sleep() 方法，因此会抛出一个 InterruptedException，从而提前结束线程，不执行之后的语句。 1234567891011121314151617181920212223242526public class InterruptExample { private static class MyThread1 extends Thread { @Override public void run() { try { Thread.sleep(2000); System.out.println(\"Thread run\"); } catch (InterruptedException e) { e.printStackTrace(); } } }}public static void main(String[] args) throws InterruptedException { Thread thread1 = new MyThread1(); thread1.start(); thread1.interrupt(); System.out.println(\"Main run\");}Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at InterruptExample.lambda$main$0(InterruptExample.java:5) at InterruptExample$$Lambda$1/713338599.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) interrupted()如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。 但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。 123456789101112131415161718public class InterruptExample { private static class MyThread2 extends Thread { @Override public void run() { while (!interrupted()) { // .. } System.out.println(\"Thread end\"); } }}public static void main(String[] args) throws InterruptedException { Thread thread2 = new MyThread2(); thread2.start(); thread2.interrupt();}Thread end Executor 的中断操作调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。 以下使用 Lambda 创建线程，相当于创建了一个匿名内部线程。 123456789101112131415161718192021public static void main(String[] args) { ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; { try { Thread.sleep(2000); System.out.println(\"Thread run\"); } catch (InterruptedException e) { e.printStackTrace(); } }); executorService.shutdownNow(); System.out.println(\"Main run\");}Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at ExecutorInterruptExample.lambda$main$0(ExecutorInterruptExample.java:9) at ExecutorInterruptExample$$Lambda$1/1160460865.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。 1234Future&lt;?&gt; future = executorService.submit(() -&gt; { // ..});future.cancel(true); 互斥同步Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。 synchronized1. 同步一个代码块 12345public void func() { synchronized (this) { // ... }} 它只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步。 对于以下代码，使用 ExecutorService 执行了两个线程，由于调用的是同一个对象的同步代码块，因此这两个线程会进行同步，当一个线程进入同步语句块时，另一个线程就必须等待。 1234567891011121314151617public class SynchronizedExample { public void func1() { synchronized (this) { for (int i = 0; i &lt; 10; i++) { System.out.print(i + \" \"); } } }}public static void main(String[] args) { SynchronizedExample e1 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e1.func1());}0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 对于以下代码，两个线程调用了不同对象的同步代码块，因此这两个线程就不需要同步。从输出结果可以看出，两个线程交叉执行。 12345678public static void main(String[] args) { SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e2.func1());}0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 2. 同步一个方法 123public synchronized void func () { // ...} 它和同步代码块一样，作用于同一个对象。 3. 同步一个类 12345public void func() { synchronized (SynchronizedExample.class) { // ... }} 作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。 123456789101112131415161718public class SynchronizedExample { public void func2() { synchronized (SynchronizedExample.class) { for (int i = 0; i &lt; 10; i++) { System.out.print(i + \" \"); } } }}public static void main(String[] args) { SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func2()); executorService.execute(() -&gt; e2.func2());}0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 4. 同步一个静态方法 123public synchronized static void fun() { // ...} 作用于整个类。 ReentrantLockReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。 12345678910111213141516171819202122public class LockExample { private Lock lock = new ReentrantLock(); public void func() { lock.lock(); try { for (int i = 0; i &lt; 10; i++) { System.out.print(i + \" \"); } } finally { lock.unlock(); // 确保释放锁，从而避免发生死锁。 } }}public static void main(String[] args) { LockExample lockExample = new LockExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; lockExample.func()); executorService.execute(() -&gt; lockExample.func());}0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 比较1. 锁的实现 synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。 2. 性能 新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。 3. 等待可中断 当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。 ReentrantLock 可中断，而 synchronized 不行。 4. 公平锁 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。 synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。 5. 锁绑定多个条件 一个 ReentrantLock 可以同时绑定多个 Condition 对象。 使用选择除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。 线程之间的协作当多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。 join()在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。 对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。 1234567891011121314151617181920212223242526272829303132333435363738394041public class JoinExample { private class A extends Thread { @Override public void run() { System.out.println(\"A\"); } } private class B extends Thread { private A a; B(A a) { this.a = a; } @Override public void run() { try { a.join(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"B\"); } } public void test() { A a = new A(); B b = new B(a); b.start(); a.start(); }}public static void main(String[] args) { JoinExample example = new JoinExample(); example.test();}AB wait() notify() notifyAll()调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。 它们都属于 Object 的一部分，而不属于 Thread。 只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateException。 使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。 123456789101112131415161718192021222324public class WaitNotifyExample { public synchronized void before() { System.out.println(\"before\"); notifyAll(); } public synchronized void after() { try { wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"after\"); }}public static void main(String[] args) { ExecutorService executorService = Executors.newCachedThreadPool(); WaitNotifyExample example = new WaitNotifyExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());}beforeafter wait() 和 sleep() 的区别 wait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。 await() signal() signalAll()java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。 相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。 使用 Lock 来获取一个 Condition 对象。 1234567891011121314151617181920212223242526272829303132333435public class AwaitSignalExample { private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void before() { lock.lock(); try { System.out.println(\"before\"); condition.signalAll(); } finally { lock.unlock(); } } public void after() { lock.lock(); try { condition.await(); System.out.println(\"after\"); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }}public static void main(String[] args) { ExecutorService executorService = Executors.newCachedThreadPool(); AwaitSignalExample example = new AwaitSignalExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());}beforeafter J.U.C - AQSjava.util.concurrent（J.U.C）大大提高了并发性能，AQS 被认为是 J.U.C 的核心。 CountDownLatch用来控制一个或者多个线程等待多个线程。 维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。 12345678910111213141516171819public class CountdownLatchExample { public static void main(String[] args) throws InterruptedException { final int totalThread = 10; CountDownLatch countDownLatch = new CountDownLatch(totalThread); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalThread; i++) { executorService.execute(() -&gt; { System.out.print(\"run..\"); countDownLatch.countDown(); }); } countDownLatch.await(); System.out.println(\"end\"); executorService.shutdown(); }}run..run..run..run..run..run..run..run..run..run..end CyclicBarrier用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。 和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。 CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障。 CyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。 12345678910public CyclicBarrier(int parties, Runnable barrierAction) { if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;}public CyclicBarrier(int parties) { this(parties, null);} 123456789101112131415161718192021public class CyclicBarrierExample { public static void main(String[] args) { final int totalThread = 10; CyclicBarrier cyclicBarrier = new CyclicBarrier(totalThread); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalThread; i++) { executorService.execute(() -&gt; { System.out.print(\"before..\"); try { cyclicBarrier.await(); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } System.out.print(\"after..\"); }); } executorService.shutdown(); }}before..before..before..before..before..before..before..before..before..before..after..after..after..after..after..after..after..after..after..after.. SemaphoreSemaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。 以下代码模拟了对某个服务的并发请求，每次只能有 3 个客户端同时访问，请求总数为 10。 1234567891011121314151617181920212223public class SemaphoreExample { public static void main(String[] args) { final int clientCount = 3; final int totalRequestCount = 10; Semaphore semaphore = new Semaphore(clientCount); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalRequestCount; i++) { executorService.execute(()-&gt;{ try { semaphore.acquire(); System.out.print(semaphore.availablePermits() + \" \"); } catch (InterruptedException e) { e.printStackTrace(); } finally { semaphore.release(); } }); } executorService.shutdown(); }}2 1 2 2 2 2 2 1 2 2 J.U.C - 其它组件FutureTask在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。 12public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; FutureTask 可用于异步获取执行结果或取消执行任务的场景。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。 1234567891011121314151617181920212223242526272829303132public class FutureTaskExample { public static void main(String[] args) throws ExecutionException, InterruptedException { FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { int result = 0; for (int i = 0; i &lt; 100; i++) { Thread.sleep(10); result += i; } return result; } }); Thread computeThread = new Thread(futureTask); computeThread.start(); Thread otherThread = new Thread(() -&gt; { System.out.println(\"other task is running...\"); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } }); otherThread.start(); System.out.println(futureTask.get()); }}other task is running...4950 BlockingQueuejava.util.concurrent.BlockingQueue 接口有以下阻塞队列的实现： FIFO 队列 ：LinkedBlockingQueue、ArrayBlockingQueue（固定长度） 优先级队列 ：PriorityBlockingQueue 提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，直到队列有空闲位置。 使用 BlockingQueue 实现生产者消费者问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ProducerConsumer { private static BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;&gt;(5); private static class Producer extends Thread { @Override public void run() { try { queue.put(\"product\"); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(\"produce..\"); } } private static class Consumer extends Thread { @Override public void run() { try { String product = queue.take(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(\"consume..\"); } }}public static void main(String[] args) { for (int i = 0; i &lt; 2; i++) { Producer producer = new Producer(); producer.start(); } for (int i = 0; i &lt; 5; i++) { Consumer consumer = new Consumer(); consumer.start(); } for (int i = 0; i &lt; 3; i++) { Producer producer = new Producer(); producer.start(); }}produce..produce..consume..consume..produce..consume..produce..consume..produce..consume.. ForkJoin主要用于并行计算中，和 MapReduce 原理类似，都是把大的计算任务拆分成多个小任务并行计算。 12345678910111213141516171819202122232425262728293031323334353637public class ForkJoinExample extends RecursiveTask&lt;Integer&gt; { private final int threshold = 5; private int first; private int last; public ForkJoinExample(int first, int last) { this.first = first; this.last = last; } @Override protected Integer compute() { int result = 0; if (last - first &lt;= threshold) { // 任务足够小则直接计算 for (int i = first; i &lt;= last; i++) { result += i; } } else { // 拆分成小任务 int middle = first + (last - first) / 2; ForkJoinExample leftTask = new ForkJoinExample(first, middle); ForkJoinExample rightTask = new ForkJoinExample(middle + 1, last); leftTask.fork(); rightTask.fork(); result = leftTask.join() + rightTask.join(); } return result; }}public static void main(String[] args) throws ExecutionException, InterruptedException { ForkJoinExample example = new ForkJoinExample(1, 10000); ForkJoinPool forkJoinPool = new ForkJoinPool(); Future result = forkJoinPool.submit(example); System.out.println(result.get());} ForkJoin 使用 ForkJoinPool 来启动，它是一个特殊的线程池，线程数量取决于 CPU 核数。 1public class ForkJoinPool extends AbstractExecutorService ForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2 从 Thread1 的队列中拿出最晚的 Task1 任务，Thread1 会拿出 Task2 来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。 线程不安全示例如果多个线程对同一个共享数据进行访问而不采取同步操作的话，那么操作的结果是不一致的。 以下代码演示了 1000 个线程同时对 cnt 执行自增操作，操作结束之后它的值有可能小于 1000。 12345678910111213141516171819202122232425262728public class ThreadUnsafeExample { private int cnt = 0; public void add() { cnt++; } public int get() { return cnt; }}public static void main(String[] args) throws InterruptedException { final int threadSize = 1000; ThreadUnsafeExample example = new ThreadUnsafeExample(); final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) { executorService.execute(() -&gt; { example.add(); countDownLatch.countDown(); }); } countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());}997 Java 内存模型Java 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。 主内存与工作内存处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。 加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。 所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。 线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。 内存间交互操作Java 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作。 内存模型三大特性1. 原子性 Java 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，例如对一个 int 类型的变量执行 assign 赋值操作，这个操作就是原子性的。但是 Java 内存模型允许虚拟机将没有被 volatile 修饰的 64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。 有一个错误认识就是，int 等原子性的类型在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt 属于 int 类型变量，1000 个线程对它进行自增操作之后，得到的值为 997 而不是 1000。 为了方便讨论，将内存间的交互操作简化为 3 个：load、assign、store。 下图演示了两个线程同时对 cnt 进行操作，load、assign、store 这一系列操作整体上看不具备原子性，那么在 T1 修改 cnt 并且还没有将修改后的值写入主内存，T2 依然可以读入旧值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中 cnt 的值最后为 1 而不是 2。因此对 int 类型读写操作满足原子性只是说明 load、assign、store 这些单个操作具备原子性。 AtomicInteger 能保证多个线程修改的原子性。 使用 AtomicInteger 重写之前线程不安全的代码之后得到以下线程安全实现： 12345678910111213141516171819202122232425262728public class AtomicExample { private AtomicInteger cnt = new AtomicInteger(); public void add() { cnt.incrementAndGet(); } public int get() { return cnt.get(); }}public static void main(String[] args) throws InterruptedException { final int threadSize = 1000; AtomicExample example = new AtomicExample(); // 只修改这条语句 final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) { executorService.execute(() -&gt; { example.add(); countDownLatch.countDown(); }); } countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());}1000 除了使用原子类之外，也可以使用 synchronized 互斥锁来保证操作的原子性。它对应的内存间交互操作为：lock 和 unlock，在虚拟机实现上对应的字节码指令为 monitorenter 和 monitorexit。 12345678910111213141516171819202122232425262728public class AtomicSynchronizedExample { private int cnt = 0; public synchronized void add() { cnt++; } public synchronized int get() { return cnt; }}public static void main(String[] args) throws InterruptedException { final int threadSize = 1000; AtomicSynchronizedExample example = new AtomicSynchronizedExample(); final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) { executorService.execute(() -&gt; { example.add(); countDownLatch.countDown(); }); } countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());}1000 2. 可见性 可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。 主要有三种实现可见性的方式： volatile synchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。 final，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。 对前面的线程不安全示例中的 cnt 变量使用 volatile 修饰，不能解决线程不安全问题，因为 volatile 并不能保证操作的原子性。 3. 有序性 有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。 也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。 先行发生原则上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。 1. 单一线程原则 Single Thread rule 在一个线程内，在程序前面的操作先行发生于后面的操作。 2. 管程锁定规则 Monitor Lock Rule ​ 一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。 3.volatile 变量规则 Volatile Variable Rule 对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。 4. 线程启动规则 Thread Start Rule Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。 5. 线程加入规则 Thread Join Rule Thread 对象的结束先行发生于 join() 方法返回。 6. 线程中断规则 Thread Interruption Rule 对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。 7. 对象终结规则 Finalizer Rule 一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始。 8. 传递性 Transitivity 如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。 线程安全多个线程不管以何种方式访问某个类，并且在主调代码中不需要进行同步，都能表现正确的行为。 线程安全有以下几种实现方式： 不可变不可变（Immutable）的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。多线程环境下，应当尽量使对象成为不可变，来满足线程安全。 不可变的类型： final 关键字修饰的基本数据类型 String 枚举类型 Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。 对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。 12345678910public class ImmutableExample { public static void main(String[] args) { Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); Map&lt;String, Integer&gt; unmodifiableMap = Collections.unmodifiableMap(map); unmodifiableMap.put(\"a\", 1); }}Exception in thread \"main\" java.lang.UnsupportedOperationException at java.util.Collections$UnmodifiableMap.put(Collections.java:1457) at ImmutableExample.main(ImmutableExample.java:9) Collections.unmodifiableXXX() 先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常。 123public V put(K key, V value) { throw new UnsupportedOperationException();} 互斥同步synchronized 和 ReentrantLock。 非阻塞同步互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。 互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。 1. CAS 随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。 乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是：比较并交换（Compare-and-Swap，CAS）。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。 2. AtomicInteger J.U.C 包里面的整数原子类 AtomicInteger 的方法调用了 Unsafe 类的 CAS 操作。 以下代码使用了 AtomicInteger 执行了自增的操作。 12345private AtomicInteger cnt = new AtomicInteger();public void add() { cnt.incrementAndGet();} 以下代码是 incrementAndGet() 的源码，它调用了 Unsafe 的 getAndAddInt() 。 123public final int incrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, 1) + 1;} 以下代码是 getAndAddInt() 源码，var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 getIntVolatile(var1, var2) 得到旧的预期值，通过调用 compareAndSwapInt() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4。 可以看到 getAndAddInt() 在一个循环中进行，发生冲突的做法是不断的进行重试。 12345678public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;} 3. ABA 如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。 J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。 无同步方案要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。 1. 栈封闭 多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。 123456789101112131415161718public class StackClosedExample { public void add100() { int cnt = 0; for (int i = 0; i &lt; 100; i++) { cnt++; } System.out.println(cnt); }}public static void main(String[] args) { StackClosedExample example = new StackClosedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; example.add100()); executorService.execute(() -&gt; example.add100()); executorService.shutdown();}100100 2. 线程本地存储（Thread Local Storage） 如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。 可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。 对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。 12345678910111213141516171819202122public class ThreadLocalExample { public static void main(String[] args) { ThreadLocal threadLocal = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; { threadLocal.set(1); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(threadLocal.get()); threadLocal.remove(); }); Thread thread2 = new Thread(() -&gt; { threadLocal.set(2); threadLocal.remove(); }); thread1.start(); thread2.start(); }}1 为了理解 ThreadLocal，先看以下代码： 12345678910111213141516public class ThreadLocalExample1 { public static void main(String[] args) { ThreadLocal threadLocal1 = new ThreadLocal(); ThreadLocal threadLocal2 = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; { threadLocal1.set(1); threadLocal2.set(1); }); Thread thread2 = new Thread(() -&gt; { threadLocal1.set(2); threadLocal2.set(2); }); thread1.start(); thread2.start(); }} 它所对应的底层结构图为： 每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象。 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-&gt;value 键值对插入到该 Map 中。 12345678public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);} get() 方法类似。 12345678910111213public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; } } return setInitialValue();} ThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。 在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。 3. 可重入代码（Reentrant Code） 这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。 可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。 锁优化这里的锁优化主要是指 JVM 对 synchronized 的优化。 自旋锁互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。 自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。 在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。 锁消除锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。 锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。 对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁： 123public static String concatString(String s1, String s2, String s3) { return s1 + s2 + s3;} String 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作： 1234567public static String concatString(String s1, String s2, String s3) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();} 每个 append() 方法中都有一个同步块。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会逃逸到 concatString() 方法之外，其他线程无法访问到它，因此可以进行消除。 锁粗化如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。 上一节的示例代码中连续的 append() 方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个 append() 操作之前直至最后一个 append() 操作之后，这样只需要加锁一次就可以了。 轻量级锁JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。 以下是 HotSpot 虚拟机对象头的内存布局，这些数据被称为 Mark Word。其中 tag bits 对应了五个状态，这些状态在右侧的 state 表格中给出。除了 marked for gc 状态，其它四个状态已经在前面介绍过了。 下图左侧是一个线程的虚拟机栈，其中有一部分称为 Lock Record 的区域，这是在轻量级锁运行过程创建的，用于存放锁对象的 Mark Word。而右侧就是一个锁对象，包含了 Mark Word 和其它信息。 轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。 当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。 如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。 偏向锁偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。 当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。 当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。 多线程开发良好的实践 给线程起个有意义的名字，这样可以方便找 Bug。 缩小同步范围，从而减少锁争用。例如对于 synchronized，应该尽量使用同步块而不是同步方法。 多用同步工具少用 wait() 和 notify()。首先，CountDownLatch, CyclicBarrier, Semaphore 和 Exchanger 这些同步类简化了编码操作，而用 wait() 和 notify() 很难实现复杂控制流；其次，这些同步类是由最好的企业编写和维护，在后续的 JDK 中还会不断优化和完善。 使用 BlockingQueue 实现生产者消费者问题。 多用并发集合少用同步集合，例如应该使用 ConcurrentHashMap 而不是 Hashtable。 使用本地变量和不可变类来保证线程安全。 使用线程池而不是直接创建线程，这是因为创建线程代价很高，线程池可以有效地利用有限的线程来启动任务。 参考自来源感谢作者的辛勤整理，转载收藏，如有侵权，请评论说明，立即处理。","link":"/2019/08/07/Java并发相关知识点.html"},{"title":"Java 垃圾回收","text":"摘要之前上学的时候有这个一个梗，说在食堂里吃饭，吃完把餐盘端走清理的，是 C++ 程序员，吃完直接就走的，是 Java 程序员。🤔 之前上学的时候有这个一个梗，说在食堂里吃饭，吃完把餐盘端走清理的，是 C++ 程序员，吃完直接就走的，是 Java 程序员。🤔 确实，在 Java 的世界里，似乎我们不用对垃圾回收那么的专注，很多初学者不懂 GC，也依然能写出一个能用甚至还不错的程序或系统。但其实这并不代表 Java 的 GC 就不重要。相反，它是那么的重要和复杂，以至于出了问题，那些初学者除了打开 GC 日志，看着一堆0101的天文，啥也做不了。😯 今天我们就从头到尾完整地聊一聊 Java 的垃圾回收 什么是垃圾回收 垃圾回收（Garbage Collection，GC），顾名思义就是释放垃圾占用的空间，防止内存泄露。有效的使用可以使用的内存，对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收。 Java 语言出来之前，大家都在拼命的写 C 或者 C++ 的程序，而此时存在一个很大的矛盾，C++ 等语言创建对象要不断的去开辟空间，不用的时候又需要不断的去释放控件，既要写构造函数，又要写析构函数，很多时候都在重复的 allocated，然后不停的析构。于是，有人就提出，能不能写一段程序实现这块功能，每次创建，释放控件的时候复用这段代码，而无需重复的书写呢？ 1960年，基于 MIT 的 Lisp 首先提出了垃圾回收的概念，而这时 Java 还没有出世呢！所以实际上 GC 并不是Java的专利，GC 的历史远远大于 Java 的历史！ 怎么定义垃圾 既然我们要做垃圾回收，首先我们得搞清楚垃圾的定义是什么，哪些内存是需要回收的。 引用计数算法引用计数算法（Reachability Counting）是通过在对象头中分配一个空间来保存该对象被引用的次数（Reference Count）。如果该对象被其它对象引用，则它的引用计数加1，如果删除对该对象的引用，那么它的引用计数就减1，当该对象的引用计数为0时，那么该对象就会被回收。 1String m = new String(\"jack\"); 先创建一个字符串，这时候”jack”有一个引用，就是 m。 然后将 m 设置为 null，这时候”jack”的引用次数就等于0了，在引用计数算法中，意味着这块内容就需要被回收了。 1m = null; 引用计数算法是将垃圾回收分摊到整个应用程序的运行当中了，而不是在进行垃圾收集时，要挂起整个应用的运行，直到对堆中所有对象的处理都结束。因此，采用引用计数的垃圾收集不属于严格意义上的”Stop-The-World”的垃圾收集机制。 看似很美好，但我们知道JVM的垃圾回收就是”Stop-The-World”的，那是什么原因导致我们最终放弃了引用计数算法呢？看下面的例子。 1234567891011121314151617public class ReferenceCountingGC { public Object instance; public ReferenceCountingGC(String name){}}public static void testGC(){ ReferenceCountingGC a = new ReferenceCountingGC(\"objA\"); ReferenceCountingGC b = new ReferenceCountingGC(\"objB\"); a.instance = b; b.instance = a; a = null; b = null;} 定义2个对象 相互引用 置空各自的声明引用 我们可以看到，最后这2个对象已经不可能再被访问了，但由于他们相互引用着对方，导致它们的引用计数永远都不会为0，通过引用计数算法，也就永远无法通知GC收集器回收它们。 可达性分析算法 可达性分析算法（Reachability Analysis）的基本思路是，通过一些被称为引用链（GC Roots）的对象作为起点，从这些节点开始向下搜索，搜索走过的路径被称为（Reference Chain)，当一个对象到 GC Roots 没有任何引用链相连时（即从 GC Roots 节点到该节点不可达），则证明该对象是不可用的。 通过可达性算法，成功解决了引用计数所无法解决的问题-“循环依赖”，只要你无法与 GC Root 建立直接或间接的连接，系统就会判定你为可回收对象。那这样就引申出了另一个问题，哪些属于 GC Root。 Java 内存区域在 Java 语言中，可作为 GC Root 的对象包括以下4种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中 JNI（即一般说的 Native 方法）引用的对象 虚拟机栈（栈帧中的本地变量表）中引用的对象此时的 s，即为 GC Root，当s置空时，localParameter 对象也断掉了与 GC Root 的引用链，将被回收。 12345678public class StackLocalParameter { public StackLocalParameter(String name){}}public static void testGC(){ StackLocalParameter s = new StackLocalParameter(\"localParameter\"); s = null;} 方法区中类静态属性引用的对象s 为 GC Root，s 置为 null，经过 GC 后，s 所指向的 properties 对象由于无法与 GC Root 建立关系被回收。 而 m 作为类的静态属性，也属于 GC Root，parameter 对象依然与 GC root 建立着连接，所以此时 parameter 对象并不会被回收。 12345678910public class MethodAreaStaicProperties { public static MethodAreaStaicProperties m; public MethodAreaStaicProperties(String name){}}public static void testGC(){ MethodAreaStaicProperties s = new MethodAreaStaicProperties(\"properties\"); s.m = new MethodAreaStaicProperties(\"parameter\"); s = null;} 方法区中常量引用的对象m 即为方法区中的常量引用，也为 GC Root，s 置为 null 后，final 对象也不会因没有与 GC Root 建立联系而被回收。 123456789public class MethodAreaStaicProperties { public static final MethodAreaStaicProperties m = MethodAreaStaicProperties(\"final\"); public MethodAreaStaicProperties(String name){}}public static void testGC(){ MethodAreaStaicProperties s = new MethodAreaStaicProperties(\"staticProperties\"); s = null;} 本地方法栈中引用的对象任何 Native 接口都会使用某种本地方法栈，实现的本地方法接口是使用 C 连接模型的话，那么它的本地方法栈就是 C 栈。当线程调用 Java 方法时，虚拟机会创建一个新的栈帧并压入 Java 栈。然而当它调用的是本地方法时，虚拟机会保持 Java 栈不变，不再在线程的 Java 栈中压入新的帧，虚拟机只是简单地动态连接并直接调用指定的本地方法。 怎么回收垃圾在确定了哪些垃圾可以被回收后，垃圾收集器要做的事情就是开始进行垃圾回收，但是这里面涉及到一个问题是：如何高效地进行垃圾回收。由于Java虚拟机规范并没有对如何实现垃圾收集器做出明确的规定，因此各个厂商的虚拟机可以采用不同的方式来实现垃圾收集器，这里我们讨论几种常见的垃圾收集算法的核心思想。 标记 — 清除算法 标记清除算法（Mark-Sweep）是最基础的一种垃圾回收算法，它分为2部分，先把内存区域中的这些对象进行标记，哪些属于可回收标记出来，然后把这些垃圾拎出来清理掉。就像上图一样，清理掉的垃圾就变成未使用的内存区域，等待被再次使用。 这逻辑再清晰不过了，并且也很好操作，但它存在一个很大的问题，那就是内存碎片。 上图中等方块的假设是 2M，小一些的是 1M，大一些的是 4M。等我们回收完，内存就会切成了很多段。我们知道开辟内存空间时，需要的是连续的内存区域，这时候我们需要一个 2M的内存区域，其中有2个 1M 是没法用的。这样就导致，其实我们本身还有这么多的内存的，但却用不了。 复制算法 复制算法（Copying）是在标记清除算法上演化而来，解决标记清除算法的内存碎片问题。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。保证了内存的连续可用，内存分配时也就不用考虑内存碎片等复杂情况，逻辑清晰，运行高效。 上面的图很清楚，也很明显的暴露了另一个问题，合着我这140平的大三房，只能当70平米的小两房来使？代价实在太高。 标记整理算法 标记整理算法（Mark-Compact）标记过程仍然与标记 — 清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，再清理掉端边界以外的内存区域。 标记整理算法一方面在标记-清除算法上做了升级，解决了内存碎片的问题，也规避了复制算法只能利用一半内存区域的弊端。看起来很美好，但从上图可以看到，它对内存变动更频繁，需要整理所有存活对象的引用地址，在效率上比复制算法要差很多。 分代收集算法分代收集算法（Generational Collection）严格来说并不是一种思想或理论，而是融合上述3种基础的算法思想，而产生的针对不同情况所采用不同算法的一套组合拳。对象存活周期的不同将内存划分为几块。一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用标记-清理或者标记 — 整理算法来进行回收。so，另一个问题来了，那内存区域到底被分为哪几块，每一块又有什么特别适合什么算法呢？ 内存模型与回收策略 Java 堆（Java Heap）是JVM所管理的内存中最大的一块，堆又是垃圾收集器管理的主要区域，这里我们主要分析一下 Java 堆的结构。 Java 堆主要分为2个区域-年轻代与老年代，其中年轻代又分 Eden 区和 Survivor 区，其中 Survivor 区又分 From 和 To 2个区。可能这时候大家会有疑问，为什么需要 Survivor 区，为什么Survivor 还要分2个区。不着急，我们从头到尾，看看对象到底是怎么来的，而它又是怎么没的。 Eden 区IBM 公司的专业研究表明，有将近98%的对象是朝生夕死，所以针对这一现状，大多数情况下，对象会在新生代 Eden 区中进行分配，当 Eden 区没有足够空间进行分配时，虚拟机会发起一次 Minor GC，Minor GC 相比 Major GC 更频繁，回收速度也更快。 通过 Minor GC 之后，Eden 会被清空，Eden 区中绝大部分对象会被回收，而那些无需回收的存活对象，将会进到 Survivor 的 From 区（若 From 区不够，则直接进入 Old 区）。 Survivor 区Survivor 区相当于是 Eden 区和 Old 区的一个缓冲，类似于我们交通灯中的黄灯。Survivor 又分为2个区，一个是 From 区，一个是 To 区。每次执行 Minor GC，会将 Eden 区和 From 存活的对象放到 Survivor 的 To 区（如果 To 区不够，则直接进入 Old 区）。 为啥需要？不就是新生代到老年代么，直接 Eden 到 Old 不好了吗，为啥要这么复杂。想想如果没有 Survivor 区，Eden 区每进行一次 Minor GC，存活的对象就会被送到老年代，老年代很快就会被填满。而有很多对象虽然一次 Minor GC 没有消灭，但其实也并不会蹦跶多久，或许第二次，第三次就需要被清除。这时候移入老年区，很明显不是一个明智的决定。 所以，Survivor 的存在意义就是减少被送到老年代的对象，进而减少 Major GC 的发生。Survivor 的预筛选保证，只有经历16次 Minor GC 还能在新生代中存活的对象，才会被送到老年代。 为啥需要俩？设置两个 Survivor 区最大的好处就是解决内存碎片化。 我们先假设一下，Survivor 如果只有一个区域会怎样。Minor GC 执行后，Eden 区被清空了，存活的对象放到了 Survivor 区，而之前 Survivor 区中的对象，可能也有一些是需要被清除的。问题来了，这时候我们怎么清除它们？在这种场景下，我们只能标记清除，而我们知道标记清除最大的问题就是内存碎片，在新生代这种经常会消亡的区域，采用标记清除必然会让内存产生严重的碎片化。因为 Survivor 有2个区域，所以每次 Minor GC，会将之前 Eden 区和 From 区中的存活对象复制到 To 区域。第二次 Minor GC 时，From 与 To 职责兑换，这时候会将 Eden 区和 To 区中的存活对象再复制到 From 区域，以此反复。 这种机制最大的好处就是，整个过程中，永远有一个 Survivor space 是空的，另一个非空的 Survivor space 是无碎片的。那么，Survivor 为什么不分更多块呢？比方说分成三个、四个、五个?显然，如果 Survivor 区再细分下去，每一块的空间就会比较小，容易导致 Survivor 区满，两块 Survivor 区可能是经过权衡之后的最佳方案。 Old 区老年代占据着2/3的堆内存空间，只有在 Major GC 的时候才会进行清理，每次 GC 都会触发“Stop-The-World”。内存越大，STW 的时间也越长，所以内存也不仅仅是越大就越好。由于复制算法在对象存活率较高的老年代会进行很多次的复制操作，效率很低，所以老年代这里采用的是标记 — 整理算法。 除了上述所说，在内存担保机制下，无法安置的对象会直接进到老年代，以下几种情况也会进入老年代。 大对象大对象指需要大量连续内存空间的对象，这部分对象不管是不是“朝生夕死”，都会直接进到老年代。这样做主要是为了避免在 Eden 区及2个 Survivor 区之间发生大量的内存复制。当你的系统有非常多“朝生夕死”的大对象时，得注意了。 长期存活对象虚拟机给每个对象定义了一个对象年龄（Age）计数器。正常情况下对象会不断的在 Survivor 的 From 区与 To 区之间移动，对象在 Survivor 区中每经历一次 Minor GC，年龄就增加1岁。当年龄增加到15岁时，这时候就会被转移到老年代。当然，这里的15，JVM 也支持进行特殊设置。 动态对象年龄虚拟机并不重视要求对象年龄必须到15岁，才会放入老年区，如果 Survivor 空间中相同年龄所有对象大小的总合大于 Survivor 空间的一半，年龄大于等于该年龄的对象就可以直接进去老年区，无需等你“成年”。 这其实有点类似于负载均衡，轮询是负载均衡的一种，保证每台机器都分得同样的请求。看似很均衡，但每台机的硬件不通，健康状况不同，我们还可以基于每台机接受的请求数，或每台机的响应时间等，来调整我们的负载均衡算法。 参考自 .","link":"/2019/07/24/Java-垃圾回收.html"},{"title":"Java BIO NIO AIO区别与使用","text":"摘要BIO 全称Block-IO 是一种同步且阻塞的通信模式。是一个比较传统的通信方式，模式简单，使用方便。但并发处理能力低，通信耗时，依赖网速。 Java BIO使用BIO实现文件的读取和写入。 123456789101112131415161718192021222324252627282930313233343536//Initializes The ObjectUser1 user = new User1();user.setName(\"hollis\");user.setAge(23);System.out.println(user);//Write Obj to FileObjectOutputStream oos = null;try { oos = new ObjectOutputStream(new FileOutputStream(\"tempFile\")); oos.writeObject(user);} catch (IOException e) { e.printStackTrace();} finally { IOUtils.closeQuietly(oos);}//Read Obj from FileFile file = new File(\"tempFile\");ObjectInputStream ois = null;try { ois = new ObjectInputStream(new FileInputStream(file)); User1 newUser = (User1) ois.readObject(); System.out.println(newUser);} catch (IOException e) { e.printStackTrace();} catch (ClassNotFoundException e) { e.printStackTrace();} finally { IOUtils.closeQuietly(ois); try { FileUtils.forceDelete(file); } catch (IOException e) { e.printStackTrace(); }} Java NIOJava NIO，全程 Non-Block IO ，是Java SE 1.4版以后，针对网络传输效能优化的新功能。是一种非阻塞同步的通信模式。NIO 与原来的 I/O 有同样的作用和目的, 他们之间最重要的区别是数据打包和传输的方式。原来的 I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。面向流的 I/O 系统一次一个字节地处理数据。一个输入流产生一个字节的数据，一个输出流消费一个字节的数据。面向块的 I/O 系统以块的形式处理数据。每一个操作都在一步中产生或者消费一个数据块。按块处理数据比按(流式的)字节处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364static void readNIO() { String pathname = \"C:\\\\Users\\\\adew\\\\Desktop\\\\jd-gui.cfg\"; FileInputStream fin = null; try { fin = new FileInputStream(new File(pathname)); FileChannel channel = fin.getChannel(); int capacity = 100;// 字节 ByteBuffer bf = ByteBuffer.allocate(capacity); int length = -1; while ((length = channel.read(bf)) != -1) { bf.clear(); byte[] bytes = bf.array(); System.out.write(bytes, 0, length); System.out.println(); } channel.close(); } catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } finally { if (fin != null) { try { fin.close(); } catch (IOException e) { e.printStackTrace(); } } } } static void writeNIO() { String filename = \"out.txt\"; FileOutputStream fos = null; try { fos = new FileOutputStream(new File(filename)); FileChannel channel = fos.getChannel(); ByteBuffer src = Charset.forName(\"utf8\").encode(\"你好你好你好你好你好\"); int length = 0; while ((length = channel.write(src)) != 0) { System.out.println(\"写入长度:\" + length); } } catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } finally { if (fos != null) { try { fos.close(); } catch (IOException e) { e.printStackTrace(); } } } } Java AIOJava AIO，全程 Asynchronous IO，是异步非阻塞的IO。是一种非阻塞异步的通信模式。在NIO的基础上引入了新的异步通道的概念，并提供了异步文件通道和异步套接字通道的实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ReadFromFile { public static void main(String[] args) throws Exception { Path file = Paths.get(\"/usr/a.txt\"); AsynchronousFileChannel channel = AsynchronousFileChannel.open(file); ByteBuffer buffer = ByteBuffer.allocate(100_000); Future&lt;Integer&gt; result = channel.read(buffer, 0); while (!result.isDone()) { ProfitCalculator.calculateTax(); } Integer bytesRead = result.get(); System.out.println(\"Bytes read [\" + bytesRead + \"]\"); }}class ProfitCalculator { public ProfitCalculator() { } public static void calculateTax() { }}public class WriteToFile { public static void main(String[] args) throws Exception { AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open( Paths.get(\"/asynchronous.txt\"), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE); CompletionHandler&lt;Integer, Object&gt; handler = new CompletionHandler&lt;Integer, Object&gt;() { @Override public void completed(Integer result, Object attachment) { System.out.println(\"Attachment: \" + attachment + \" \" + result + \" bytes written\"); System.out.println(\"CompletionHandler Thread ID: \" + Thread.currentThread().getId()); } @Override public void failed(Throwable e, Object attachment) { System.err.println(\"Attachment: \" + attachment + \" failed with:\"); e.printStackTrace(); } }; System.out.println(\"Main Thread ID: \" + Thread.currentThread().getId()); fileChannel.write(ByteBuffer.wrap(\"Sample\".getBytes()), 0, \"First Write\", handler); fileChannel.write(ByteBuffer.wrap(\"Box\".getBytes()), 0, \"Second Write\", handler); }} 三种IO的区别首先，我们站在宏观的角度，重新画一下重点： BIO （Blocking I/O）：同步阻塞I/O模式。 NIO （New I/O）：同步非阻塞模式。 AIO （Asynchronous I/O）：异步非阻塞I/O模型。 同步请求，A调用B，B的处理是同步的，在处理完之前他不会通知A，只有处理完之后才会明确的通知A。 异步请求，A调用B，B的处理是异步的，B在接到请求后先告诉A我已经接到请求了，然后异步去处理，处理完之后通过回调等方式再通知A。 所以说，同步和异步最大的区别就是被调用方的执行方式和返回时机。同步指的是被调用方做完事情之后再返回，异步指的是被调用方先返回，然后再做事情，做完之后再想办法通知调用方。 阻塞请求，A调用B，A一直等着B的返回，别的事情什么也不干。 非阻塞请求，A调用B，A不用一直等着B的返回，先去忙别的事情了。 所以说，阻塞非阻塞最大的区别就是在被调用方返回结果之前的这段时间内，调用方是否一直等待。阻塞指的是调用方一直等待别的事情什么都不做。非阻塞指的是调用方先去忙别的事情。 同步阻塞模式：这种模式下，我们的工作模式是先来到厨房，开始烧水，并坐在水壶面前一直等着水烧开。 同步非阻塞模式：这种模式下，我们的工作模式是先来到厨房，开始烧水，但是我们不一直坐在水壶前面等，而是回到客厅看电视，然后每隔几分钟到厨房看一下水有没有烧开。 异步非阻塞I/O模型：这种模式下，我们的工作模式是先来到厨房，开始烧水，我们不一一直坐在水壶前面等，也不隔一段时间去看一下，而是在客厅看电视，水壶上面有个开关，水烧开之后他会通知我。 阻塞VS非阻塞：人是否坐在水壶前面一直等。 同步VS异步：水壶是不是在水烧开之后主动通知人。 适用场景BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。 NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。 AIO方式适用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。 参考自 .","link":"/2019/07/19/Java-BIO-NIO-AIO区别与使用.html"},{"title":"常见sql错误写法","text":"摘要sql语句应用不当，可能仅仅一个顺序的不同，往往会带来成千上万倍的耗时问题。 1、LIMIT 语句分页查询是最常用的场景之一，但也通常也是最容易出问题的地方。比如对于下面简单的语句，一般 DBA 想到的办法是在 type, name, create_time 字段上加组合索引。这样条件排序都能有效的利用到索引，性能迅速提升。 123456SELECT * FROM operation WHERE type = 'SQLStats' AND name = 'SlowLog' ORDER BY create_time LIMIT 1000, 10; 好吧，可能90%以上的 DBA 解决该问题就到此为止。但当 LIMIT 子句变成 “LIMIT 1000000,10” 时，程序员仍然会抱怨：我只取10条记录为什么还是慢？ 要知道数据库也并不知道第1000000条记录从什么地方开始，即使有索引也需要从头计算一次。出现这种性能问题，多数情形下是程序员偷懒了。 在前端数据浏览翻页，或者大数据分批导出等场景下，是可以将上一页的最大值当成参数作为查询条件的。SQL 重新设计如下： 123456SELECT * FROM operation WHERE type = 'SQLStats' AND name = 'SlowLog' AND create_time &gt; '2017-03-16 14:00:00' ORDER BY create_time limit 10; 在新设计下查询时间基本固定，不会随着数据量的增长而发生变化。 2、隐式转换SQL语句中查询变量和字段定义类型不匹配是另一个常见的错误。比如下面的语句： 123456mysql&gt; explain extended SELECT * &gt; FROM my_balance b &gt; WHERE b.bpn = 14000000123 &gt; AND b.isverified IS NULL ;mysql&gt; show warnings;| Warning | 1739 | Cannot use ref access on index 'bpn' due to type or collation conversion on field 'bpn' 其中字段 bpn 的定义为 varchar(20)，MySQL 的策略是将字符串转换为数字之后再比较。函数作用于表字段，索引失效。 上述情况可能是应用程序框架自动填入的参数，而不是程序员的原意。现在应用框架很多很繁杂，使用方便的同时也小心它可能给自己挖坑。 3、关联更新、删除虽然 MySQL5.6 引入了物化特性，但需要特别注意它目前仅仅针对查询语句的优化。对于更新或删除需要手工重写成 JOIN。 比如下面 UPDATE 语句，MySQL 实际执行的是循环/嵌套子查询（DEPENDENT SUBQUERY)，其执行时间可想而知。 1234567891011UPDATE operation o SET status = 'applying' WHERE o.id IN (SELECT id FROM (SELECT o.id, o.status FROM operation o WHERE o.group = 123 AND o.status NOT IN ( 'done' ) ORDER BY o.parent, o.id LIMIT 1) t); 执行计划： 1234567+----+--------------------+-------+-------+---------------+---------+---------+-------+------+-----------------------------------------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+--------------------+-------+-------+---------------+---------+---------+-------+------+-----------------------------------------------------+| 1 | PRIMARY | o | index | | PRIMARY | 8 | | 24 | Using where; Using temporary || 2 | DEPENDENT SUBQUERY | | | | | | | | Impossible WHERE noticed after reading const tables || 3 | DERIVED | o | ref | idx_2,idx_5 | idx_5 | 8 | const | 1 | Using where; Using filesort |+----+--------------------+-------+-------+---------------+---------+---------+-------+------+-----------------------------------------------------+ 重写为 JOIN 之后，子查询的选择模式从 DEPENDENT SUBQUERY 变成 DERIVED，执行速度大大加快，从7秒降低到2毫秒。 1234567891011UPDATE operation o JOIN (SELECT o.id, o.status FROM operation o WHERE o.group = 123 AND o.status NOT IN ( 'done' ) ORDER BY o.parent, o.id LIMIT 1) t ON o.id = t.id SET status = 'applying' 执行计划简化为： 123456+----+-------------+-------+------+---------------+-------+---------+-------+------+-----------------------------------------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+------+---------------+-------+---------+-------+------+-----------------------------------------------------+| 1 | PRIMARY | | | | | | | | Impossible WHERE noticed after reading const tables || 2 | DERIVED | o | ref | idx_2,idx_5 | idx_5 | 8 | const | 1 | Using where; Using filesort |+----+-------------+-------+------+---------------+-------+---------+-------+------+-----------------------------------------------------+ 4、混合排序MySQL 不能利用索引进行混合排序。但在某些场景，还是有机会使用特殊方法提升性能的。 123456SELECT * FROM my_order o INNER JOIN my_appraise a ON a.orderid = o.id ORDER BY a.is_reply ASC, a.appraise_time DESC LIMIT 0, 20 执行计划显示为全表扫描： 123456+----+-------------+-------+--------+-------------+---------+---------+---------------+---------+-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra +----+-------------+-------+--------+-------------+---------+---------+---------------+---------+-+| 1 | SIMPLE | a | ALL | idx_orderid | NULL | NULL | NULL | 1967647 | Using filesort || 1 | SIMPLE | o | eq_ref | PRIMARY | PRIMARY | 122 | a.orderid | 1 | NULL |+----+-------------+-------+--------+---------+---------+---------+-----------------+---------+-+ 由于 is_reply 只有0和1两种状态，我们按照下面的方法重写后，执行时间从1.58秒降低到2毫秒。 12345678910111213141516171819SELECT * FROM ((SELECT * FROM my_order o INNER JOIN my_appraise a ON a.orderid = o.id AND is_reply = 0 ORDER BY appraise_time DESC LIMIT 0, 20) UNION ALL (SELECT * FROM my_order o INNER JOIN my_appraise a ON a.orderid = o.id AND is_reply = 1 ORDER BY appraise_time DESC LIMIT 0, 20)) t ORDER BY is_reply ASC, appraisetime DESC LIMIT 20; 5、EXISTS语句MySQL 对待 EXISTS 子句时，仍然采用嵌套子查询的执行方式。如下面的 SQL 语句： 1234567891011SELECT *FROM my_neighbor n LEFT JOIN my_neighbor_apply sra ON n.id = sra.neighbor_id AND sra.user_id = 'xxx' WHERE n.topic_status &lt; 4 AND EXISTS(SELECT 1 FROM message_info m WHERE n.id = m.neighbor_id AND m.inuser = 'xxx') AND n.topic_type &lt;&gt; 5 执行计划为： 1234567+----+--------------------+-------+------+-----+------------------------------------------+---------+-------+---------+ -----+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+--------------------+-------+------+ -----+------------------------------------------+---------+-------+---------+ -----+| 1 | PRIMARY | n | ALL | | NULL | NULL | NULL | 1086041 | Using where || 1 | PRIMARY | sra | ref | | idx_user_id | 123 | const | 1 | Using where || 2 | DEPENDENT SUBQUERY | m | ref | | idx_message_info | 122 | const | 1 | Using index condition; Using where |+----+--------------------+-------+------+ -----+------------------------------------------+---------+-------+---------+ -----+ 去掉 exists 更改为 join，能够避免嵌套子查询，将执行时间从1.93秒降低为1毫秒。 12345678910SELECT *FROM my_neighbor n INNER JOIN message_info m ON n.id = m.neighbor_id AND m.inuser = 'xxx' LEFT JOIN my_neighbor_apply sra ON n.id = sra.neighbor_id AND sra.user_id = 'xxx' WHERE n.topic_status &lt; 4 AND n.topic_type &lt;&gt; 5 新的执行计划： 1234567+----+-------------+-------+--------+ -----+------------------------------------------+---------+ -----+------+ -----+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+--------+ -----+------------------------------------------+---------+ -----+------+ -----+| 1 | SIMPLE | m | ref | | idx_message_info | 122 | const | 1 | Using index condition || 1 | SIMPLE | n | eq_ref | | PRIMARY | 122 | ighbor_id | 1 | Using where || 1 | SIMPLE | sra | ref | | idx_user_id | 123 | const | 1 | Using where |+----+-------------+-------+--------+ -----+------------------------------------------+---------+ -----+------+ -----+ 6、条件下推外部查询条件不能够下推到复杂的视图或子查询的情况有： 聚合子查询； 含有 LIMIT 的子查询； UNION 或 UNION ALL 子查询； 输出字段中的子查询； 如下面的语句，从执行计划可以看出其条件作用于聚合子查询之后： 123456SELECT * FROM (SELECT target, Count(*) FROM operation GROUP BY target) t WHERE target = 'rm-xxxx' 123456+----+-------------+------------+-------+---------------+-------------+---------+-------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+-------+---------------+-------------+---------+-------+------+-------------+| 1 | PRIMARY | &lt;derived2&gt; | ref | &lt;auto_key0&gt; | &lt;auto_key0&gt; | 514 | const | 2 | Using where || 2 | DERIVED | operation | index | idx_4 | idx_4 | 519 | NULL | 20 | Using index |+----+-------------+------------+-------+---------------+-------------+---------+-------+------+-------------+ 确定从语义上查询条件可以直接下推后，重写如下： 12345SELECT target, Count(*) FROM operation WHERE target = 'rm-xxxx' GROUP BY target 执行计划变为： 12345+----+-------------+-----------+------+---------------+-------+---------+-------+------+--------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-----------+------+---------------+-------+---------+-------+------+--------------------+| 1 | SIMPLE | operation | ref | idx_4 | idx_4 | 514 | const | 1 | Using where; Using index |+----+-------------+-----------+------+---------------+-------+---------+-------+------+--------------------+ 关于 MySQL 外部条件不能下推的详细解释说明请参考文章： 7、提前缩小范围先上初始 SQL 语句： 12345678910SELECT * FROM my_order o LEFT JOIN my_userinfo u ON o.uid = u.uid LEFT JOIN my_productinfo p ON o.pid = p.pid WHERE ( o.display = 0 ) AND ( o.ostaus = 1 ) ORDER BY o.selltime DESC LIMIT 0, 15 该SQL语句原意是：先做一系列的左连接，然后排序取前15条记录。从执行计划也可以看出，最后一步估算排序记录数为90万，时间消耗为12秒。 1234567+----+-------------+-------+--------+---------------+---------+---------+-----------------+--------+----------------------------------------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+--------+---------------+---------+---------+-----------------+--------+----------------------------------------------------+| 1 | SIMPLE | o | ALL | NULL | NULL | NULL | NULL | 909119 | Using where; Using temporary; Using filesort || 1 | SIMPLE | u | eq_ref | PRIMARY | PRIMARY | 4 | o.uid | 1 | NULL || 1 | SIMPLE | p | ALL | PRIMARY | NULL | NULL | NULL | 6 | Using where; Using join buffer (Block Nested Loop) |+----+-------------+-------+--------+---------------+---------+---------+-----------------+--------+----------------------------------------------------+ 由于最后 WHERE 条件以及排序均针对最左主表，因此可以先对 my_order 排序提前缩小数据量再做左连接。SQL 重写后如下，执行时间缩小为1毫秒左右。 123456789101112131415SELECT * FROM (SELECT * FROM my_order o WHERE ( o.display = 0 ) AND ( o.ostaus = 1 ) ORDER BY o.selltime DESC LIMIT 0, 15) o LEFT JOIN my_userinfo u ON o.uid = u.uid LEFT JOIN my_productinfo p ON o.pid = p.pid ORDER BY o.selltime DESClimit 0, 15 再检查执行计划：子查询物化后（select_type=DERIVED)参与 JOIN。虽然估算行扫描仍然为90万，但是利用了索引以及 LIMIT 子句后，实际执行时间变得很小。 12345678+----+-------------+------------+--------+---------------+---------+---------+-------+--------+----------------------------------------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+--------+---------------+---------+---------+-------+--------+----------------------------------------------------+| 1 | PRIMARY | &lt;derived2&gt; | ALL | NULL | NULL | NULL | NULL | 15 | Using temporary; Using filesort || 1 | PRIMARY | u | eq_ref | PRIMARY | PRIMARY | 4 | o.uid | 1 | NULL || 1 | PRIMARY | p | ALL | PRIMARY | NULL | NULL | NULL | 6 | Using where; Using join buffer (Block Nested Loop) || 2 | DERIVED | o | index | NULL | idx_1 | 5 | NULL | 909112 | Using where |+----+-------------+------------+--------+---------------+---------+---------+-------+--------+----------------------------------------------------+ 8、中间结果集下推再来看下面这个已经初步优化过的例子(左连接中的主表优先作用查询条件)： 1234567891011121314SELECT a.*, c.allocated FROM ( SELECT resourceid FROM my_distribute d WHERE isdelete = 0 AND cusmanagercode = '1234567' ORDER BY salecode limit 20) a LEFT JOIN ( SELECT resourcesid， sum(ifnull(allocation, 0) * 12345) allocated FROM my_resources GROUP BY resourcesid) c ON a.resourceid = c.resourcesid 那么该语句还存在其它问题吗？不难看出子查询 c 是全表聚合查询，在表数量特别大的情况下会导致整个语句的性能下降。 其实对于子查询 c，左连接最后结果集只关心能和主表 resourceid 能匹配的数据。因此我们可以重写语句如下，执行时间从原来的2秒下降到2毫秒。 123456789101112131415161718192021SELECT a.*, c.allocated FROM ( SELECT resourceid FROM my_distribute d WHERE isdelete = 0 AND cusmanagercode = '1234567' ORDER BY salecode limit 20) a LEFT JOIN ( SELECT resourcesid， sum(ifnull(allocation, 0) * 12345) allocated FROM my_resources r, ( SELECT resourceid FROM my_distribute d WHERE isdelete = 0 AND cusmanagercode = '1234567' ORDER BY salecode limit 20) a WHERE r.resourcesid = a.resourcesid GROUP BY resourcesid) c ON a.resourceid = c.resourcesid 但是子查询 a 在我们的SQL语句中出现了多次。这种写法不仅存在额外的开销，还使得整个语句显的繁杂。使用 WITH 语句再次重写： 123456789101112131415161718WITH a AS ( SELECT resourceid FROM my_distribute d WHERE isdelete = 0 AND cusmanagercode = '1234567' ORDER BY salecode limit 20)SELECT a.*, c.allocated FROM a LEFT JOIN ( SELECT resourcesid， sum(ifnull(allocation, 0) * 12345) allocated FROM my_resources r, a WHERE r.resourcesid = a.resourcesid GROUP BY resourcesid) c ON a.resourceid = c.resourcesid 总结数据库编译器产生执行计划，决定着SQL的实际执行方式。但是编译器只是尽力服务，所有数据库的编译器都不是尽善尽美的。 上述提到的多数场景，在其它数据库中也存在性能问题。了解数据库编译器的特性，才能避规其短处，写出高性能的SQL语句。 程序员在设计数据模型以及编写SQL语句时，要把算法的思想或意识带进来。 编写复杂SQL语句要养成使用 WITH 语句的习惯。简洁且思路清晰的SQL语句也能减小数据库的负担 。转自","link":"/2019/07/05/常见sql错误写法.html"},{"title":"mysql索引优化方案","text":"摘要mysql自带优化：先执行explain sql，在执行explain extended sql，得到优化结果，show warnings显示优化后的结果sql. 索引基数基数是数据列所包含的不同值的数量，例如，某个数据列包含值 1、3、7、4、7、3，那么它的基数就是 4。索引的基数相对于数据表行数较高（也就是说，列中包含很多不同的值，重复的值很少）的时候，它的工作效果最好。如果某数据列含有很多不同的年龄，索引会很快地分辨数据行；如果某个数据列用于记录性别（只有“M”和“F”两种值），那么索引的用处就不大；如果值出现的几率几乎相等，那么无论搜索哪个值都可能得到一半的数据行。在这些情况下，最好根本不要使用索引，因为查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。惯用的百分比界线是“30%”。 索引失效原因索引失效的原因有如下几点： 对索引列运算，运算包括（+、-、*、/、！、&lt;&gt;、%、like’%_’（% 放在前面）。 类型错误，如字段类型为 varchar，where 条件用 number。 对索引应用内部函数，这种情况下应该要建立基于函数的索引。例如 select * from template t where ROUND (t.logicdb_id) = 1，此时应该建 ROUND (t.logicdb_id) 为索引。 MySQL 8.0 开始支持函数索引，5.7 可以通过虚拟列的方式来支持，之前只能新建一个 ROUND (t.logicdb_id) 列然后去维护。 如果条件有 or，即使其中有条件带索引也不会使用（这也是为什么建议少使用 or 的原因），如果想使用 or，又想索引有效，只能将 or 条件中的每个列加上索引。 如果列类型是字符串，那一定要在条件中数据使用引号，否则不使用索引。 B-tree 索引 is null 不会走，is not null 会走，位图索引 is null，is not null 都会走。 组合索引遵循最左原则。 索引的建立索引的建立需要注意以下几点： 最重要的肯定是根据业务经常查询的语句。 尽量选择区分度高的列作为索引，区分度的公式是$$COUNT(DISTINCT空格col) / COUNT(*):表示字段不重复的比率，比率越大我们扫描的记录数就越少。$$ 如果业务中唯一特性最好建立唯一键，一方面可以保证数据的正确性，另一方面索引的效率能大大提高。 EXPLIAN 中有用的信息EXPLIAN 基本用法如下： desc 或者 explain 加上你的 SQL。 explain extended 加上你的 SQL，然后通过 show warnings 可以查看实际执行的语句，这一点也是非常有用的，很多时候不同的写法经 SQL 分析后，实际执行的代码是一样的。 提高性能的特性EXPLIAN 提高性能的特性如下： 索引覆盖(covering index)：需要查询的数据在索引上都可以查到不需要回表 EXTRA 列显示 using index。 ICP特性(Index Condition Pushdown)：本来 index 仅仅是 data access 的一种访问模式，存数引擎通过索引回表获取的数据会传递到 MySQL Server 层进行 where 条件过滤。 5.6 版本开始当 ICP 打开时，如果部分 where 条件能使用索引的字段，MySQL Server 会把这部分下推到引擎层，可以利用 index 过滤的 where 条件在存储引擎层进行数据过滤。 EXTRA 显示 using index condition。需要了解 MySQL 的架构图分为 Server 和存储引擎层。 索引合并(index merge)：对多个索引分别进行条件扫描，然后将它们各自的结果进行合并(intersect/union)。 一般用 or 会用到，如果是 AND 条件，考虑建立复合索引。EXPLAIN 显示的索引类型会显示 index_merge，EXTRA 会显示具体的合并算法和用到的索引。 Extra字段Extra 字段使用： using filesort：说明 MySQL 会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。 MySQL 中无法利用索引完成的排序操作称为“文件排序”，其实不一定是文件排序，内部使用的是快排。 using temporary：使用了临时表保存中间结果，MySQL 在对查询结果排序时使用临时表。常见于排序 order by 和分组查询 group by。 using index：表示相应的 SELECT 操作中使用了覆盖索引（Covering Index），避免访问了表的数据行，效率不错。 impossible where：where 子句的值总是 false，不能用来获取任何元组。 select tables optimized away：在没有 group by 子句的情况下基于索引优化 MIN/MAX 操作或者对于 MyISAM 存储引擎优化 COUNT(*) 操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。 distinct：优化 distinct 操作，在找到第一匹配的元组后即停止找同样值的操作。 using filesort、using temporary 这两项出现时需要注意下，这两项是十分耗费性能的 在使用 group by 的时候，虽然没有使用 order by，如果没有索引，是可能同时出现 using filesort，using temporary 的。因为 group by 就是先排序在分组，如果没有排序的需要，可以加上一个 order by NULL 来避免排序，这样 using filesort 就会去除，能提升一点性能。 type字段 system：表只有一行记录（等于系统表），这是 const 类型的特例，平时不会出现。 const：如果通过索引依次就找到了，const 用于比较主键索引或者 unique 索引。因为只能匹配一行数据，所以很快。如果将主键置于 where 列表中，MySQL 就能将该查询转换为一个常量。 eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描。 ref：非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而它可能会找到多个符合条件的行，所以它应该属于查找和扫描的混合体。 range：只检索给定范围的行，使用一个索引来选择行。key 列显示使用了哪个索引，一般就是在你的 where 语句中出现 between、&lt;、&gt;、in 等的查询。 这种范围扫描索引比全表扫描要好，因为只需要开始于缩印的某一点，而结束于另一点，不用扫描全部索引。 index：Full Index Scan ，index 与 ALL 的区别为 index 类型只遍历索引树，这通常比 ALL 快，因为索引文件通常比数据文件小。 也就是说虽然 ALL 和 index 都是读全表，但 index 是从索引中读取的，而 ALL 是从硬盘读取的。 all：Full Table Scan，遍历全表获得匹配的行。 字段类型和编码 MySQL 返回字符串长度 CHARACTER_LENGTH(同CHAR_LENGTH)方法返回的是字符数，LENGTH 函数返回的是字节数，一个汉字三个字节。 varchar 等字段建立索引长度计算语句 select count(distinct left(test,5))/count(*) from table；越趋近 1 越好。 MySQL 的 utf8 MySQL 的 utf8 最大是 3 个字节不支持 emoji 表情符号，必须只用 utf8mb4。需要在 MySQL 配置文件中配置客户端字符集为 utf8mb4。 JDBC 的连接串不支持配置 characterEncoding=utf8mb4，最好的办法是在连接池中指定初始化 SQL。例如：hikari 连接池，其他连接池类似 spring . datasource . hikari . connection - init - sql =set names utf8mb4。否则需要每次执行 SQL 前都先执行 set names utf8mb4。 MySQL 排序规则一般使用 _bin 和 _genera_ci： utf8_genera_ci 不区分大小写，ci 为 case insensitive 的缩写，即大小写不敏感。 utf8_general_cs 区分大小写，cs 为 case sensitive 的缩写，即大小写敏感，但是目前 MySQL 版本中已经不支持类似于 _genera_cs 的排序规则，直接使用 utf8_bin 替代。 utf8_bin 将字符串中的每一个字符用二进制数据存储，区分大小写。 那么，同样是区分大小写，utf8_general_cs 和 utf8_bin 有什么区别？ cs 为 case sensitive 的缩写，即大小写敏感；bin 的意思是二进制，也就是二进制编码比较。 utf8_general_cs 排序规则下，即便是区分了大小写，但是某些西欧的字符和拉丁字符是不区分的，比如 ä=a，但是有时并不需要 ä=a，所以才有 utf8_bin。 utf8_bin 的特点在于使用字符的二进制的编码进行运算，任何不同的二进制编码都是不同的，因此在 utf8_bin 排序规则下：ä&lt;&gt;a。 SQL语句总结常用但容易忘的 如果有主键或者唯一键冲突则不插入：insert ignore into。 如果有主键或者唯一键冲突则更新，注意这个会影响自增的增量：INSERT INTO room_remarks(room_id,room_remarks)VALUE(1,”sdf”) ON DUPLICATE KEY UPDATE room_remarks = “234”。 如果有就用新的替代，values 如果不包含自增列，自增列的值会变化：REPLACE INTO room_remarks(room_id,room_remarks) VALUE(1,”sdf”)。 备份表：CREATE TABLE user_info SELECT * FROM user_info。 复制表结构：CREATE TABLE user_v2 LIKE user。 从查询语句中导入：INSERT INTO user_v2 SELECT * FROM user 或者 INSERT INTO user_v2(id,num) SELECT id,num FROM user。 连表更新：UPDATE user a, room b SET a.num=a.num+1 WHERE a.room_id=b.id。 连表删除：DELETE user FROM user,black WHERE user.id=black.id。 锁相关锁相关(作为了解，很少用)： 共享锁：select id from tb_test where id = 1 lock in share mode。 排它锁：select id from tb_test where id = 1 for update。 优化时用到 强制使用某个索引：select * from table force index(idx_user) limit 2。 禁止使用某个索引：select * from table ignore index(idx_user) limit 2。 禁用缓存(在测试时去除缓存的影响)：select SQL_NO_CACHE from table limit 2。 查看状态 查看字符集：SHOW VARIABLES LIKE ‘character_set%’。 查看排序规则：SHOW VARIABLES LIKE ‘collation%’。 SQL编写注意 where 语句的解析顺序是从右到左，条件尽量放 where 不要放 having。 采用延迟关联(deferred join)技术优化超多分页场景，比如 limit 10000,10,延迟关联可以避免回表。 distinct 语句非常损耗性能，可以通过 group by 来优化。 连表尽量不要超过三个表。 踩坑 如果有自增列，truncate 语句会把自增列的基数重置为 0，有些场景用自增列作为业务上的 ID 需要十分重视。 聚合函数会自动滤空，比如 a 列的类型是 int 且全部是 NULL，则 SUM(a) 返回的是 NULL 而不是 0。 MySQL 判断 null 相等不能用 “a=null”，这个结果永远为 UnKnown，where 和 having 中，UnKnown 永远被视为 false，check 约束中，UnKnown 就会视为 true 来处理。所以要用“a is null”处理。 千万大表在线修改MySQL 在表数据量很大的时候，如果修改表结构会导致锁表，业务请求被阻塞。MySQL 在 5.6 之后引入了在线更新，但是在某些情况下还是会锁表，所以一般都采用 PT 工具( Percona Toolkit)。如对表添加索引： 123pt-online-schema-change --user='root' --host='localhost' --ask-pass --alter \"add index idx_user_id(room_id,create_time)\" D=fission_show_room_v2,t=room_favorite_info --execute 慢查询日志 有时候如果线上请求超时，应该去关注下慢查询日志，慢查询的分析很简单，先找到慢查询日志文件的位置，然后利用 mysqldumpslow 去分析。 查询慢查询日志信息可以直接通过执行 SQL 命令查看相关变量，常用的 SQL 如下： mysqldumpslow 的工具十分简单，我主要用到的参数如下： -t：限制输出的行数，我一般取前十条就够了。 -s：根据什么来排序默认是平均查询时间 at，我还经常用到 c 查询次数，因为查询次数很频繁但是时间不高也是有必要优化的，还有 t 查询时间，查看那个语句特别卡。 -v：输出详细信息。 例子：mysqldumpslow -v -s t -t 10 mysql_slow.log.2018-11-20-0500。 一些数据库性能的思考 在对公司慢查询日志做优化的时候，很多时候可能是忘了建索引，像这种问题很容易解决，加个索引就行了。但是有几种情况就不是简单加索引能解决了 业务代码循环读数据库 ​ 考虑这样一个场景，获取用户粉丝列表信息，加入分页是十个，其实像这样的 SQL 是十分简单的，通过连表查询性能也很高。 ​ 但是有时候，很多开发采用了取出一串 ID，然后循环读每个 ID 的信息，这样如果 ID 很多对数据库的压力是很大的，而且性能也很低。 统计 SQL ​ 很多时候，业务上都会有排行榜这种，发现公司有很多地方直接采用数据库做计算，在对一些大表做聚合运算的时候，经常超过五秒，这些 SQL 一般很长而且很难优化。像这种场景，如果业务允许（比如一致性要求不高或者是隔一段时间才统计的），可以专门在从库里面做统计。另外我建议还是采用 Redis 缓存来处理这种业务。 超大分页 ​ 在慢查询日志中发现了一些超大分页的慢查询如 Limit 40000，1000，因为 MySQL 的分页是在 Server 层做的，可以采用延迟关联在减少回表。但是看了相关的业务代码正常的业务逻辑是不会出现这样的请求的，所以很有可能是有恶意用户在刷接口，最好在开发的时候也对接口加上校验拦截这些恶意请求。","link":"/2019/07/03/mysql索引优化方案.html"},{"title":"一次数据库的死锁问题排查过程","text":"摘要某天晚上，同事正在发布，突然线上大量报警，很多是关于数据库死锁的，报警提示信息如下： 现象某天晚上，同事正在发布，突然线上大量报警，很多是关于数据库死锁的，报警提示信息如下： 123456789{\"errorCode\":\"SYSTEM_ERROR\",\"errorMsg\":\"nested exception is org.apache.ibatis.exceptions.PersistenceException: Error updating database. Cause: ERR-CODE: [TDDL-4614][ERR_EXECUTE_ON_MYSQL] Deadlock found when trying to get lock; The error occurred while setting parameters\\n### SQL: update fund_transfer_stream set gmt_modified=now(),state = ? where fund_transfer_order_no = ? and seller_id = ? and state = 'NEW' 通过报警，我们基本可以定位到发生死锁的数据库以及数据库表。先来介绍下本文案例中涉及到的数据库相关信息。 背景情况我们使用的数据库是Mysql 5.7，引擎是InnoDB，事务隔离级别是READ-COMMITED。 数据库版本查询方法： 1SELECT version(); 引擎查询方法： 1show create table fund_transfer_stream; 建表语句中会显示存储引擎信息，形如：ENGINE=InnoDB 事务隔离级别查询方法： 1select @@tx_isolation; 事务隔离级别设置方法（只对当前Session生效）： 1set session transaction isolation level read committed; PS：注意，如果数据库是分库的，以上几条SQL语句需要在单库上执行，不要在逻辑库执行。 发生死锁的表结构及索引情况（隐去了部分无关字段和索引）： 1234567891011121314CREATE TABLE `fund_transfer_stream` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键', `gmt_create` datetime NOT NULL COMMENT '创建时间', `gmt_modified` datetime NOT NULL COMMENT '修改时间', `pay_scene_name` varchar(256) NOT NULL COMMENT '支付场景名称', `pay_scene_version` varchar(256) DEFAULT NULL COMMENT '支付场景版本', `identifier` varchar(256) NOT NULL COMMENT '唯一性标识', `seller_id` varchar(64) NOT NULL COMMENT '卖家Id', `state` varchar(64) DEFAULT NULL COMMENT '状态', `fund_transfer_order_no` varchar(256) DEFAULT NULL COMMENT '资金平台返回的状态', PRIMARY KEY (`id`),UNIQUE KEY `uk_scene_identifier` (KEY `idx_seller` (`seller_id`), KEY `idx_seller_transNo` (`seller_id`,`fund_transfer_order_no`(20)) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='资金流水'; 该数据库共有三个索引，1个聚簇索引（主键索引），2个非聚簇索（非主键索引）引。 聚簇索引： 1PRIMARY KEY (`id`) 非聚簇索引： 123KEY `idx_seller` (`seller_id`),KEY `idx_seller_transNo` (`seller_id`,`fund_transfer_order_no`(20)) 以上两个索引，其实idx_seller_transNo已经覆盖到了idx_seller，由于历史原因，因为该表以seller_id分表，所以是先有的idx_seller，后有的idx_seller_transNo 死锁日志当数据库发生死锁时，可以通过以下命令获取死锁日志： 1show engine innodb status 发生死锁，第一时间查看死锁日志，得到死锁日志内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243Transactions deadlock detected, dumping detailed information.2019-03-19T21:44:23.516263+08:00 5877341 [Note] InnoDB: *** (1) TRANSACTION:TRANSACTION 173268495, ACTIVE 0 sec fetching rowsmysql tables in use 1, locked 1LOCK WAIT 304 lock struct(s), heap size 41168, 6 row lock(s), undo log entries 1MySQL thread id 5877358, OS thread handle 47356539049728, query id 557970181 11.183.244.150 fin_instant_app updatingupdate `fund_transfer_stream` set `gmt_modified` = NOW(), `state` = 'PROCESSING' where ((`state` = 'NEW') AND (`seller_id` = '38921111') AND (`fund_transfer_order_no` = '99010015000805619031958363857'))2019-03-19T21:44:23.516321+08:00 5877341 [Note] InnoDB: *** (1) HOLDS THE LOCK(S):RECORD LOCKS space id 173 page no 13726 n bits 248 index idx_seller_transNo of table `xxx`.`fund_transfer_stream` trx id 173268495 lock_mode X locks rec but not gapRecord lock, heap no 168 PHYSICAL RECORD: n_fields 3; compact format; info bits 02019-03-19T21:44:23.516565+08:00 5877341 [Note] InnoDB: *** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 173 page no 12416 n bits 128 index PRIMARY of table `xxx`.`fund_transfer_stream` trx id 173268495 lock_mode X locks rec but not gap waitingRecord lock, heap no 56 PHYSICAL RECORD: n_fields 17; compact format; info bits 02019-03-19T21:44:23.517793+08:00 5877341 [Note] InnoDB: *** (2) TRANSACTION:TRANSACTION 173268500, ACTIVE 0 sec fetching rows, thread declared inside InnoDB 81mysql tables in use 1, locked 1302 lock struct(s), heap size 41168, 2 row lock(s), undo log entries 1MySQL thread id 5877341, OS thread handle 47362313119488, query id 557970189 11.131.81.107 fin_instant_app updatingupdate `fund_transfer_stream_0056` set `gmt_modified` = NOW(), `state` = 'PROCESSING' where ((`state` = 'NEW') AND (`seller_id` = '38921111') AND (`fund_transfer_order_no` = '99010015000805619031957477256'))2019-03-19T21:44:23.517855+08:00 5877341 [Note] InnoDB: *** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 173 page no 12416 n bits 128 index PRIMARY of table `fin_instant_0003`.`fund_transfer_stream_0056` trx id 173268500 lock_mode X locks rec but not gapRecord lock, heap no 56 PHYSICAL RECORD: n_fields 17; compact format; info bits 02019-03-19T21:44:23.519053+08:00 5877341 [Note] InnoDB: *** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 173 page no 13726 n bits 248 index idx_seller_transNo of table `fin_instant_0003`.`fund_transfer_stream_0056` trx id 173268500 lock_mode X locks rec but not gap waitingRecord lock, heap no 168 PHYSICAL RECORD: n_fields 3; compact format; info bits 02019-03-19T21:44:23.519297+08:00 5877341 [Note] InnoDB: *** WE ROLL BACK TRANSACTION (2) 简单解读一下死锁日志，可以得到以下信息： 1、导致死锁的两条SQL语句分别是： 123update `fund_transfer_stream_0056` set `gmt_modified` = NOW(), `state` = 'PROCESSING' where ((`state` = 'NEW') AND (`seller_id` = '38921111') AND (`fund_transfer_order_no` = '99010015000805619031957477256')) 和 123update `fund_transfer_stream_0056` set `gmt_modified` = NOW(), `state` = 'PROCESSING' where ((`state` = 'NEW') AND (`seller_id` = '38921111') AND (`fund_transfer_order_no` = '99010015000805619031958363857')) 2、事务1，持有索引idx_seller_transNo的锁，在等待获取PRIMARY的锁。 3、事务2，持有PRIMARY的锁，在等待获取idx_seller_transNo的锁。 4、因事务1和事务2之间发生循环等待，故发生死锁。 5、事务1和事务2当前持有的锁均为：lock_mode X locks rec but not gap 两个事务对记录加的都是X 锁，No Gap锁，即对当行记录加锁，并为加间隙锁。 X锁：排他锁、又称写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。 与之对应的是S锁：共享锁，又称读锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。 Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。 Next-Key Lock：1+2，锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。 详见：https://www.cnblogs.com/zhoujinyi/p/3435982.html 、 https://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-isolation-levels.html 问题排查根据我们目前已知的数据库相关信息，以及死锁的日志，我们基本可以做一些简单的判定。 首先，此次死锁一定是和Gap锁以及Next-Key Lock没有关系的。因为我们的数据库隔离级别是RC（READ-COMMITED）的，这种隔离级别是不会添加Gap锁的。前面的死锁日志也提到这一点。 然后，就要翻代码了，看看我们的代码中事务到底是怎么做的。核心代码及SQL如下： 12345@Transactional(rollbackFor = Exception.class)public int doProcessing(String sellerId, Long id, String fundTransferOrderNo) { fundTreansferStreamDAO.updateFundStreamId(sellerId, id, fundTransferOrderNo); return fundTreansferStreamDAO.updateStatus(sellerId, fundTransferOrderNo, FundTransferStreamState.PROCESSING.name());} 该代码的目的是先后修改同一条记录的两个不同字段，updateFundStreamId SQL： 123update fund_transfer_stream set gmt_modified=now(),fund_transfer_order_no = #{fundTransferOrderNo} where id = #{id} and seller_id = #{sellerId} updateStatus SQL： 1234update fund_transfer_stream set gmt_modified=now(),state = #{state} where fund_transfer_order_no = #{fundTransferOrderNo} and seller_id = #{sellerId} and state = 'NEW' 可以看到，我们的同一个事务中执行了两条Update语句，这里分别查看下两条SQL的执行计划： updateFundStreamId执行的时候使用到的是PRIMARY索引。 updateStatus执行的时候使用到的是idx_seller_transNo索引。 通过执行计划，我们发现updateStatus其实是有两个索引可以用的，执行的时候真正使用的是idx_seller_transNo索引。这是因为MySQL查询优化器是基于代价（cost-based）的查询方式。因此，在查询过程中，最重要的一部分是根据查询的SQL语句，依据多种索引，计算查询需要的代价，从而选择最优的索引方式生成查询计划。 我们查询执行计划是在死锁发生之后做的，事后查询的执行计划和发绳死锁那一刻的索引使用情况并不一定相同的。但是，我们结合死锁日志，也可以定位到以上两条SQL语句执行的时候使用到的索引。即updateFundStreamId执行的时候使用到的是PRIMARY索引，updateStatus执行的时候使用到的是idx_seller_transNo索引。 有了以上这些已知信息，我们就可以开始排查死锁原因及其背后的原理了。通过分析死锁日志，再结合我们的代码以及数据库建表语句，我们发现主要问题出在我们的idx_seller_transNo索引上面： 1KEY `idx_seller_transNo` (`seller_id`,`fund_transfer_order_no`(20)) 索引创建语句中，我们使用了前缀索引，为了节约索引空间，提高索引效率，我们只选择了fund_transfer_order_no字段的前20位作为索引值。 因为fund_transfer_order_no只是普通索引，而非唯一性索引。又因为在一种特殊情况下，会有同一个用户的两个fund_transfer_order_no的前20位相同，这就导致两条不同的记录的索引值一样（因为seller_id 和fund_transfer_order_no(20)都相同 ）。 就如本文中的例子，发生死锁的两条记录的fund_transfer_order_no字段的值：99010015000805619031958363857和99010015000805619031957477256这两个就是前20位相同的。 那么为什么fund_transfer_order_no的前20位相同会导致死锁呢？ 加锁原理我们就拿本次的案例来看一下MySql数据库加锁的原理是怎样的，本文的死锁背后又发生了什么。 我们在数据库上模拟死锁场景，执行顺序如下： 事务1 事务2 执行结果 begin update fund_transfer_stream set gmt_modified=now(),fund_transfer_order_no = ‘99010015000805619031958363857’ where id = 1 and seller_id = 3111095611; 执行成功 begin update fund_transfer_stream set gmt_modified=now(),fund_transfer_order_no = ‘99010015000805619031957477256’ where id = 2 and seller_id = 3111095611; 执行成功 update fund_transfer_stream set gmt_modified = NOW(), state = ‘PROCESSING’ where ((state = ‘NEW’) AND (seller_id = ‘3111095611’) AND (fund_transfer_order_no = ‘99010015000805619031958363857’)); 阻塞 update fund_transfer_stream set gmt_modified = NOW(), state = ‘PROCESSING’ where ((state = ‘NEW’) AND (seller_id = ‘3111095611’) AND (fund_transfer_order_no = ‘99010015000805619031957477256’)); 死锁 我们知道，在MySQL中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 主键索引的叶子节点存的是整行数据。在InnoDB中，主键索引也被称为聚簇索引（clustered index） 非主键索引的叶子节点的内容是主键的值，在InnoDB中，非主键索引也被称为非聚簇索引（secondary index） 所以，本文的示例中涉及到的索引结构（索引是B+树，简化成表格了）如图： 死锁的发生与否，并不在于事务中有多少条SQL语句，死锁的关键在于：两个(或以上)的Session加锁的顺序不一致。那么接下来就看下上面的例子中两个事务的加锁顺序是怎样的： 下图是分解图，每一条SQL执行的时候加锁情况： 结合以上两张图，我们发现了导致死锁的原因： 事务1执行update1占用PRIMARY = 1的锁 ——&gt; 事务2执行update1 占有PRIMARY = 2的锁； 事务1执行update2占有idx_seller_transNo = (3111095611，99010015000805619031)的锁，尝试占有PRIMARY = 2锁失败（阻塞）； 事务2执行update2尝试占有idx_seller_transNo = (3111095611，99010015000805619031)的锁失败（死锁）； 事务在以非主键索引为where条件进行Update的时候，会先对该非主键索引加锁，然后再查询该非主键索引对应的主键索引都有哪些，再对这些主键索引进行加锁。） 解决方法至此，我们分析清楚了导致死锁的根本原理以及其背后的原理。那么这个问题解决起来就不难了。 可以从两方面入手，分别是修改索引和修改代码（包含SQL语句）。 修改索引：只要我们把前缀索引 idx_seller_transNo中fund_transfer_order_no的前缀长度修改下就可以了。比如改成50。即可避免死锁。 但是，改了idx_seller_transNo的前缀长度后，可以解决死锁的前提条件是update语句真正执行的时候，会用到fund_transfer_order_no索引。如果MySQL查询优化器在代价分析之后，决定使用索引 KEY idx_seller(seller_id)，那么还是会存在死锁问题。原理和本文类似。 所以，根本解决办法就是改代码： 12* 所有update都通过主键ID进行。* 在同一个事务中，避免出现多条update语句修改同一条记录。 总结与思考在死锁发生之后的一周内，我几乎每天都会抽空研究一会，问题早早的就定位到了，修改方案也有了，但是其中原理一直没搞清楚。 前前后后做过很多中种推断及假设，又都被自己一次次推翻。最终还是要靠实践来验证自己的想法。于是我自己在本地安装了数据库，实战的做了些测试，并实时查看数据库锁情况。show engine innodb status ;可以查看锁情况。最终才搞清楚原理。 简单说几点思考： 1、遇到问题，不要猜！！！亲手复现下问题，然后再来分析。 2、不要忽略上下文！！！我刚开始就是只关注死锁日志，一直忽略了代码中的事务其实还执行了另外一条SQL语句（updateFundStreamId）。 3、理论知识再充足，关键时刻不一定想的起来！！！ 4、坑都是自己埋的！！！ 参考资料：MySQL 加锁处理分析 innodb 事务隔离级别 《MySql实战45讲》 MySQL中的行级锁,表级锁,页级锁 查看原文","link":"/2019/06/25/一次数据库的死锁问题排查过程.html"},{"title":"博客图片上传picgo工具github图传使用","text":"摘要对于每一个写博客的人来说，图片是至关重要。这一路经历了多次图片的烦恼，之前选择了微博个人文章那里粘贴图片的方式上传，感觉也挺方便的。但是由于新浪的图片显示问题，如果header中不设置 标签就不能异步访问图片，导致图裂，那之恶心。然而设置之后又与网站访客统计的插件冲突，使之不能统计，真是神仙打架。无赖之下使用了PicGo工具，使用后感觉真XX方便！ PicGo工具下载安装配置下载 .PicGo下载 github网站提供三个版本的下载，MacOs、linux、windows覆盖市面上90%系统，还是很给力了。 我是mac用户，直接使用brew cask来安装PicGo: brew cask install picgo，简直方便到爆。 配置 PicGo配置(使用github图传，免费方便，同时配合github.io博客真是方便) 选上必填的就ok,一开始不知道token的设置，附赠token获取方法 图片上传相关的设置 链接格式：选择适合自己的，一般用户md文件中，选第一个，然后就可以疯狂使用了。 使用github图传，获取token在github-&gt;setting-&gt;developer settings 选择generate new token 勾选好之后生成就好了 使用 PicGo使用，简直方便 1).默认网页上直接右键复制图片 2).点击等待中的图片，开始上传 3).上传完之后有个提示，同时粘贴板也会自动粘贴上 4).直接粘贴到想要的地方 或者也可以直接截图，然后点击图片里的图片上传，很方便 PicGo上传动图gif 如果直接复制网页上的动图，去上传的话是截取的某帧，是静图。应该下载到本地，然后在拖进去上传就可以了。","link":"/2019/06/20/博客图片上传picgo工具github图传使用.html"},{"title":"阿里一年的成长经历","text":"摘要任何工作一定对个人都是有提升的，但是不会总结的人，在每个项目/需求中成长的东西都是散的，久而久之就忘了。通过充分的总结之后，犯过的错误我们不会二次再犯，理清楚的业务的来龙去脉铭记在心，对自己是一种提升，分享给别人对别人也是很大的帮助。失败者失败的原因各有不同，成功者的做事方式总是相似的，从宏观角度去看，我认为总结就是成功者之所以能成功，很重要一个原因。 应当如何面对线上的异常/故障看起来毫无意义的一个问题，碰到线上异常/故障如何面对，排查解决了不就好了，但是这真的只是第一层 最近在想“消防”这个词语很有意思，它其实是两层意思： “消”是消除问题 “防”是防止问题 即“消防”这个词语表达的意思应该是先消除问题再防止相同的问题再次发生。其实线上的异常/故障也是同样的道理，我们应当先及时止血，把问题处理掉，然后深挖问题，探究根因，举几个例子： 假设是某段代码的空指针异常导致的，那么是否考虑加强Code Review，或者使用findbugs插件去自动扫描代码中可能的异常？ 假设是线上某个配置修改导致的，那么是否今后变更的修改必须有人双重检查一遍才可以修改？ 假设是本地内存中某些值因为系统重启丢失导致的，那么是否引入定时任务，定时把值写入本地内存中？ 假设是某段代码逻辑没测试到导致的，那么是否可以反思总结为什么这段逻辑没有测试到，未来的测试应该如何改进？ 根据我过往的经验，太多公司、太多团队处理线上的问题仅仅满足于把问题处理完就完事，忽略了对问题的复盘，这对团队/对公司的发展都是不利的。 什么是真正的技术能力之前加了几个技术微信群，看到很多技术朋友在兴高采烈地讨论各种源码，spring源码我彻底撸了一遍、最近深入学习了dubbo底层实现方式，当然曾经的我也是这样的，记得学习volatile的时候一直挖到了volatile在硬件层面上的实现方式，但是这真的说明技术能力强吗？从今天的思考去看这个问题，我认为这更多反应的是一个人的学习能力、钻研能力以及对技术的热情，除此之外再体现不出太多其他东西了。 这个话题，可能是这一年思考的最多个的一个点，钻研是好事，但是实际上大多时候的深入钻研并不在实际工作中有用，且研究得越深，忘得越快，因为研究得越深，那么这个技术点关联的技术点就越多，边边角角的忘了，核心的东西不容易串起来。那么什么是真正的技术能力，我画一张图概括一下： 技术能力=解决问题的能力(解决当下问题+解决长远问题) 简而言之，技术能力 = 解决问题的能力，那么同样都在解决问题，大家之间的技术高低又有什么区分呢？我认为有以下几个层次： 第一层级，解决当下问题 第二层级，以优雅且可复用的方式解决当下问题 第三层级，解决的问题不仅仅能满足当下，还能满足未来一段时间 其实从这个角度上来看，不同的技术能力，在工作过程中区分度是很明显的： 写的代码是否存在异常风险，多线程运行下是否存在线程安全问题，某段代码是否会导致内存泄露 写的代码是否优雅可复用，设计的框架是否足够符合开闭原则，代码结构层次是否清晰明了 针对特定的场景，技术选型、库表结构设计是否足够合理，今天你设计的框架是只能用一年，还是未来三年五年都可以持续使用 来了一个大的需求，就比如做一个App的会员体系功能好了，是否可以在充分分析需求后，精确将需求划分为几个特定的子模块并梳理清楚模块之间的关系 越厉害的人，在代码设计与开发过程中，越能看到想到一些别人看不到想不到的问题，这叫做高屋建瓴；当代码运行出现问题的时候，有人1小时排查出问题，有人1分钟发现问题，这叫做举重若轻。 因此我认为解决问题的能力才是技术能力的真正体现，这一年对技术的探究我也从研究源码更多的转变去学习设计模式、去学习分布式环境下各种NoSql的选型对比、去学习使用Lambda让代码更简洁，往真正在实际工作中解决问题的方向去努力。 另外，抛开这个点，这两天我在思考，还有一个体现技术能力的点，就是学习能力。现实中的全栈是很少的，互联网这个行业的程序员的方向通常有几类： 服务端 前端 移动端 AI 嵌入式 大数据 在同一类中，基础知识、基本概念、思维方向是一致的，更多可能差异在开发工具、语言上，我精通Java，但是如果明天有一个需求，使用nodejs、scala、go更好，那么是否可以快速学习、快速上手？甚至明天有一个需求需要写前端代码，是否可以快速开发、无bug上线？ 所以，解决问题的能力 + 学习能力，是我认为真正的技术能力，不过说到底，学习能力某种程度上也只是为了解决问题而已。 不要造轮子曾几何时，当我们看着github上这么多优秀的源代码的时候，默默立誓，这辈子我一定要写出一个牛逼的框架，开源在网上。 曾几何时，公司招聘的时候，技术负责人激情满满地介绍着公司内部自研了多少系统并在线上投入使用。 很多对技术有追求的朋友，进入一家公司可能时时刻刻在寻找机会去做一些自己造轮子的事情，但是就如同前面所说的，衡量真正好技术的标准就是能否实实在在地解决问题，自己造轮子风险高、周期长，且需要长时间的验证、排坑才能达到比较好的效果。 随便举几个例子，在互联网发展的今天： 数据库连接池有dbcp、c3p0、druid 本地缓存有ehcache、要用中心缓存有redis、tail 服务化有dubbo、跨语言可以用thrift 分布式任务调度可以考虑schedulex 搜索可以选es、solr 更高级一点图片存储可以用七牛、im可以用融云/环信、音视频这块声网做得比较成熟，所有这些都提供了各个开发版本的sdk，接入简单 只要你有的技术方面的需求，绝大多数业界已经有了成熟的解决方案了，根本不需要去专门自己搞一套。因此我认为轻易一定不要造轮子，如果一定要造轮子，那么请想清楚下面几个问题： 你要做的事情是否当前已经有了类似解决方案？ 如果有，那么你自己做的这一套东西和类似解决方案的差异点在哪里？假设不用你这套，基于已有的解决方案稍加改造是否就能达到目的？ 如果没有，那么为什么之前没有？是你们公司这种场景是独一无二的？还是这种场景对应的解决方案根本就是不可行的所以之前没人去搞？ 如果想清楚了这些问题，那么就去干吧。 去提升看问题的高度过去有太多人在我的公众号或者博客下反馈了一个问题：在这个公司，整天做着增删改查的工作，对自己一点都没有提高。 对于这种看法，说难听点就是四个字—-目光短浅。我们看：如果以普通的视角去看，那么一颗树那也就只是一棵树而已，但是如果跳脱出目前的视角，站在更高的角度去看，它其实是森林的一部分。你的主管并不是因为他是你的主管所以他就应该你比更高瞻远瞩，而是因为他看问题的高度比你更高、想得更远、做得更深，所以才成为了你的主管。 把这个问题说得实际点： 假设今天你负责的是一个系统，那么你仅仅是把这个系统的基本原理搞懂了？还是可以把上下游有几个系统、每个系统之间如何调用、依赖方式都理顺？ 假设今天你负责的是一块业务，那么你仅仅把自己负责的功能点弄清楚了？还是你可以从最上游开始，到你负责的系统，再到最下游，都思考得非常透彻？ 今天与其在抱怨没有机会、抱怨公司对自己能力没有提升，为什么不去思考机会为什么降临在别人头上不降临在你头上？为什么别人可以从小公司写着一样的增删改查走向BAT而你年复一年还在小公司写着增删改查？当你真正能转变自己的思维模式，跳脱出现在的圈子往更高一个层次去看问题、去提升自己，我相信总会有发光发热的一天的。 同样在阿里巴巴，马老师思考自然、思考环保、思考人类的发展，你的主管思考团队未来的方向和打法，我们在思考如何把某个客户需求完整落地，这就是高度，你未必能想到马老师想的，但是你对标层级高一点的人，一步一步尝试往他们的高度去靠。 总而言之：眼界决定高度，多看、多想、多保持好奇心、多问几个为什么，久而久之自然就迈上了一个新的台阶。 学会总结需求、项目的复盘是非常重要的一部分内容，然而我之前见过的太多团队、太多Leader，只顾着一个迭代接着一个迭代，一个版本接着一个版本，只满足于把需求做好，而忽略了总结的重要性。 我认为大到项目、小到需求，如果在完成之后缺乏总结那么某种程度上来说是失败的，可以总结的点非常多： 通过这个项目/需求，是否吃透了某一块业务，搞懂了来龙去脉 通过这个项目/需求，是否充分理解了公司某个技术框架/基础组件的用法 在整个项目的设计上，有哪些做的不好的地方 在整个项目的开发（针对程序员而言），是否踩了坑，犯了低级的错误 在整个项目的进度把控上、人员安排上、上下游协调上，是否存在不足之处 经历了某次大促的值班，是否对可以熟练使用公司的监控工具，遇到突发事件，是否快速有效地进行了解决 任何工作一定对个人都是有提升的，但是不会总结的人，在每个项目/需求中成长的东西都是散的，久而久之就忘了。通过充分的总结之后，犯过的错误我们不会二次再犯，理清楚的业务的来龙去脉铭记在心，对自己是一种提升，分享给别人对别人也是很大的帮助。 失败者失败的原因各有不同，成功者的做事方式总是相似的，从宏观角度去看，我认为总结就是成功者之所以能成功，很重要一个原因。 参考资料","link":"/2019/06/13/阿里一年的成长经历.html"},{"title":"mysql数据库索引解析","text":"摘要看了很多关于索引的博客，讲的大同小异。但是始终没有让我明白关于索引的一些概念，如B-Tree索引，Hash索引，唯一索引….或许有很多人和我一样，没搞清楚概念就开始研究B-Tree，B+Tree等结构，导致在面试的时候答非所问！ 索引是什么?索引是帮助MySQL高效获取数据的数据结构。 索引能干什么?索引非常关键，尤其是当表中的数据量越来越大时，索引对于性能的影响愈发重要。 索引能够轻易将查询性能提高好几个数量级，总的来说就是可以明显的提高查询效率。 索引的分类? 从存储结构上来划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。这里所描述的是索引存储时保存的形式， 从应用层次来分：普通索引，唯一索引，复合索引 根据中数据的物理顺序与键值的逻辑（索引）顺序关系：聚集索引，非聚集索引。 平时讲的索引类型一般是指在应用层次的划分。就像手机分类：安卓手机，IOS手机 与 华为手机，苹果手机，OPPO手机一样。 普通索引**：**即一个索引只包含单个列，一个表可以有多个单列索引 唯一索引：索引列的值必须唯一，但允许有空值 复合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并 聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。 非聚簇索引：不是聚簇索引，就是非聚簇索引 索引的底层实现mysql默认存储引擎innodb只显式支持B-Tree( 从技术上来说是B+Tree)索引，对于频繁访问的表，innodb会透明建立自适应hash索引，即在B树索引基础上建立hash索引，可以显著提高查找效率，对于客户端是透明的，不可控制的，隐式的。 不谈存储引擎，只讨论实现(抽象) Hash索引基于哈希表实现，只有精确匹配索引所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code），并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。 B-Tree索引（MySQL使用B+Tree）B-Tree能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，数据分布在各个节点之中。 B+Tree索引 是B-Tree的改进版本，同时也是数据库索引索引所采用的存储结构。数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址。相比B-Tree来说，进行范围查找时只需要查找两个节点，进行遍历即可。而B-Tree需要获取所有节点，相比之下B+Tree效率更高。 结合存储引擎来讨论（一般默认使用B+Tree） 案例：假设有一张学生表，id为主键 id name birthday 1 Tom 1996-01-01 2 Jann 1996-01-04 3 Ray 1996-01-08 4 Michael 1996-01-10 5 Jack 1996-01-13 6 Steven 1996-01-23 7 Lily 1996-01-25 在MyISAM引擎中的实现（二级索引也是这样实现的） 在InnoDB中的实现 为什么索引结构默认使用B+Tree，而不是Hash，二叉树，红黑树？B+tree：因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低； Hash：虽然可以快速定位，但是没有顺序，IO复杂度高。 二叉树：树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。 红黑树：树的高度随着数据量增加而增加，IO代价高。 红黑树: 每个节点或者是黑色，或者是红色。 根节点是黑色。 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！] 如果一个节点是红色的，则它的子节点必须是黑色的。 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。 为什么官方建议使用自增长主键作为索引？结合B+Tree的特点，自增主键是连续的，在插入过程中尽量减少页分裂，即使要进行页分裂，也只会分裂很少一部分。并且能减少数据的移动，每次插入都是插入到最后。总之就是减少分裂和移动的频率。 插入连续的数据： 插入非连续的数据 简单总结下 MySQL使用B+Tree作为索引数据结构。 B+Tree在新增数据时，会根据索引指定列的值对旧的B+Tree做调整。 从物理存储结构上说，B-Tree和B+Tree都以页(4K)来划分节点的大小，但是由于B+Tree中中间节点不存储数据，因此B+Tree能够在同样大小的节点中，存储更多的key，提高查找效率。 影响MySQL查找性能的主要还是磁盘IO次数，大部分是磁头移动到指定磁道的时间花费。 MyISAM存储引擎下索引和数据存储是分离的，InnoDB索引和数据存储在一起。 InnoDB存储引擎下索引的实现，(辅助索引)全部是依赖于主索引建立的(辅助索引中叶子结点存储的并不是数据的地址，还是主索引的值，因此，所有依赖于辅助索引的都是先根据辅助索引查到主索引，再根据主索引查数据的地址)。 由于InnoDB索引的特性，因此如果主索引不是自增的(id作主键)，那么每次插入新的数据，都很可能对B+Tree的主索引进行重整，影响性能。因此，尽量以自增id作为InnoDB的主索引。 InnoDB一棵B+树能存多少行数据？为什么要用B+树？而不是其他树？InnoDB一棵B+树可以存放多少行数据？这个问题的简单回答是：约2千万。为什么是这么多呢？因为这是可以算出来的，要搞清楚这个问题，我们先从InnoDB索引数据结构、数据组织方式说起。 我们都知道计算机在存储数据的时候，有最小存储单元，这就好比我们今天进行现金的流通最小单位是一毛。在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，而对于我们的InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。 innodb的所有数据文件（后缀为ibd的文件），他的大小始终都是16384（16k）的整数倍。 磁盘扇区、文件系统、InnoDB存储引擎都有各自的最小存储单元。 在MySQL中我们的InnoDB页的大小默认是16k，当然也可以通过参数设置： 12345678mysql&gt; show variables like &apos;innodb_page_size&apos;;+------------------+-------+| Variable_name| Value|+------------------+-------+| innodb_page_size | 16384|+------------------+-------+1 row in set(0.00sec) 数据表中的数据都是存储在页中的，所以一个页中能存储多少行数据呢？假设一行数据的大小是1k，那么一个页可以存放16行这样的数据。 如果数据库只按这样的方式存储，那么如何查找数据就成为一个问题，因为我们不知道要查找的数据存在哪个页中，也不可能把所有的页遍历一遍，那样太慢了。所以人们想了一个办法，用B+树的方式组织这些数据。如图所示： 我们先将数据记录按主键进行排序，分别存放在不同的页中（为了便于理解我们这里一个页中只存放3条记录，实际情况可以存放很多），除了存放数据的页以外，还有存放键值+指针的页，如图中page number=3的页，该页存放键值和指向数据页的指针，这样的页由N个键值+指针组成。当然它也是排好序的。这样的数据组织形式，我们称为索引组织表。现在来看下，要查找一条数据，怎么查？ 如select * from user where id=5; 这里id是主键,我们通过这棵B+树来查找，首先找到根页，你怎么知道user表的根页在哪呢？其实每张表的根页位置在表空间文件中是固定的，即page number=3的页（这点我们下文还会进一步证明），找到根页后通过二分查找法，定位到id=5的数据应该在指针P5指向的页中，那么进一步去page number=5的页中查找，同样通过二分查询法即可找到id=5的记录： | 5 | zhao2 | 27 | 现在我们清楚了InnoDB中主键索引B+树是如何组织数据、查询数据的，我们总结一下： 1、InnoDB存储引擎的最小存储单元是页，页可以用于存放数据也可以用于存放键值+指针，在B+树中叶子节点存放数据，非叶子节点存放键值+指针。 2、索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而在去数据页中查找到需要的数据； 那么回到我们开始的问题，通常一棵B+树可以存放多少行数据？这里我们先假设B+树高为2，即存在一个根节点和若干个叶子节点，那么这棵B+树的存放总记录数为：根节点指针数*单个叶子节点记录行数。 上文我们已经说明单个叶子节点（页）中的记录数=16K/1K=16。（这里假设一行记录的数据大小为1k，实际上现在很多互联网业务数据记录大小通常就是1K左右）。 那么现在我们需要计算出非叶子节点能存放多少指针？ 其实这也很好算，我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即16384/14=1170。那么可以算出一棵高度为2的B+树，能存放1170*16=18720条这样的数据记录。 根据同样的原理我们可以算出一个高度为3的B+树可以存放：1170*1170*16=21902400条这样的记录。 所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO，所以通过主键索引查询通常只需要1-3次IO操作即可查找到数据。 怎么得到InnoDB主键索引B+树的高度？上面我们通过推断得出B+树的高度通常是1-3，下面我们从另外一个侧面证明这个结论。在InnoDB的表空间文件中，约定page number为3的代表主键索引的根页，而在根页偏移量为64的地方存放了该B+树的page level。如果page level为1，树高为2，page level为2，则树高为3。即B+树的高度=page level+1；下面我们将从实际环境中尝试找到这个page level。 在实际操作之前，你可以通过InnoDB元数据表确认主键索引根页的page number为3，你也可以从《InnoDB存储引擎》这本书中得到确认。 1234567SELECTb.name, a.name, index_id, type, a.space, a.PAGE_NOFROMinformation_schema.INNODB_SYS_INDEXES a,information_schema.INNODB_SYS_TABLES bWHEREa.table_id = b.table_id AND a.space &lt;&gt; 0; 执行结果： 可以看出数据库dbt3下的customer表、lineitem表主键索引根页的page number均为3，而其他的二级索引page number为4。关于二级索引与主键索引的区别请参考MySQL相关书籍，本文不在此介绍。 下面我们对数据库表空间文件做想相关的解析： 因为主键索引B+树的根页在整个表空间文件中的第3个页开始，所以可以算出它在文件中的偏移量：16384*3=49152（16384为页大小）。 另外根据《InnoDB存储引擎》中描述在根页的64偏移量位置前2个字节，保存了page level的值，因此我们想要的page level的值在整个文件中的偏移量为：16384*3+64=49152+64=49216，前2个字节中。 接下来我们用hexdump工具，查看表空间文件指定偏移量上的数据： linetem表的page level为2，B+树高度为page level+1=3；**region表的page level为0，B+树高度为page level+1=1；**customer表的page level为2，B+树高度为page level+1=3； 这三张表的数据量如下： 小结lineitem表的数据行数为600多万，B+树高度为3，customer表数据行数只有15万，B+树高度也为3。可以看出尽管数据量差异较大，这两个表树的高度都是3，换句话说这两个表通过索引查询效率并没有太大差异，因为都只需要做3次IO。那么如果有一张表行数是一千万，那么他的B+树高度依旧是3，查询效率仍然不会相差太大。 region表只有5行数据，当然他的B+树高度为1。 最后回顾一道面试题有一道MySQL的面试题，为什么MySQL的索引要使用B+树而不是其它树形结构？比如B树？ 现在这个问题的复杂版本可以参考本文； 他的简单版本回答是： 因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低； 总结本文从一个问题出发，逐步介绍了InnoDB索引组织表的原理、查询方式，并结合已有知识，回答该问题，结合实践来证明。当然为了表述简单易懂，文中忽略了一些细枝末节，比如一个页中不可能所有空间都用于存放数据，它还会存放一些少量的其他字段比如page level，index number等等，另外还有页的填充因子也导致一个页不可能全部用于保存数据。关于二级索引数据存取方式可以参考MySQL相关书籍，他的要点是结合主键索引进行回表查询。参考参考","link":"/2019/06/04/mysql数据库索引解析.html"},{"title":"java注解Annotation说明实例","text":"摘要Java 注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。 什么是注解？对于很多初次接触的开发者来说应该都有这个疑问？Annontation是Java5开始引入的新特征，中文名称叫注解。它提供了一种安全的类似注释的机制，用来将任何的信息或元数据（metadata）与程序元素（类、方法、成员变量等）进行关联。为程序的元素（类、方法、成员变量）加上更直观更明了的说明，这些说明信息是与程序的业务逻辑无关，并且供指定的工具或框架使用。Annontation像一种修饰符一样，应用于包、类型、构造方法、方法、成员变量、参数及本地变量的声明语句中。 Java注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。包含在 java.lang.annotation 包中。 注解的用处 生成文档。这是最常见的，也是java 最早提供的注解。常用的有@param @return 等 跟踪代码依赖性，实现替代配置文件功能。比如Dagger 2 依赖注入，未来java 开发，将大量注解配置，具有很大用处; 在编译时进行格式检查。如@override 放在方法前，如果你这个方法并不是覆盖了超类方法，则编译时就能检查出。 注解原理注解本质是一个继承了Annotation 的特殊接口，其具体实现类是Java 运行时生成的动态代理类。而我们通过反射获取注解时，返回的是Java 运行时生成的动态代理对象$Proxy1。通过代理对象调用自定义注解（接口）的方法，会最终调用AnnotationInvocationHandler 的invoke 方法。该方法会从memberValues 这个Map 中索引出对应的值。而memberValues 的来源是Java 常量池。 元注解java.lang.annotation 提供了四种元注解，专门注解其他的注解（在自定义注解的时候，需要使用到元注解）： @Documented – 注解是否将包含在JavaDoc中 @Retention – 什么时候使用该注解 @Target – 注解用于什么地方 @Inherited – 是否允许子类继承该注解 @Retention 定义该注解的生命周期 ● RetentionPolicy.SOURCE : 在编译阶段丢弃。这些注解在编译结束之后就不再有任何意义，所以它们不会写入字节码。@Override, @SuppressWarnings都属于这类注解。 ● RetentionPolicy.CLASS : 在类加载的时候丢弃。在字节码文件的处理中有用。注解默认使用这种方式 ● RetentionPolicy.RUNTIME : 始终不会丢弃，运行期也保留该注解，因此可以使用反射机制读取该注解的信息。我们自定义的注解通常使用这种方式。 @Target 表示该注解用于什么地方。默认值为任何元素，表示该注解用于什么地方。可用的ElementType 参数包括 ● ElementType.CONSTRUCTOR: 用于描述构造器 ● ElementType.FIELD: 成员变量、对象、属性（包括enum实例） ● ElementType.LOCAL_VARIABLE: 用于描述局部变量 ● ElementType.METHOD: 用于描述方法 ● ElementType.PACKAGE: 用于描述包 ● ElementType.PARAMETER: 用于描述参数 ● ElementType.TYPE: 用于描述类、接口(包括注解类型) 或enum声明 @Documented 一个简单的Annotations 标记注解，表示是否将注解信息添加在java 文档中。 @Inherited 定义该注释和子类的关系@Inherited 元注解是一个标记注解，@Inherited 阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited 修饰的annotation 类型被用于一个class，则这个annotation 将被用于该class 的子类。 常见标准的Annotation Overridejava.lang.Override 是一个标记类型注解，它被用作标注方法。它说明了被标注的方法重载了父类的方法，起到了断言的作用。如果我们使用了这种注解在一个没有覆盖父类方法的方法时，java 编译器将以一个编译错误来警示 DeprecatedDeprecated 也是一种标记类型注解。当一个类型或者类型成员使用@Deprecated 修饰的话，编译器将不鼓励使用这个被标注的程序元素。所以使用这种修饰具有一定的“延续性”：如果我们在代码中通过继承或者覆盖的方式使用了这个过时的类型或者成员，虽然继承或者覆盖后的类型或者成员并不是被声明为@Deprecated，但编译器仍然要报警。 SuppressWarningsSuppressWarning 不是一个标记类型注解。它有一个类型为String[] 的成员，这个成员的值为被禁止的警告名。对于javac 编译器来讲，被-Xlint 选项有效的警告名也同样对@SuppressWarings 有效，同时编译器忽略掉无法识别的警告名。 @SuppressWarnings(“unchecked”) 自定义注解自定义注解类编写的一些规则: Annotation 型定义为@interface, 所有的Annotation 会自动继承java.lang.Annotation这一接口,并且不能再去继承别的类或是接口. 参数成员只能用public 或默认(default) 这两个访问权修饰 参数成员只能用基本类型byte、short、char、int、long、float、double、boolean八种基本数据类型和String、Enum、Class、annotations等数据类型，以及这一些类型的数组. 要获取类方法和字段的注解信息，必须通过Java的反射技术来获取 Annotation 对象，因为你除此之外没有别的获取注解对象的方法 注解也可以没有定义成员,，不过这样注解就没啥用了PS:自定义注解需要使用到元注解 实例FruitName.java 123456789101112131415import java.lang.annotation.Documented;import java.lang.annotation.Retention;import java.lang.annotation.Target;import static java.lang.annotation.ElementType.FIELD;import static java.lang.annotation.RetentionPolicy.RUNTIME;/** * 水果名称注解 */@Target(FIELD)@Retention(RUNTIME)@Documentedpublic @interface FruitName { String value() default \"\";} FruitColor.java 123456789101112131415161718192021222324import java.lang.annotation.Documented;import java.lang.annotation.Retention;import java.lang.annotation.Target;import static java.lang.annotation.ElementType.FIELD;import static java.lang.annotation.RetentionPolicy.RUNTIME;/** * 水果颜色注解 */@Target(FIELD)@Retention(RUNTIME)@Documentedpublic @interface FruitColor { /** * 颜色枚举 */ public enum Color{ BLUE,RED,GREEN}; /** * 颜色属性 */ Color fruitColor() default Color.GREEN;} FruitProvider.java 12345678910111213141516171819202122232425262728import java.lang.annotation.Documented;import java.lang.annotation.Retention;import java.lang.annotation.Target;import static java.lang.annotation.ElementType.FIELD;import static java.lang.annotation.RetentionPolicy.RUNTIME;/** * 水果供应者注解 */@Target(FIELD)@Retention(RUNTIME)@Documentedpublic @interface FruitProvider { /** * 供应商编号 */ public int id() default -1; /** * 供应商名称 */ public String name() default \"\"; /** * 供应商地址 */ public String address() default \"\";} FruitInfoUtil.java 1234567891011121314151617181920212223242526272829303132import java.lang.reflect.Field;/** * 注解处理器 */public class FruitInfoUtil { public static void getFruitInfo(Class&lt;?&gt; clazz){ String strFruitName=\" 水果名称：\"; String strFruitColor=\" 水果颜色：\"; String strFruitProvicer=\"供应商信息：\"; Field[] fields = clazz.getDeclaredFields(); for(Field field :fields){ if(field.isAnnotationPresent(FruitName.class)){ FruitName fruitName = (FruitName) field.getAnnotation(FruitName.class); strFruitName=strFruitName+fruitName.value(); System.out.println(strFruitName); } else if(field.isAnnotationPresent(FruitColor.class)){ FruitColor fruitColor= (FruitColor) field.getAnnotation(FruitColor.class); strFruitColor=strFruitColor+fruitColor.fruitColor().toString(); System.out.println(strFruitColor); } else if(field.isAnnotationPresent(FruitProvider.class)){ FruitProvider fruitProvider= (FruitProvider) field.getAnnotation(FruitProvider.class); strFruitProvicer=\" 供应商编号：\"+fruitProvider.id()+\" 供应商名称：\"+fruitProvider.name()+\" 供应商地址：\"+fruitProvider.address(); System.out.println(strFruitProvicer); } } }} Apple.java 1234567891011121314151617181920212223242526272829303132333435363738394041import test.FruitColor.Color;/** * 注解使用 */public class Apple { @FruitName(\"Apple\") private String appleName; @FruitColor(fruitColor=Color.RED) private String appleColor; @FruitProvider(id=1,name=\"陕西红富士集团\",address=\"陕西省西安市延安路89号红富士大厦\") private String appleProvider; public void setAppleColor(String appleColor) { this.appleColor = appleColor; } public String getAppleColor() { return appleColor; } public void setAppleName(String appleName) { this.appleName = appleName; } public String getAppleName() { return appleName; } public void setAppleProvider(String appleProvider) { this.appleProvider = appleProvider; } public String getAppleProvider() { return appleProvider; } public void displayName(){ System.out.println(\"水果的名字是：苹果\"); }} FruitRun.java 12345678/** * 输出结果 */public class FruitRun { public static void main(String[] args) { FruitInfoUtil.getFruitInfo(Apple.class); }} 运行结果： 123水果名称：Apple水果颜色：RED供应商编号：1 供应商名称：陕西红富士集团 供应商地址：陕西省西安市延安路89号红富士大厦 参考资料","link":"/2019/05/31/java注解Annotation说明实例.html"},{"title":"elasticsearch6.x倒排索引和分词","text":"摘要倒排索引（Inverted Index）也叫反向索引，有反向索引必有正向索引。通俗地来讲，正向索引是通过key找value，反向索引则是通过value找key。 倒排索引（Inverted Index）也叫反向索引，有反向索引必有正向索引。通俗地来讲，正向索引是通过key找value，反向索引则是通过value找key。 倒排索引 正排索引：文档id到单词的关联关系 倒排索引：单词到文档id的关联关系 示例：对以下三个文档去除停用词后构造倒排索引 倒排索引-查询过程查询包含“搜索引擎”的文档 通过倒排索引获得“搜索引擎”对应的文档id列表，有1，3 通过正排索引查询1和3的完整内容 返回最终结果 倒排索引-组成 单词词典（Term Dictionary） 倒排列表（Posting List） 单词词典（Term Dictionary）单词词典的实现一般用B+树，B+树构造的可视化过程网址: B+ Tree Visualization 关于B树和B+树 维基百科-B树 维基百科-B+树 B树和B+树的插入、删除图文详解 倒排列表（Posting List） 倒排列表记录了单词对应的文档集合，有倒排索引项（Posting）组成 倒排索引项主要包含如下信息： 文档id用于获取原始信息 单词频率（TF，Term Frequency），记录该单词在该文档中出现的次数，用于后续相关性算分 位置（Posting），记录单词在文档中的分词位置（多个），用于做词语搜索（Phrase Query） 偏移（Offset），记录单词在文档的开始和结束位置，用于高亮显示 B+树内部结点存索引，叶子结点存数据，这里的 单词词典就是B+树索引，倒排列表就是数据，整合在一起后如下所示 ES存储的是一个JSON格式的文档，其中包含多个字段，每个字段会有自己的倒排索引 分词分词是将文本转换成一系列单词（Term or Token）的过程，也可以叫文本分析，在ES里面称为Analysis 分词器分词器是ES中专门处理分词的组件，英文为Analyzer，它的组成如下： Character Filters：针对原始文本进行处理，比如去除html标签 Tokenizer：将原始文本按照一定规则切分为单词 Token Filters：针对Tokenizer处理的单词进行再加工，比如转小写、删除或增新等处理 分词器调用顺序 Analyze APIES提供了一个可以测试分词的API接口，方便验证分词效果，endpoint是_analyze 可以直接指定analyzer进行测试 可以直接指定索引中的字段进行测试 1234567891011POST test_index/doc{ \"username\": \"whirly\", \"age\":22}POST test_index/_analyze{ \"field\": \"username\", \"text\": [\"hello world\"]} 可以自定义分词器进行测试 123456POST _analyze{ &quot;tokenizer&quot;: &quot;standard&quot;, &quot;filter&quot;: [&quot;lowercase&quot;], &quot;text&quot;: [&quot;Hello World&quot;]} 预定义的分词器ES自带的分词器有如下： Standard Analyzer 默认分词器 按词切分，支持多语言 小写处理 Simple Analyzer 按照非字母切分 小写处理 Whitespace Analyzer 空白字符作为分隔符 Stop Analyzer 相比Simple Analyzer多了去除请用词处理 停用词指语气助词等修饰性词语，如the, an, 的， 这等 Keyword Analyzer 不分词，直接将输入作为一个单词输出 Pattern Analyzer 通过正则表达式自定义分隔符 默认是\\W+，即非字词的符号作为分隔符 Language Analyzer 提供了30+种常见语言的分词器 示例：停用词分词器 12345POST _analyze{ \"analyzer\": \"stop\", \"text\": [\"The 2 QUICK Brown Foxes jumped over the lazy dog's bone.\"]} 结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667{ \"tokens\": [ { \"token\": \"quick\", \"start_offset\": 6, \"end_offset\": 11, \"type\": \"word\", \"position\": 1 }, { \"token\": \"brown\", \"start_offset\": 12, \"end_offset\": 17, \"type\": \"word\", \"position\": 2 }, { \"token\": \"foxes\", \"start_offset\": 18, \"end_offset\": 23, \"type\": \"word\", \"position\": 3 }, { \"token\": \"jumped\", \"start_offset\": 24, \"end_offset\": 30, \"type\": \"word\", \"position\": 4 }, { \"token\": \"over\", \"start_offset\": 31, \"end_offset\": 35, \"type\": \"word\", \"position\": 5 }, { \"token\": \"lazy\", \"start_offset\": 40, \"end_offset\": 44, \"type\": \"word\", \"position\": 7 }, { \"token\": \"dog\", \"start_offset\": 45, \"end_offset\": 48, \"type\": \"word\", \"position\": 8 }, { \"token\": \"s\", \"start_offset\": 49, \"end_offset\": 50, \"type\": \"word\", \"position\": 9 }, { \"token\": \"bone\", \"start_offset\": 51, \"end_offset\": 55, \"type\": \"word\", \"position\": 10 } ]} 中文分词 难点 中文分词指的是将一个汉字序列切分为一个一个的单独的词。在英文中，单词之间以空格作为自然分界词，汉语中词没有一个形式上的分界符 上下文不同，分词结果迥异，比如交叉歧义问题 常见分词系统 IK：实现中英文单词的切分，可自定义词库，支持热更新分词词典 jieba：支持分词和词性标注，支持繁体分词，自定义词典，并行分词等 Hanlp：由一系列模型与算法组成的Java工具包，目标是普及自然语言处理在生产环境中的应用 THUAC：中文分词和词性标注 安装ik中文分词插件12345# 在Elasticsearch安装目录下执行命令，然后重启esbin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.0/elasticsearch-analysis-ik-6.3.0.zip# 如果由于网络慢，安装失败，可以先下载好zip压缩包，将下面命令改为实际的路径，执行，然后重启esbin/elasticsearch-plugin install file:///path/to/elasticsearch-analysis-ik-6.3.0.zip ik测试 - ik_smart 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667POST _analyze{ \"analyzer\": \"ik_smart\", \"text\": [\"公安部：各地校车将享最高路权\"]}# 结果{ \"tokens\": [ { \"token\": \"公安部\", \"start_offset\": 0, \"end_offset\": 3, \"type\": \"CN_WORD\", \"position\": 0 }, { \"token\": \"各地\", \"start_offset\": 4, \"end_offset\": 6, \"type\": \"CN_WORD\", \"position\": 1 }, { \"token\": \"校车\", \"start_offset\": 6, \"end_offset\": 8, \"type\": \"CN_WORD\", \"position\": 2 }, { \"token\": \"将\", \"start_offset\": 8, \"end_offset\": 9, \"type\": \"CN_CHAR\", \"position\": 3 }, { \"token\": \"享\", \"start_offset\": 9, \"end_offset\": 10, \"type\": \"CN_CHAR\", \"position\": 4 }, { \"token\": \"最高\", \"start_offset\": 10, \"end_offset\": 12, \"type\": \"CN_WORD\", \"position\": 5 }, { \"token\": \"路\", \"start_offset\": 12, \"end_offset\": 13, \"type\": \"CN_CHAR\", \"position\": 6 }, { \"token\": \"权\", \"start_offset\": 13, \"end_offset\": 14, \"type\": \"CN_CHAR\", \"position\": 7 } ]} ik测试 - ik_max_word 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081POST _analyze{ \"analyzer\": \"ik_max_word\", \"text\": [\"公安部：各地校车将享最高路权\"]}# 结果{ \"tokens\": [ { \"token\": \"公安部\", \"start_offset\": 0, \"end_offset\": 3, \"type\": \"CN_WORD\", \"position\": 0 }, { \"token\": \"公安\", \"start_offset\": 0, \"end_offset\": 2, \"type\": \"CN_WORD\", \"position\": 1 }, { \"token\": \"部\", \"start_offset\": 2, \"end_offset\": 3, \"type\": \"CN_CHAR\", \"position\": 2 }, { \"token\": \"各地\", \"start_offset\": 4, \"end_offset\": 6, \"type\": \"CN_WORD\", \"position\": 3 }, { \"token\": \"校车\", \"start_offset\": 6, \"end_offset\": 8, \"type\": \"CN_WORD\", \"position\": 4 }, { \"token\": \"将\", \"start_offset\": 8, \"end_offset\": 9, \"type\": \"CN_CHAR\", \"position\": 5 }, { \"token\": \"享\", \"start_offset\": 9, \"end_offset\": 10, \"type\": \"CN_CHAR\", \"position\": 6 }, { \"token\": \"最高\", \"start_offset\": 10, \"end_offset\": 12, \"type\": \"CN_WORD\", \"position\": 7 }, { \"token\": \"路\", \"start_offset\": 12, \"end_offset\": 13, \"type\": \"CN_CHAR\", \"position\": 8 }, { \"token\": \"权\", \"start_offset\": 13, \"end_offset\": 14, \"type\": \"CN_CHAR\", \"position\": 9 } ]} ik两种分词模式ik_max_word 和 ik_smart 什么区别? ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合； ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”。 自定义分词当自带的分词无法满足需求时，可以自定义分词，通过定义Character Filters、Tokenizer和Token Filters实现 Character Filters 在Tokenizer之前对原始文本进行处理，比如增加、删除或替换字符等 自带的如下: HTML Strip Character Filter：去除HTML标签和转换HTML实体 Mapping Character Filter：进行字符替换操作 Pattern Replace Character Filter：进行正则匹配替换 会影响后续tokenizer解析的position和offset信息 Character Filters测试1234567891011121314151617181920212223POST _analyze{ \"tokenizer\": \"keyword\", \"char_filter\": [\"html_strip\"], \"text\": [\"&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;\"]}# 结果{ \"tokens\": [ { \"token\": \"\"\"I'm so happy!\"\"\", \"start_offset\": 0, \"end_offset\": 32, \"type\": \"word\", \"position\": 0 } ]} Tokenizers 将原始文本按照一定规则切分为单词（term or token） 自带的如下： standard 按照单词进行分割 letter 按照非字符类进行分割 whitespace 按照空格进行分割 UAX URL Email 按照standard进行分割，但不会分割邮箱和URL Ngram 和 Edge NGram 连词分割 Path Hierarchy 按照文件路径进行分割 Tokenizers 测试1234567891011121314151617181920212223242526272829303132POST _analyze{ \"tokenizer\": \"path_hierarchy\", \"text\": [\"/path/to/file\"]}# 结果{ \"tokens\": [ { \"token\": \"/path\", \"start_offset\": 0, \"end_offset\": 5, \"type\": \"word\", \"position\": 0 }, { \"token\": \"/path/to\", \"start_offset\": 0, \"end_offset\": 8, \"type\": \"word\", \"position\": 0 }, { \"token\": \"/path/to/file\", \"start_offset\": 0, \"end_offset\": 13, \"type\": \"word\", \"position\": 0 } ]} Token Filters 对于tokenizer输出的单词（term）进行增加、删除、修改等操作 自带的如下： lowercase 将所有term转为小写 stop 删除停用词 Ngram 和 Edge NGram 连词分割 Synonym 添加近义词的term Token Filters测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950POST _analyze{ \"text\": [ \"a Hello World!\" ], \"tokenizer\": \"standard\", \"filter\": [ \"stop\", \"lowercase\", { \"type\": \"ngram\", \"min_gram\": 4, \"max_gram\": 4 } ]}# 结果{ \"tokens\": [ { \"token\": \"hell\", \"start_offset\": 2, \"end_offset\": 7, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 1 }, { \"token\": \"ello\", \"start_offset\": 2, \"end_offset\": 7, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 1 }, { \"token\": \"worl\", \"start_offset\": 8, \"end_offset\": 13, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 2 }, { \"token\": \"orld\", \"start_offset\": 8, \"end_offset\": 13, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 2 } ]} 自定义分词自定义分词需要在索引配置中设定 char_filter、tokenizer、filter、analyzer等 自定义分词示例: 分词器名称：my_custom\\ 过滤器将token转为大写 1234567891011121314151617181920PUT test_index_1{ \"settings\": { \"analysis\": { \"analyzer\": { \"my_custom_analyzer\": { \"type\": \"custom\", \"tokenizer\": \"standard\", \"char_filter\": [ \"html_strip\" ], \"filter\": [ \"uppercase\", \"asciifolding\" ] } } } }} 12345678910111213141516171819202122232425262728293031323334353637383940// javaXContentFactory.jsonBuilder() .startObject().startObject(\"analysis\") .startObject(\"normalizer\").startObject(Normalizers.CASE_INSENSITIVE) .field(\"type\", \"custom\") .field(\"filter\", \"lowercase\") .endObject().endObject() // 动态同义词 .startObject(\"filter\") .startObject(\"dynamic_synonym\").field(\"type\", \"dynamic_synonym\").field(\"tokenizer\", \"ik_smart\").endObject().endObject() .startObject(\"analyzer\") // 自定义分词器 .startObject(\"ik\") .field(\"filter\", \"\") .field(\"char_filter\", Arrays.asList(\"char_mapper\")) .field(\"type\", \"custom\") .field(\"tokenizer\", \"ik_max_word\") .endObject() // 搜索时处理同义词 .startObject(\"ikt\") .field(\"filter\", Arrays.asList(\"dynamic_synonym\")) .field(\"char_filter\", Arrays.asList(\"char_mapper\")) .field(\"type\", \"custom\") .field(\"tokenizer\", \"ik_smart\") .endObject() .endObject() // 自定义字符过滤 .startObject(\"char_filter\") .startObject(\"char_mapper\") .field(\"type\", \"mapping\") .field(\"mappings_path\", \"analysis/mapping.txt\") .endObject() .endObject() .endObject().endObject(); 自定义分词器测试1234567891011121314151617181920212223242526272829303132POST test_index_1/_analyze{ \"analyzer\": \"my_custom_analyzer\", \"text\": [\"&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;\"]}# 结果{ \"tokens\": [ { \"token\": \"I'M\", \"start_offset\": 3, \"end_offset\": 11, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 0 }, { \"token\": \"SO\", \"start_offset\": 12, \"end_offset\": 14, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 1 }, { \"token\": \"HAPPY\", \"start_offset\": 18, \"end_offset\": 27, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 2 } ]} 分词使用说明分词会在如下两个时机使用： 创建或更新文档时(Index Time)，会对相应的文档进行分词处理 查询时（Search Time），会对查询语句进行分词 查询时通过analyzer指定分词器 通过index mapping设置search_analyzer实现 一般不需要特别指定查询时分词器，直接使用索引分词器即可，否则会出现无法匹配的情况 分词使用建议 明确字段是否需要分词，不需要分词的字段就将type设置为keyword，可以节省空间和提高写性能 善用_analyze API，查看文档的分词结果 参考自","link":"/2019/05/06/elasticsearch6-x倒排索引和分词.html"},{"title":"Java版常用正则表达式说明","text":"摘要正则表达式在几乎所有语言中都可以使用，无论是前端的JavaScript、还是后端的Java、c#。他们都提供相应的接口/函数支持正则表达式。 元字符元字符说明：匹配除换行符以外的任意字符 w：匹配字母或数字或下划线或汉字 s：匹配任意的空白符 d：匹配数字匹配单词的开始或结束 ^：匹配字符串的开始 $：匹配字符串的结束 eg:匹配有abc开头的字符串：abc或者^abc 匹配8位数字的QQ号码：^dddddddd$ 匹配1开头11位数字的手机号码：^1dddddddddd$ 重复限定符为了处理这些重复问题，正则表达式中一些重复限定符，把重复部分用合适的限定符替代 语法说明： *重复零次或更多次 +重复一次或更多次 ?重复零次或一次 {n}重复n次 {n,}重复n次或更多次 {n,m}重复n到m次 匹配8位数字的QQ号码：^d{8}$ 匹配1开头11位数字的手机号码：^1d{10}$ 匹配银行卡号是14~18位的数字：^d{14,18}$ 匹配以a开头的，0个或多个b结尾的字符串^ab*$ 分组正则表达式中用小括号()来做分组，也就是括号中的内容作为一个整体。 因此当我们要匹配多个ab时，我们可以这样。 如匹配字符串中包含0到多个ab开头：^(ab)* 转义我们看到正则表达式用小括号来做分组，那么问题来了： 如果要匹配的字符串中本身就包含小括号，那是不是冲突？应该怎么办？ 针对这种情况，正则提供了转义的方式，也就是要把这些元字符、限定符或者关键字转义成普通的字符，做法很简答，就是在要转义的字符前面加个斜杠，也就是\\即可。 如要匹配以(ab)开头：^\\(ab\\)* 条件或回到我们刚才的手机号匹配，我们都知道：国内号码都来自三大网，它们都有属于自己的号段，比如联通有130/131/132/155/156/185/186/145/176等号段，假如让我们匹配一个联通的号码，那按照我们目前所学到的正则，应该无从下手的，因为这里包含了一些并列的条件，也就是“或”，那么在正则中是如何表示“或”的呢？ 正则用符号 | 来表示或，也叫做分支条件，当满足正则里的分支条件的任何一种条件时，都会当成是匹配成功。 那么我们就可以用“或”条件来处理这个问题：^(130|131|132|155|156|185|186|145|176)d{8}$ 区间正则提供一个元字符中括号 [] 来表示区间条件。 限定0到9 可以写成[0-9] 限定A-Z 写成[A-Z] 限定某些数字 [165] 那上面的正则我们还改成这样： ^((13[0-2])|(15[56])|(18[5-6])|145|176)d{8}$ 好了，正则表达式的基本用法就讲到这里了，其实它还有非常多的知识点以及元字符，我们在此只列举了部分元字符和语法来讲，旨在给那些不懂正则或者想学正则但有看不下去文档的人做一个快速入门级的教程，看完本教程，即使你不能写出高大上的正则，至少也能写一些简单的正则或者看得懂别人写的正则了。 正则进阶知识点1.零宽断言断言：俗话的断言就是“我断定什么什么”，而正则中的断言，就是说正则可以指明在指定的内容的前面或后面会出现满足指定规则的内容，意思正则也可以像人类那样断定什么什么，比如”ss1aa2bb3”,正则可以用断言找出aa2前面有bb3，也可以找出aa2后面有ss1. 零宽：就是没有宽度，在正则中，断言只是匹配位置，不占字符，也就是说，匹配结果里是不会返回断言本身。 eg:假设我们要用爬虫抓取csdn里的文章阅读量。通过查看源代码可以看到文章阅读量这个内容是这样的结构 “阅读数：641“ 其中也就‘641’这个是变量，也就是说不同文章不同的值，当我们拿到这个字符串时，需要获得这里边的‘641’有很多种办法，但如果正则应该怎么匹配呢？ 正向先行断言（正前瞻）语法：（?=pattern） 作用：匹配pattern表达式的前面内容，不返回本身。 这样子说，还是一脸懵逼，好吧，回归刚才那个栗子，要取到阅读量，在正则表达式中就意味着要能匹配到‘’前面的数字内容。 按照上所说的正向先行断言可以匹配表达式前面的内容，那意思就是:(?=) 就可以匹配到前面的内容了。 匹配什么内容呢？如果要所有内容那就是： 12345678910 String reg=\".+(?=&lt;/span&gt;)\";String test = \"&lt;span class=\"read-count\"&gt;阅读数：641&lt;/span&gt;\"; Pattern pattern = Pattern.compile(reg); Matcher mc= pattern.matcher(test); while(mc.find()){ System.out.println(\"匹配结果：\") System.out.println(mc.group()); } //匹配结果：//&lt;span class=\"read-count\"&gt;阅读数：641 可是老哥我们要的只是前面的数字呀，那也简单咯，匹配数字 d,那可以改成： 123456789String reg=\"\\d+(?=&lt;/span&gt;)\";String test = \"&lt;span class=\\\"read-count\\\"&gt;阅读数：641&lt;/span&gt;\";Pattern pattern = Pattern.compile(reg);Matcher mc= pattern.matcher(test);while(mc.find()){ System.out.println(mc.group());}//匹配结果：//641 大功告成！ 正向后行断言（正后顾）语法：（?&lt;=pattern） 作用：匹配pattern表达式的后面的内容，不返回本身。 有先行就有后行，先行是匹配前面的内容，那后行就是匹配后面的内容啦。 上面的栗子，我们也可以用后行断言来处理。 12345678910//(?&lt;=&lt;span class=\"read-count\"&gt;阅读数：)d+String reg=\"(?&lt;=&lt;span class=\\\"read-count\\\"&gt;阅读数：)\\d+\";String test = \"&lt;span class=\\\"read-count\\\"&gt;阅读数：641&lt;/span&gt;\"; Pattern pattern = Pattern.compile(reg); Matcher mc= pattern.matcher(test); while(mc.find()){ System.out.println(mc.group()); }//匹配结果：//641 就这么简单。 负向先行断言（负前瞻）语法：(?!pattern) 作用：匹配非pattern表达式的前面内容，不返回本身。 有正向也有负向，负向在这里其实就是非的意思。 举个栗子：比如有一句 “我爱祖国，我是祖国的花朵” 现在要找到不是’的花朵’前面的祖国 用正则就可以这样写：祖国(?!的花朵)。 负向后行断言（负后顾）语法：(?&lt;!pattern) 作用：匹配非pattern表达式的后面内容，不返回本身。 2.捕获和非捕获单纯说到捕获，他的意思是匹配表达式，但捕获通常和分组联系在一起，也就是“捕获组”。 捕获组：匹配子表达式的内容，把匹配结果保存到内存中中数字编号或显示命名的组里，以深度优先进行编号，之后可以通过序号或名称来使用这些匹配结果。 而根据命名方式的不同，又可以分为两种组。 数字编号捕获组 语法：(exp) 解释：从表达式左侧开始，每出现一个左括号和它对应的右括号之间的内容为一个分组，在分组中，第0组为整个表达式，第一组开始为分组。 比如固定电话的：020-85653333 他的正则表达式为：(0d{2})-(d{8}) 按照左括号的顺序，这个表达式有如下分组： 序号编号分组内容00(0d{2})-(d{8})020-8565333311(0d{2})02022(d{8})85653333 我们用Java来验证一下： 12345678910String test = \"020-85653333\"; String reg=\"(0\\d{2})-(\\d{8})\"; Pattern pattern = Pattern.compile(reg); Matcher mc= pattern.matcher(test); if(mc.find()){ System.out.println(\"分组的个数有：\"+mc.groupCount()); for(int i=0;i&lt;=mc.groupCount();i++){ System.out.println(\"第\"+i+\"个分组为：\"+mc.group(i)); } } 输出结果： 1234分组的个数有：2第0个分组为：020-85653333第1个分组为：020第2个分组为：85653333 可见，分组个数是2，但是因为第0个为整个表达式本身，因此也一起输出了。 命名编号捕获组 语法：(?exp) 解释：分组的命名由表达式中的name指定 比如区号也可以这样写:(?d{2})-(?d{8}) 按照左括号的顺序，这个表达式有如下分组：序号名称分组内容00(0d{2})-(d{8})020-856533331quhao(0d{2})0202haoma(d{8})85653333 用代码来验证一下： 123456789String test = \"020-85653333\";String reg=\"(?&lt;quhao&gt;0\\d{2})-(?&lt;haoma&gt;\\d{8})\";Pattern pattern = Pattern.compile(reg);Matcher mc= pattern.matcher(test);if(mc.find()){ System.out.println(\"分组的个数有：\"+mc.groupCount()); System.out.println(mc.group(\"quhao\")); System.out.println(mc.group(\"haoma\"));} 输出结果： 123分组的个数有：2分组名称为:quhao,匹配内容为：020分组名称为:haoma,匹配内容为：85653333 非捕获组 语法：(?:exp) 解释：和捕获组刚好相反，它用来标识那些不需要捕获的分组，说的通俗一点，就是你可以根据需要去保存你的分组。 比如上面的正则表达式，程序不需要用到第一个分组，那就可以这样写：(?:d{2})-(d{8}) 序号编号分组内容00(0d{2})-(d{8})020-8565333311(d{8})85653333 验证一下： 12345678910String test = \"020-85653333\";String reg=\"(?:0\\d{2})-(\\d{8})\";Pattern pattern = Pattern.compile(reg);Matcher mc= pattern.matcher(test);if(mc.find()){ System.out.println(\"分组的个数有：\"+mc.groupCount()); for(inti=0;i&lt;=mc.groupCount();i++){ System.out.println(\"第\"+i+\"个分组为：\"+mc.group(i)); }} 输出结果： 123分组的个数有：1第0个分组为：020-85653333第1个分组为：85653333 3.反向引用上面讲到捕获，我们知道：捕获会返回一个捕获组，这个分组是保存在内存中，不仅可以在正则表达式外部通过程序进行引用，也可以在正则表达式内部进行引用，这种引用方式就是反向引用。 根据捕获组的命名规则，反向引用可分为： 数字编号组反向引用：k或 umber 命名编号组反向引用：k或者’name’ 好了 讲完了，懂吗？不懂！！！ 可能连前面讲的捕获有什么用都还不懂吧？ 其实只是看完捕获不懂不会用是很正常的！ 因为捕获组通常是和反向引用一起使用的。 上面说到捕获组是匹配子表达式的内容按序号或者命名保存起来以便使用。 注意两个字眼：“内容” 和 “使用”。 这里所说的“内容”，是匹配结果，而不是子表达式本身，强调这个有什么用？嗯，先记住。 那这里所说的“使用”是怎样使用呢？ 因为它的作用主要是用来查找一些重复的内容或者做替换指定字符。 还是举栗子吧。 比如要查找一串字母”aabbbbgbddesddfiid”里成对的字母 如果按照我们之前学到的正则，什么区间啊限定啊断言啊可能是办不到的， 现在我们先用程序思维理一下思路： 1）匹配到一个字母 2）匹配第下一个字母，检查是否和上一个字母是否一样 3）如果一样，则匹配成功，否则失败 这里的思路2中匹配下一个字母时，需要用到上一个字母，那怎么记住上一个字母呢？？？ 这下子捕获就有用处啦，我们可以利用捕获把上一个匹配成功的内容用来作为本次匹配的条件 好了，有思路就要实践 首先匹配一个字母：w 我们需要做成分组才能捕获，因此写成这样：(w) 那这个表达式就有一个捕获组：（w） 然后我们要用这个捕获组作为条件，那就可以：(w) 这样就大功告成了 可能有人不明白了，是什么意思呢？ 还记得捕获组有两种命名方式吗，一种是是根据捕获分组顺序命名，一种是自定义命名来作为捕获组的命名 在默认情况下都是以数字来命名，而且数字命名的顺序是从1开始的 因此要引用第一个捕获组，根据反向引用的数字命名规则 就需要 k或者 当然，通常都是是后者。 我们来测试一下： 1234567String test = \"aabbbbgbddesddfiid\";Pattern pattern = Pattern.compile(\"(\\w)\\1\");Matcher mc= pattern.matcher(test);while(mc.find()){ System.out.println(mc.group());} 输出结果： 1aabbbbddddii 嗯，这就是我们想要的了。 在举个替换的例子，假如想要把字符串中abc换成a。 123String test = \"abcbbabcbcgbddesddfiid\";String reg=\"(a)(b)c\";System.out.println(test.replaceAll(reg, \"$1\")); 输出结果： 1abbabcgbddesddfiid 4.贪婪和非贪婪 贪婪 我们都知道，贪婪就是不满足，尽可能多的要。 在正则中，贪婪也是差不多的意思: 贪婪匹配：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符，这匹配方式叫做贪婪匹配。 特性：一次性读入整个字符串进行匹配，每当不匹配就舍弃最右边一个字符，继续匹配，依次匹配和舍弃（这种匹配-舍弃的方式也叫做回溯），直到匹配成功或者把整个字符串舍弃完为止，因此它是一种最大化的数据返回，能多不会少。 前面我们讲过重复限定符，其实这些限定符就是贪婪量词，比如表达式：d{3,6}。 用来匹配3到6位数字，在这种情况下，它是一种贪婪模式的匹配，也就是假如字符串里有6个个数字可以匹配，那它就是全部匹配到。 如下面的代码。 123456789String reg=\"\\d{3,6}\";String test=\"61762828 176 2991 871\";System.out.println(\"文本：\"+test);System.out.println(\"贪婪模式：\"+reg);Pattern p1 =Pattern.compile(reg);Matcher m1 = p1.matcher(test);while(m1.find()){ System.out.println(\"匹配结果：\"+m1.group(0));} 输出结果： 123456文本：61762828 176 2991 44 871贪婪模式：d{3,6}匹配结果：617628匹配结果：176匹配结果：2991匹配结果：871 由结果可见：本来字符串中的“61762828”这一段，其实只需要出现3个（617）就已经匹配成功了的，但是他并不满足，而是匹配到了最大能匹配的字符，也就是6个。 一个量词就如此贪婪了， 那有人会问，如果多个贪婪量词凑在一起，那他们是如何支配自己的匹配权的呢？ 是这样的，多个贪婪在一起时，如果字符串能满足他们各自最大程度的匹配时，就互不干扰，但如果不能满足时，会根据深度优先原则，也就是从左到右的每一个贪婪量词，优先最大数量的满足，剩余再分配下一个量词匹配。 123456789String reg=\"(\\d{1,2})(\\d{3,4})\";String test=\"61762828 176 2991 87321\";System.out.println(\"文本：\"+test);System.out.println(\"贪婪模式：\"+reg);Pattern p1 =Pattern.compile(reg);Matcher m1 = p1.matcher(test);while(m1.find()){ System.out.println(\"匹配结果：\"+m1.group(0));} 输出结果： 12345文本：61762828 176 2991 87321贪婪模式：(d{1,2})(d{3,4})匹配结果：617628匹配结果：2991匹配结果：87321 “617628” 是前面的d{1,2}匹配出了61，后面的匹配出了7628 “2991” 是前面的d{1,2}匹配出了29 ，后面的匹配出了91 “87321”是前面的d{1,2}匹配出了87，后面的匹配出了321 懒惰（非贪婪） 懒惰匹配：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能少的字符，这匹配方式叫做懒惰匹配。 特性：从左到右，从字符串的最左边开始匹配，每次试图不读入字符匹配，匹配成功，则完成匹配，否则读入一个字符再匹配，依此循环（读入字符、匹配）直到匹配成功或者把字符串的字符匹配完为止。 懒惰量词是在贪婪量词后面加个“？” 代码说明 *?重复任意次，但尽可能少重复 +?重复1次或更多次，但尽可能少重复 ??重复0次或1次，但尽可能少重复 {n,m}?重复n到m次，但尽可能少重复 {n,}?重复n次以上，但尽可能少重复。 123456789String reg=\"(\\d{1,2}?)(\\d{3,4})\";String test=\"61762828 176 2991 87321\";System.out.println(\"文本：\"+test);System.out.println(\"贪婪模式：\"+reg);Pattern p1 =Pattern.compile(reg);Matcher m1 = p1.matcher(test);while(m1.find()){ System.out.println(\"匹配结果：\"+m1.group(0));} 输出结果： 12345文本：61762828 176 2991 87321贪婪模式：(d{1,2}?)(d{3,4})匹配结果：61762匹配结果：2991匹配结果：87321 “61762” 是左边的懒惰匹配出6，右边的贪婪匹配出1762 “2991” 是左边的懒惰匹配出2，右边的贪婪匹配出991 “87321” 左边的懒惰匹配出8，右边的贪婪匹配出7321 5.反义前面说到元字符的都是要匹配什么什么，当然如果你想反着来，不想匹配某些字符，正则也提供了一些常用的反义元字符。 元字符解释: W匹配任意不是字母，数字，下划线，汉字的字符 S匹配任意不是空白符的字符 D匹配任意非数字的字符 B匹配不是单词开头或结束的位置 [x]匹配除了x以外的任意字符 [aeiou]匹配除了aeiou这几个字母以外的任意字符 正则进阶知识就讲到这里，正则是一门博大精深的语言，其实学会它的一些语法和知识点还算不太难，但想要做到真正学以致用能写出非常6的正则，还有很远的距离，只有真正对它感兴趣的，并且经常研究和使用它，才会渐渐的理解它的博大精深之处，我就带你们走到这，剩下的，靠自己啦。 参考资料","link":"/2019/04/28/Java版常用正则表达式说明.html"},{"title":"Elasticsearch常用工具api","text":"摘要Elasticsearch 是一个高度可扩展且开源的全文检索和分析引擎。它可以让您快速且近实时地存储，检索以及分析海量数据。它通常用作那些具有复杂搜索功能和需求的应用的底层引擎或者技术。 下面是 Elasticsearch 一些简单的使用案例 : 您运行一个可以让您顾客来搜索您所售产品的在线的网络商店。在这种情况下，您可以使用 Elasticsearch 来存储您的整个产品的目录和库存，并且为他们提供搜索和自动完成的建议。 您想要去收集日志或交易数据，并且您还想要去分析和挖掘这些数据以来找出趋势，统计，概述，或者异常现。在这种情况下，您可以使用 Logstash（Elasticsearch/Logstash/Kibana 技术栈中的一部分）来收集，聚合，以及解析数据，然后让 Logstash 发送这些数据到 Elasticsearch。如果这些数据存在于 Elasticsearch 中，那么您就可以执行搜索和聚合以挖掘出任何您感兴趣的信息。 您运行一个价格警告平台，它允许客户指定精确的价格，如“我感兴趣的是购买指定的电子产品，如果任何供应商该产品的价格在未来一个月内低于 $X 这个价钱的话我应该被通知到”。在这种情况下，您可以收集供应商的价格，推送它们到 Elasticsearch 中去，然后使用 reverse-search（Percolator）（反向搜索（过滤器））功能以匹配客户查询价格的变动，最后如果发现匹配成功就给客户发出通知。 您必须分析/商业智能的需求，并希望快速的研究，分析，可视化，并且需要 ad-hoc（即席查询）海量数据（像数百万或者数十亿条记录）上的质疑。在这种情况下，您可以使用 Elasticsearch 来存储数据，然后使用 Kibana（Elasticsearch/Logstash/Kibana 技术栈中的一部分）以建立一个能够可视化的对您很重要的数据方面的定制的 dashboards（面板）。此外，您还可以使用 Elasticsearch 的聚合功能对您的数据执行复杂的商业智能查询 对于本教程的其余部分，我将引导您完成 Elasticsearch 的启动和运行的过程，同时了解其原理，并执行像 indexing（索引），searching（查询）和 modifing（修改）数据的基础操作。在本教程的最后一部分，您应该可以清楚的了解到 Elasticsearch 是什么，它是如何工作的，并有希望获得启发。看您如何使用它来构建复杂的搜索应用程序或者从数据中挖掘出想要的信息。 常用实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238# 常用kibana脚本(可以自动填充，比较好用)PUT /test_business/data/1 #更改数据{ \"name\":\"zhe\"}}POST _analyze #实时分词{ \"text\": \"张月超\", \"analyzer\": \"ik_max_word\"}DELETE /analyze_index #删除索引GET analyze_index/_settings #查看索引_settingsGET analyze_index/_mapping #查看索引_mappingPOST /analyze_index/data/_mapping #设置mapping{ \"dynamic\": \"false\", \"properties\": { \"name\": { \"type\": \"text\", \"analyzer\": \"ik\" } }}POST /analyze_index #设置settings{ \"settings\": { \"index\": { \"analysis\": { \"normalizer\": { \"case_insensitive_normalizer\": { \"type\": \"custom\", \"filter\": \"lowercase\" } }, \"filter\": { \"my_synonym\": { \"type\": \"synonym\", \"synonyms_path\": \"analysis-ik/extra/synonyms.dic\" } }, \"analyzer\": { \"ik\": { \"filter\": [ \"my_synonym\" ], \"char_filter\": [ \"my_char_mapper\" ], \"type\": \"custom\", \"tokenizer\": \"ik_max_word\" } }, \"char_filter\": { \"my_char_mapper\": { \"type\": \"mapping\", \"mappings_path\": \"analysis-ik/extra/pre_filter_mapping.dic\" } } } } }, \"mapping\": { \"data\": { \"properties\": { \"name\": { \"type\": \"text\", \"analyzer\": \"ik\" } } } }}GET /es_test_analyzer/_settingsGET /es_test_analyzer/_mappingGET /analyze_index/data/1POST /es_test_analyzer/_analyze{ \"text\": \"超越\", \"analyzer\": \"ik_max_word\"}POST /es_test_analyzer/data/1{ \"name\": \"张月超666哈哈张月超\", \"nick_name\":\"张月超666哈哈张月超\"}POST /es_test_analyzer/data/2{ \"name\": \"王月\", \"nick_name\":\"王月\"}POST /es_test_analyzer/data/3{ \"name\": \"超越\", \"nick_name\":\"超越\"}GET /es_test_analyzer/data/1GET /es_test_analyzer/data/3/_termvectors?fields=nick_name # 查看索引中分词情况GET /es_test_analyzer/data/_search{ \"query\": { \"multi_match\": { \"query\": \"超越\", \"fields\": [ \"nick_name\" ], \"analyzer\": \"ik\", \"operator\": \"or\", \"type\": \"best_fields\" } }, \"highlight\": { \"fields\": { \"name\": { } } }}DELETE /es_test_analyzer/GET /analyze_index/data/_mappingGET /test/data/_search{ \"query\": { \"bool\": { \"should\": [ { \"multi_match\": { \"query\": \"餐饮\", \"fields\": [\"title^2\",\"tags\"] } },{ \"wildcard\": { \"name\": { \"value\": \"*中国*\" } } } ] } }}GET /user/data/9969/_explain # 查看详细id：9969 得分情况{ \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"tacos n frankies\", \"fields\": [ \"name^1.0\", \"info^1.0\" ], \"type\": \"best_fields\", \"operator\": \"or\", \"analyzer\": \"ik_max_word\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } } \"adjust_pure_negative\": true, \"boost\": 1 } } , \"highlight\": { \"fields\": { \"name\": {}, \"info\": {} } }}GET /user/data/_search{ \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"tacos n frankies\", \"fields\": [ \"name^1.0\", \"info^1.0\" ], \"type\": \"best_fields\", \"operator\": \"or\", \"analyzer\": \"ik_max_word\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } } \"adjust_pure_negative\": true, \"boost\": 1 } } , \"highlight\": { \"fields\": { \"name\": {}, \"info\": {} } }} 查看健康信息 curl -XGET ‘localhost:9200/_cat/health?v&amp;pretty’ 我们可以获得 green，yellow，或者 red 的 status。Green 表示一切正常（集群功能齐全）， yellow 表示所有数据可用，但是有些副本尚未分配（集群功能齐全），red 意味着由于某些原因有些数据不可用。注意，集群是 red，它仍然具有部分功能（例如，它将继续从可用的分片中服务搜索请求），但是您可能需要尽快去修复它，因为您已经丢失数据了。 查看所有的索引 curl -XGET ‘localhost:9200/_cat/indices?v&amp;pretty’ Document APISindex api 索引 API 在特定索引中 add ( 添加 ) 或 update *( 更新 ) *a typed JSON document ( 类型化的 JSON 文档 )，使其可搜索。以下示例将 JSON 文档插入到 “twitter” 索引中，ID 为1 ： 123456789101112131415161718192021curl -XPUT 'localhost:9200/twitter/tweet/1?pretty' -H 'Content-Type: application/json' -d'{ \"user\" : \"kimchy\", \"post_date\" : \"2009-11-15T14:12:12\", \"message\" : \"trying out Elasticsearch\"}'结果：{ \"_shards\" : { \"total\" : 2, \"failed\" : 0, \"successful\" : 2 }, \"_index\" : \"twitter\", \"_type\" : \"tweet\", \"_id\" : \"1\", \"_version\" : 1, \"created\" : true, \"result\" : created} total - 指示应对多少 shard copies ( 分片副本 )（ \\primary ( 主 )分片和 replica ( 副本 ) 分片）执行索引操作。 successful - 表示索引操作成功的分片副本的数量。 failed - 在索引操作在副本碎片上失败的情况下包含与复制相关的错误的数组。 当索引操作 successful 返回时，可能不会全部启动副本碎片（默认情况下，只需要主索引，但可以更改此行为）。在这种情况下， total 将等于基于 number_of_replicas 设置的总分片，并且 successful 将等于已启动的分片数（主副本和副本）。如果没有失败， failed 将是 0 。 get apiget api 允许从一个基于其id的 index 中获取一个 JSON格式的 document，下面的示例是从一个在名称为tweet的 type \\下的id为1，名称为twitter的 \\index \\中获取一个JSON格式的 \\document。 1curl -XGET 'http://localhost:9200/twitter/tweet/1' update api12345678910111213141516171819202122232425262728293031323334353637383940# 更新api PUT test/type1/1{ \"counter\" : 1, \"tags\" : [\"red\"]}# 脚本更新POST test/type1/1/_update{ \"script\" : { \"inline\": \"ctx._source.counter += params.count\", \"lang\": \"painless\", \"params\" : { \"count\" : 4 } }}# 将新字段添加到文档：POST test/type1/1/_update{ \"script\" : \"ctx._source.new_field = \\\"value_of_new_field\\\"\"}# 删除字段POST test/type1/1/_update{ \"script\" : \"ctx._source.remove(\\\"new_field\\\")\"}# 甚至可以改变已执行的操作。这个例子就是删除文档，如果 tags包含 green，否则就什么也不做（noop）：POST test/type1/1/_update{ \"script\" : { \"inline\": \"if (ctx._source.tags.contains(params.tag)) { ctx.op = \\\"delete\\\" } else { ctx.op = \\\"none\\\" }\", \"lang\": \"painless\", \"params\" : { \"tag\" : \"green\" } }} 通过查询api更新123456789101112POST twitter/_update_by_query{ \"script\": { \"inline\": \"ctx._source.likes++\", \"lang\": \"painless\" }, \"query\": { \"term\": { \"user\": \"kimchy\" } }} bulk apiBulk API，能够在一个单一的API调用执行多项索引/删除操作。这可以大大提高索引速度。 该 REST API 端点/_bulk，它遵循JSON结构： 1234567action_and_meta_data\\noptional_source\\naction_and_meta_data\\noptional_source\\n....action_and_meta_data\\noptional_source\\n 注意：数据的最终行必须以换行符结束\\n。 可能的操作有 index，create，delete和 update， index 和 `create期望在下一行的作为源，并与索引 API 有相同的语义。（如果文件具有相同的索引和类型的文件已经存在，就会创建失败，必要时候而索引回添加或替换文件）。delete不会作为下一行的源，并与 delete API 中具有相同的语义。update 是希望`部分文档，upsert 和脚本及其选项能够在下一行指定。 delete apidelete API允许基于指定的ID来从索引库中删除一个JSON文件。下面演示了从一个叫twitter的索引库的tweettype下删除文档，id是1: 1$ curl -XDELETE 'http://localhost:9200/twitter/tweet/1' 索引的每个文档都被标记了版本。当删除文档时， 可以通过指定version来确保我们试图删除一个实际上已被删除的文档时，它在此期间并没有改变。在文档中执行的每个写入操作，包括删除，都会使其版本递增。 delete by query api最简单的用法是使用_delete_by_query对每个查询匹配的文档执行删除。这是API: 12345678POST twitter/_delete_by_query{ \"query\": { //① \"match\": { \"message\": \"some message\" } }} term vectors返回有关特定文档字段中的词条的信息和统计信息。文档可以存储在索引中或由用户人工提供。词条向量默认为实时，不是近实时。这可以通过将realtime参数设置为false来更改。 1GET /twitter/tweet/1/_termvectors 可选的，您可以使用url中的参数指定检索信息的字段： 1GET /twitter/tweet/1/_termvectors?fields=message searchquery api结果的分页可以通过使用 from 和 size 参数来完成。 from 参数定义了您要提取的第一个结果的偏移量。 size 参数允许您配置要返回的最大匹配数。 虽然 from 和 size 可以设置为请求参数，但它们也可以在搜索正文中设置。from 默认值为 0，size 默认为 10。 1234567GET /_search{ &quot;from&quot; : 0, &quot;size&quot; : 10, &quot;query&quot; : { &quot;term&quot; : { &quot;user&quot; : &quot;kimchy&quot; } }} 注意 from + size 不能超过 index.max_result_window 索引设置，默认为 10,000。 有关深入滚动的更有效方法，请参阅 Scroll 或 Search After API。 sort排序选项可以有以下值： | asc | 按升序排序 | | desc | 按倒序排序 | 在对 _score 进行排序时，该顺序默认为 desc，在对其他事物进行排序时默认为 asc。 Sort mode Option Elasticsearch支持按数组或多值字段排序。 mode 选项控制选择用于对其所属文档进行排序的数组值。 mode 选项可以具有以下值： | min | 选择最低值。 | | max | 选择最高值。 | | sum | 使用所有值的和作为排序值。 仅适用于基于数字的数组字段。 | | avg | 使用所有值的平均值作为排序值。 仅适用于基于数字的数组字段。 | | median | 使用所有值的中值作为排序值。 仅适用于基于数字的数组字段。 | Elasticsearch 还支持根据一个或多个嵌套对象内的字段进行排序。 通过嵌套字段支持进行的排序在已经存在的排序选项之上具有以下参数： nested_path 定义要排序的嵌套对象。 实际排序字段必须是此嵌套对象内的直接字段。 当通过嵌套字段排序时，此字段是必需的。 nested_filter 嵌套路径中的内部对象应与其匹配的过滤器，以便通过排序考虑其字段值。 常见的情况是在嵌套的过滤器或查询中重复查询/过滤。 默认情况下，没有 nested_filter 是激活的。 Nested sorting example 在下面的示例中，offer是一个类型为嵌套的字段。 需要指定nested_path; 否则，elasticsearch不知道需要捕获哪个嵌套级排序值。 123456789101112131415161718POST /_search{ \"query\" : { \"term\" : { \"product\" : \"chocolate\" } }, \"sort\" : [ { \"offer.price\" : { \"mode\" : \"avg\", \"order\" : \"asc\", \"nested_path\" : \"offer\", \"nested_filter\" : { \"term\" : { \"offer.color\" : \"blue\" } } } } ]} 当通过脚本排序和按地理距离排序时，也支持嵌套排序。 Missing Values 缺少的参数指定应如何处理缺少字段的文档：缺少的值可以设置为 last，first 或自定义值（将用于缺少文档作为排序值）。 123456789GET /_search{ &quot;sort&quot; : [ { &quot;price&quot; : {&quot;missing&quot; : &quot;_last&quot;} } ], &quot;query&quot; : { &quot;term&quot; : { &quot;product&quot; : &quot;chocolate&quot; } }} Note：如果嵌套的内部对象与 nested_filter 不匹配，则使用缺少的值。 Geo Distance Sorting 允许按 geodistance 排序。 下面是一个例子，假设 pin.location 是一个类型为 geo_point 的字段： 1234567891011121314151617GET /_search{ &quot;sort&quot; : [ { &quot;_geo_distance&quot; : { &quot;pin.location&quot; : [-70, 40], &quot;order&quot; : &quot;asc&quot;, &quot;unit&quot; : &quot;km&quot;, &quot;mode&quot; : &quot;min&quot;, &quot;distance_type&quot; : &quot;sloppy_arc&quot; } } ], &quot;query&quot; : { &quot;term&quot; : { &quot;user&quot; : &quot;kimchy&quot; } }} distance_type 如何计算距离。 可以是 sloppy_arc（默认），弧（稍微更精确但显着更慢）或平面（更快，但不准确在长距离和接近极点）。 mode 如果字段有多个地理点，该怎么办。 默认情况下，按升序排序时考虑最短距离，按降序排序时最长距离。 支持的值为 min，max，median 和 avg。 unit 计算排序值时使用的单位。 默认值为 m（米）。 geo distance sorting 不支持可配置的缺失值：当文档没有用于距离计算的字段的值时，距离将始终被视为等于 Infinity。 在提供坐标时支持以下格式： highlighting允许突出显示一个或多个字段的搜索结果。 实现使用 lucene 普通荧光笔，快速向量荧光笔（fvh）或 postings 荧光笔。 以下是一个搜索请求正文的示例： 1234567891011GET /_search{ &quot;query&quot; : { &quot;match&quot;: { &quot;user&quot;: &quot;kimchy&quot; } }, &quot;highlight&quot; : { &quot;fields&quot; : { &quot;content&quot; : {} } }} 在上述情况下，内容字段将为每个搜索命中突出显示（每个搜索命中内将有另一个元素，称为突出显示，其中包括突出显示的字段和突出显示的片段）。 Note： 为了执行突出显示，需要字段的实际内容。 如果有问题的字段被存储（在映射中存储设置为 true），它将被使用，否则，实际的 _source 将被加载，并且相关字段将从中提取。 _all 字段不能从 _source 中提取，因此它只能用于突出显示，如果它映射到将 store 设置为 true。 字段名称支持通配符符号。 例如，使用 comment_ * 将导致所有与表达式匹配的文本和关键字字段（以及 5.0 之前的字符串）被突出显示。 请注意，所有其他字段将不会突出显示。 如果您使用自定义映射器并要在字段上突出显示，则必须显式提供字段名称。 Plain highlighte(有多种类型选择、根据实际情况使用) 荧光笔的默认选择是普通类型，并使用Lucene荧光笔。 它试图在理解词重要性和短语查询中的任何词定位标准方面反映查询匹配逻辑。 warning： 如果你想突出很多文档中的大量字段与复杂的查询，这个荧光笔不会快。 在努力准确地反映查询逻辑，它创建一个微小的内存索引，并通过 Lucene 的查询执行计划程序重新运行原始查询条件，以获取当前文档的低级别匹配信息。 这对于每个字段和需要突出显示的每个文档重复。 如果这在您的系统中出现性能问题，请考虑使用替代荧光笔。 search typeQuery Then Fetch 参数值： query_then_fetch。 请求分两个阶段处理。 在第一阶段，查询被转发到所有涉及的分片。 每个分片执行搜索并生成对该分片本地的结果的排序列表。 每个分片只向协调节点返回足够的信息，以允许其合并并将分片级结果重新排序为全局排序的最大长度大小的结果集。 在第二阶段期间，协调节点仅从相关分片请求文档内容（以及高亮显示的片段，如果有的话）。 Note： 如果您未在请求中指定 search_type，那么这是默认设置。 Dfs, Query Then Fetch 参数值：dfs_query_then_fetch 与 “Query Then Fetch” 相同，除了初始分散阶段，其计算分布项频率用于更准确的计分。 scroll 游标(多数据深度分页问题解决)从滚动请求返回的结果反映了进行初始搜索请求时索引的状态，如时间快照。 对文档（索引，更新或删除）的后续更改只会影响以后的搜索请求。 为了使用滚动，初始搜索请求应该在查询字符串中指定滚动参数，它告诉 Elasticsearch 应保持“搜索上下文”活动的时间（见保持搜索上下文），例如 ?scroll=1m。 123456789POST /twitter/tweet/_search?scroll=1m{ \"size\": 100, \"query\": { \"match\" : { \"title\" : \"elasticsearch\" } }} 上述请求的结果包括一个 scrollid，它应该被传递给滚动 API，以便检索下一批结果。 12345POST ①/_search/scroll ②{ \"scroll\" : \"1m\", ③ \"scroll_id\" : \"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==\" ④} | ① | 可以使用GET或POST。 | | ② | 网址不应包含索引或类型名称 - 而是在原始搜索请求中指定的。 | | ③ | scroll 参数告诉 Elasticsearch 将搜索上下文打开另一个1m。 | | ④ | scroll_id参数 | size 参数允许您配置每批结果返回的最大命中数。 每次调用 scroll API 都会返回下一批结果，直到没有更多结果要返回，即 hits 数组为空。 explan启用每次匹配对其评分计算方式的说明。 1234567GET /_search{ \"explain\": true, \"query\" : { \"term\" : { \"user\" : \"kimchy\" } }} suggesters (共有四种方式) Completion Suggester Context Suggester Phrase Suggester Term suggester completion suggester完全（completion）suggester 提供自动完成/按需搜索功能。 这是一种导航功能，可在用户输入时引导用户查看相关结果，从而提高搜索精度。 它不是用于拼写校正或平均值功能，如术语或短语 suggesters 。 理想地，自动完成功能应当与用户键入的速度一样快，以提供与用户已经键入的内容相关的即时反馈。因此，完成 suggester 针对速度进行优化。 suggester 使用允许快速查找的数据结构，但是构建成本高并且存储在存储器中。 要使用此功能，请为此字段指定一个特殊映射，为快速完成的字段值编制索引。 123456789101112131415PUT music{ \"mappings\": { \"song\" : { \"properties\" : { \"suggest\" : { \"type\" : \"completion\" }, \"title\" : { \"type\": \"keyword\" } } } }} 映射支持以下参数： analyzer 使用索引分析器，默认为简单。 如果你想知道为什么我们没有选择标准分析器：我们尝试在这里很容易理解的行为，如果你索引字段内容在Drive-in，你不会得到任何建议， （第一个非停用词） search_analyzer 要使用的搜索分析器，默认为分析器的值。 preserve_separators 保留分隔符，默认为true。 如果禁用，你可以找到一个以Foo Fighters开头的字段，如果你推荐foof。 preserve_position_increments 启用位置增量，默认为true。 如果禁用和使用停用分析器，您可以得到一个字段从披头士开始，如果你 suggest b。 注意：你也可以通过索引两个输入，Beatles和披头士，不需要改变一个简单的分析器，如果你能够丰富你的数据。 max_input_length 限制单个输入的长度，默认为50个UTF-16代码点。 此限制仅在索引时使用，以减少每个输入字符串的字符总数，以防止大量输入膨胀底层数据结构。 大多数用例不会受默认值的影响，因为前缀完成很少超过前缀长度超过少数几个字符。 索引 您像任何其他字段一样索引 suggestion 。 suggestion 由输入和可选的权重属性组成。 输入是要由 suggestion 查询匹配的期望文本，并且权重确定如何对 suggestion 进行评分。 索引 suggestion 如下： 1234567PUT music/song/1?refresh{ &quot;suggest&quot; : { &quot;input&quot;: [ &quot;Nevermind&quot;, &quot;Nirvana&quot; ], &quot;weight&quot; : 34 }} 以下参数被支持： input 输入存储，这可以是字符串数组或只是一个字符串。 此字段是必填字段。 weight 正整数或包含正整数的字符串，用于定义权重并允许对 suggestions 进行排名。 此字段是可选的。 查询 suggest 像往常一样工作，除了您必须指定 suggest 类型为完成。 suggestions 接近实时，这意味着可以通过刷新显示新 suggestions ，并且一旦删除就不会显示文档。 此请求： 123456789POST music/_suggest?pretty{ &quot;song-suggest&quot; : { &quot;prefix&quot; : &quot;nir&quot;, &quot;completion&quot; : { &quot;field&quot; : &quot;suggest&quot; } }} 返回这个响应： 12345678910111213141516171819202122{ &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;song-suggest&quot; : [ { &quot;text&quot; : &quot;nir&quot;, &quot;offset&quot; : 0, &quot;length&quot; : 3, &quot;options&quot; : [ { &quot;text&quot; : &quot;Nirvana&quot;, &quot;_index&quot;: &quot;music&quot;, &quot;_type&quot;: &quot;song&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1.0, &quot;_source&quot;: { &quot;suggest&quot;: [&quot;Nevermind&quot;, &quot;Nirvana&quot;] } } ] } ]} 模糊查询 完成 suggester 还支持模糊查询 - 这意味着，您可以在搜索中输入错误，并仍然返回结果。 123456789101112POST music/_suggest?pretty{ &quot;song-suggest&quot; : { &quot;prefix&quot; : &quot;nor&quot;, &quot;completion&quot; : { &quot;field&quot; : &quot;suggest&quot;, &quot;fuzzy&quot; : { &quot;fuzziness&quot; : 2 } } }} 与查询前缀共享最长前缀的 suggestion 将得分更高。 模糊查询可以采用特定的模糊参数。 支持以下参数： | fuzziness | 模糊系数，默认为AUTO。 有关允许的设置，请参阅 “Fuzzinessedit”一节。 | | transpositions | 如果设置为true，则换位计数为一个更改而不是两个，默认为true | | min_length | 返回模糊 suggestions 前的输入的最小长度，默认值3 | | prefix_length | 输入的最小长度（未针对模糊替代项进行检查）默认为1 | | unicode_aware | 如果为true，则所有度量（如模糊编辑距离，置换和长度）都以Unicode代码点而不是字节为单位。 这比原始字节稍慢，因此默认情况下设置为false。 | 如果你想坚持使用默认值，但仍然使用模糊，你可以使用 fuzzy：{}或fuzzy：true。 Explan apiExplain API 计算查询和特定文档的分数说明。 这可以提供有用的反馈，无论文档是否匹配特定查询。 index 和 type 参数分别期望单个索引和单个类型。 用法完整查询示例： 123456GET /twitter/tweet/0/_explain{ &quot;query&quot; : { &quot;match&quot; : { &quot;message&quot; : &quot;elasticsearch&quot; } }} 这将产生以下结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748{ &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;0&quot;, &quot;matched&quot; : true, &quot;explanation&quot; : { &quot;value&quot; : 1.55077, &quot;description&quot; : &quot;sum of:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 1.55077, &quot;description&quot; : &quot;weight(message:elasticsearch in 0) [PerFieldSimilarity], result of:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 1.55077, &quot;description&quot; : &quot;score(doc=0,freq=1.0 = termFreq=1.0\\n), product of:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 1.3862944, &quot;description&quot; : &quot;idf(docFreq=1, docCount=5)&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 1.1186441, &quot;description&quot; : &quot;tfNorm, computed from:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 1.0, &quot;description&quot; : &quot;termFreq=1.0&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 1.2, &quot;description&quot; : &quot;parameter k1&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 0.75, &quot;description&quot; : &quot;parameter b&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 5.4, &quot;description&quot; : &quot;avgFieldLength&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 4.0, &quot;description&quot; : &quot;fieldLength&quot;, &quot;details&quot; : [ ] } ] } ] } ] }, { &quot;value&quot; : 0.0, &quot;description&quot; : &quot;match on required clause, product of:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 0.0, &quot;description&quot; : &quot;# clause&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 1.0, &quot;description&quot; : &quot;_type:tweet, product of:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 1.0, &quot;description&quot; : &quot;boost&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 1.0, &quot;description&quot; : &quot;queryNorm&quot;, &quot;details&quot; : [ ] } ] } ] } ] }} 还有一种更简单的通过 q 参数指定查询的方法。 然后解析指定的 q 参数值，就像使用 query_string 查询一样。 在api中的 q 参数的用法示例： 1GET /twitter/tweet/0/_explain?q=message:search 这将产生与先前请求相同的结果。 参考资料","link":"/2019/04/26/Elasticsearch常用工具api.html"},{"title":"restful api 设计以及幂等性相关设计","text":"摘要针对项目中部分使用restful-api接口，总结文档如下，没有规矩不成方圆。写代码亦是，设计restful-api接口亦是。 RESTful 的核心思想就是，客户端发出的数据操作指令都是”动词 + 宾语”的结构。比如，GET /articles这个命令，GET是动词，/articles是宾语。 动词通常就是五种 HTTP 方法，对应 CRUD 操作。 GET：读取（Read） POST：新建（Create） PUT：更新（Update） PATCH：更新（Update），通常是部分更新 DELETE：删除（Delete） 根据 HTTP 规范，动词一律大写 话不多说，先上代码，一份完整的restful-api示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445@RestController@RequestMapping(\"admin/biz-name/v1/user\") //@RequestMapping(\"api/biz-name/v1/city\")public class AdminUserController { @Autowired private UserService service; @GetMapping(\"{id}/county/list\") public List&lt;UserView&gt; getUsersByCategoryId(@PathVariable(\"id\") Integer id) { return service.getUsersByCategoryId(id); } @GetMapping(\"{id}\") public UserView userInfoById(@PathVariable(\"id\") Integer id) { return service.getUserInfoById(id); } @PostMapping public Object create(@RequestBody UserEntityForm form) { // 相关验证valid 设置默认值 service.valid(form); if (StringUtil.isEmpty(form.getCsEmail())) { form.setCsEmail(\"980099577@qq.com\"); } Integer id = service.ceate(form); return Collections.singletonMap(\"id\", id); } @PutMapping public Result update(@RequestBody UserEntityForm form) { // 相关验证 valid service.valid(form); service.update(form); return Result.SUCCEED; } @DeleteMapping(\"{id}\") public Result delete(@PathVariable(\"id\") Integer id) { // 相关验证 valid service.valid(form); service.delete(id); return Result.SUCCEED; }} 针对以上restful-api 代码需要注意一下几点：@RestController 注解此注解加在类的上面，返回的结果以json格式，标注此为RestController。不同于Controller注解。Controller非json格式返回。 @RequestMapping此注解标识api请求的路劲，可指定相应的请求方法，例如@RequestMapping(“admin/biz-name/v1/user”)：http://localhost:8080/admin/biz-name/v1/user 有如下定义参数： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146@Target({ElementType.METHOD, ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Mappingpublic @interface RequestMapping { /** * Assign a name to this mapping. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used on both levels, a combined name is derived by concatenation * with \"#\" as separator. * @see org.springframework.web.servlet.mvc.method.annotation.MvcUriComponentsBuilder * @see org.springframework.web.servlet.handler.HandlerMethodMappingNamingStrategy */ String name() default \"\"; /** * The primary mapping expressed by this annotation. * &lt;p&gt;In a Servlet environment this is an alias for {@link #path}. * For example {@code @RequestMapping(\"/foo\")} is equivalent to * {@code @RequestMapping(path=\"/foo\")}. * &lt;p&gt;In a Portlet environment this is the mapped portlet modes * (i.e. \"EDIT\", \"VIEW\", \"HELP\" or any custom modes). * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this primary mapping, narrowing it for a specific handler method. */ @AliasFor(\"path\") String[] value() default {}; /** * In a Servlet environment only: the path mapping URIs (e.g. \"/myPath.do\"). * Ant-style path patterns are also supported (e.g. \"/myPath/*.do\"). * At the method level, relative paths (e.g. \"edit.do\") are supported within * the primary mapping expressed at the type level. Path mapping URIs may * contain placeholders (e.g. \"/${connect}\") * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this primary mapping, narrowing it for a specific handler method. * @see org.springframework.web.bind.annotation.ValueConstants#DEFAULT_NONE * @since 4.2 */ @AliasFor(\"value\") String[] path() default {}; /** * The HTTP request methods to map to, narrowing the primary mapping: * GET, POST, HEAD, OPTIONS, PUT, PATCH, DELETE, TRACE. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this HTTP method restriction (i.e. the type-level restriction * gets checked before the handler method is even resolved). * &lt;p&gt;Supported for Servlet environments as well as Portlet 2.0 environments. */ RequestMethod[] method() default {}; /** * The parameters of the mapped request, narrowing the primary mapping. * &lt;p&gt;Same format for any environment: a sequence of \"myParam=myValue\" style * expressions, with a request only mapped if each such parameter is found * to have the given value. Expressions can be negated by using the \"!=\" operator, * as in \"myParam!=myValue\". \"myParam\" style expressions are also supported, * with such parameters having to be present in the request (allowed to have * any value). Finally, \"!myParam\" style expressions indicate that the * specified parameter is &lt;i&gt;not&lt;/i&gt; supposed to be present in the request. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this parameter restriction (i.e. the type-level restriction * gets checked before the handler method is even resolved). * &lt;p&gt;In a Servlet environment, parameter mappings are considered as restrictions * that are enforced at the type level. The primary path mapping (i.e. the * specified URI value) still has to uniquely identify the target handler, with * parameter mappings simply expressing preconditions for invoking the handler. * &lt;p&gt;In a Portlet environment, parameters are taken into account as mapping * differentiators, i.e. the primary portlet mode mapping plus the parameter * conditions uniquely identify the target handler. Different handlers may be * mapped onto the same portlet mode, as long as their parameter mappings differ. */ String[] params() default {}; /** * The headers of the mapped request, narrowing the primary mapping. * &lt;p&gt;Same format for any environment: a sequence of \"My-Header=myValue\" style * expressions, with a request only mapped if each such header is found * to have the given value. Expressions can be negated by using the \"!=\" operator, * as in \"My-Header!=myValue\". \"My-Header\" style expressions are also supported, * with such headers having to be present in the request (allowed to have * any value). Finally, \"!My-Header\" style expressions indicate that the * specified header is &lt;i&gt;not&lt;/i&gt; supposed to be present in the request. * &lt;p&gt;Also supports media type wildcards (*), for headers such as Accept * and Content-Type. For instance, * &lt;pre class=\"code\"&gt; * &amp;#064;RequestMapping(value = \"/something\", headers = \"content-type=text/*\") * &lt;/pre&gt; * will match requests with a Content-Type of \"text/html\", \"text/plain\", etc. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this header restriction (i.e. the type-level restriction * gets checked before the handler method is even resolved). * &lt;p&gt;Maps against HttpServletRequest headers in a Servlet environment, * and against PortletRequest properties in a Portlet 2.0 environment. * @see org.springframework.http.MediaType */ String[] headers() default {}; /** * The consumable media types of the mapped request, narrowing the primary mapping. * &lt;p&gt;The format is a single media type or a sequence of media types, * with a request only mapped if the {@code Content-Type} matches one of these media types. * Examples: * &lt;pre class=\"code\"&gt; * consumes = \"text/plain\" * consumes = {\"text/plain\", \"application/*\"} * &lt;/pre&gt; * Expressions can be negated by using the \"!\" operator, as in \"!text/plain\", which matches * all requests with a {@code Content-Type} other than \"text/plain\". * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings override * this consumes restriction. * @see org.springframework.http.MediaType * @see javax.servlet.http.HttpServletRequest#getContentType() */ String[] consumes() default {}; /** * The producible media types of the mapped request, narrowing the primary mapping. * &lt;p&gt;The format is a single media type or a sequence of media types, * with a request only mapped if the {@code Accept} matches one of these media types. * Examples: * &lt;pre class=\"code\"&gt; * produces = \"text/plain\" * produces = {\"text/plain\", \"application/*\"} * produces = \"application/json; charset=UTF-8\" * &lt;/pre&gt; * &lt;p&gt;It affects the actual content type written, for example to produce a JSON response * with UTF-8 encoding, {@code \"application/json; charset=UTF-8\"} should be used. * &lt;p&gt;Expressions can be negated by using the \"!\" operator, as in \"!text/plain\", which matches * all requests with a {@code Accept} other than \"text/plain\". * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings override * this produces restriction. * @see org.springframework.http.MediaType */ String[] produces() default {};} @GetMapping此注解，接收前端为get请求的相关方法,接口返回天生具有幂等性，每次请求参数一致返回的结果也一致 此注解请求一般为获取相关信息的方法 有如下参数， 12345678910111213141516171819202122232425262728293031323334353637383940414243@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documented@RequestMapping(method = RequestMethod.GET)public @interface GetMapping { /** * Alias for {@link RequestMapping#name}. */ @AliasFor(annotation = RequestMapping.class) String name() default \"\"; /** * Alias for {@link RequestMapping#value}. */ @AliasFor(annotation = RequestMapping.class) String[] value() default {}; /** * Alias for {@link RequestMapping#path}. */ @AliasFor(annotation = RequestMapping.class) String[] path() default {}; /** * Alias for {@link RequestMapping#params}. */ @AliasFor(annotation = RequestMapping.class) String[] params() default {}; /** * Alias for {@link RequestMapping#headers}. */ @AliasFor(annotation = RequestMapping.class) String[] headers() default {}; /** * Alias for {@link RequestMapping#produces}. */ @AliasFor(annotation = RequestMapping.class) String[] produces() default {};} @PostMapping此注解，接收前端为post请求的相关方法 一般为保存，创建信息的方法，save…,create… @putMapping此注解，接收前端为put请求的相关方法 一般为更新数据的接口方法，update… @deleteMapping此注解，接收前端为delete请求的相关方法 一般为删除数据的方法 @RequestBody此注解放入接口方法的参数前面，对应请求中的body里的内容，要求body内容为json格式 例如： 1public Object create(@RequestBody UserEntityForm form) {}; @PathVariable此注解放入接口方法的参数前面，要求里面的值出现在Mapping中，以{}包裹，如下 接受参数required，设置判断此字段是否必须 12@GetMapping(\"{id}\")public UserView userInfoById(@PathVariable(\"id\",required = true) Integer id) {} @RequestParam此注解放入接口方法的参数前面，前端放入请求参数中，非body里面 接受参数required，设置判断此字段是否必须 defaultValue 设置此字段的默认值 1public UserView userInfoById(@RequestParam(value = \"id\", required = false, defaultValue = \"1\") Integer id）{} 所有的接口方法都应该设计为幂等性，即接口请求多次或一次都应该达到同样的效果。此特性在高并发下面非常适用。 高并发的核心技术 - 幂等的实现方案一、背景我们实际系统中有很多操作，是不管做多少次，都应该产生一样的效果或返回一样的结果。 例如： 前端重复提交选中的数据，应该后台只产生对应这个数据的一个反应结果。 2. 我们发起一笔付款请求，应该只扣用户账户一次钱，当遇到网络重发或系统bug重发，也应该只扣一次钱； 3. 发送消息，也应该只发一次，同样的短信发给用户，用户会哭的； 4. 创建业务订单，一次业务请求只能创建一个，创建多个就会出大问题。 等等很多重要的情况，这些逻辑都需要幂等的特性来支持。 二、幂等性概念幂等（idempotent、idempotence）是一个数学与计算机学概念，常见于抽象代数中。 在编程中.一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“getUsername()和setTrue()”函数就是一个幂等函数. 更复杂的操作幂等保证是利用唯一交易号(流水号)实现. 我的理解：幂等就是一个操作，不论执行多少次，产生的效果和返回的结果都是一样的 三、技术方案 查询操作 查询一次和查询多次，在数据不变的情况下，查询结果是一样的。select是天然的幂等操作 删除操作 删除操作也是幂等的，删除一次和多次删除都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0，删除的数据多条，返回结果多个) 3.唯一索引，防止新增脏数据 比如：支付宝的资金账户，支付宝也有用户账户，每个用户只能有一个资金账户，怎么防止给用户创建资金账户多个，那么给资金账户表中的用户ID加唯一索引，所以一个用户新增成功一个资金账户记录 要点： 唯一索引或唯一组合索引来防止新增数据存在脏数据 （当表存在唯一索引，并发时新增报错时，再查询一次就可以了，数据应该已经存在了，返回结果即可） token机制，防止页面重复提交 业务要求： 页面的数据只能被点击提交一次 发生原因： 由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交 解决办法： 集群环境：采用token加redis（redis单线程的，处理需要排队） 单JVM环境：采用token加redis或token加jvm内存 处理流程： 1. 数据提交前要向服务的申请token，token放到redis或jvm内存，token有效时间 2. 提交后后台校验token，同时删除token，生成新的token返回 token特点： 要申请，一次有效性，可以限流 注意：redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用 悲观锁 获取数据的时候加锁获取 select * from table_xxx where id=’xxx’ for update; 注意：id字段一定是主键或者唯一索引，不然是锁表，会死人的 悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用 乐观锁 乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。 乐观锁的实现方式多种多样可以通过version或者其他状态条件： 1. 通过版本号实现 update table_xxx set name=#name#,version=version+1 where version=#version# 如下图(来自网上)： 通过条件限制 update tablexxx set avaiamount=avaiamount-#subAmount# where avaiamount-#subAmount# &gt;= 0 要求：quality-#subQuality# &gt;= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高 注意：乐观锁的更新操作，最好用主键或者唯一索引来更新,这样是行锁，否则更新时会锁表，上面两个sql改成下面的两个更好 update tablexxx set name=#name#,version=version+1 where id=#id# and version=#version# update tablexxx set avaiamount=avaiamount-#subAmount# where id=#id# and avai_amount-#subAmount# &gt;= 0 分布式锁 还是拿插入数据的例子，如果是分布是系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多多个系统，也就是分布式系统中得解决思路。 要点：某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志(用户ID+后缀等)获取分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁(分布式锁要第三方系统提供) select + insert 并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，在进行业务处理，就可以了 注意：核心高并发流程不要用这种方法 状态机幂等 在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机(状态变更图)，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。 注意：订单等单据类业务，存在很长的状态流转，一定要深刻理解状态机，对业务系统设计能力提高有很大帮助 对外提供接口的api如何保证幂等 如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号 source+seq在数据库里面做唯一索引，防止多次付款，(并发时，只能处理一个请求) 重点对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。 总结幂等性应该是合格程序员的一个基因，在设计系统时，是首要考虑的问题，尤其是在像支付宝，银行，互联网金融公司等涉及的都是钱的系统，既要高效，数据也要准确，所以不能出现多扣款，多打款等问题，这样会很难处理，用户体验也不好 参考自","link":"/2019/04/18/restful-api-设计以及幂等性相关设计.html"},{"title":"一千行 MySQL 学习笔记(转载)","text":"摘要以下为本人初学 MySQL 时做的笔记，也从那时起没再更新过，但还是囊括了基本的知识点，有时还翻出来查查。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044/* Windows服务 */-- 启动MySQL net start mysql-- 创建Windows服务 sc create mysql binPath= mysqld_bin_path(注意：等号与值之间有空格)/* 连接与断开服务器 */mysql -h 地址 -P 端口 -u 用户名 -p 密码SHOW PROCESSLIST -- 显示哪些线程正在运行SHOW VARIABLES -- 显示系统变量信息/* 数据库操作 */ -------------------- 查看当前数据库 SELECT DATABASE();-- 显示当前时间、用户名、数据库版本 SELECT now(), user(), version();-- 创建库 CREATE DATABASE[ IF NOT EXISTS] 数据库名 数据库选项 数据库选项： CHARACTER SET charset_name COLLATE collation_name-- 查看已有库 SHOW DATABASES[ LIKE 'PATTERN']-- 查看当前库信息 SHOW CREATE DATABASE 数据库名-- 修改库的选项信息 ALTER DATABASE 库名 选项信息-- 删除库 DROP DATABASE[ IF EXISTS] 数据库名 同时删除该数据库相关的目录及其目录内容/* 表的操作 */ -------------------- 创建表 CREATE [TEMPORARY] TABLE[ IF NOT EXISTS] [库名.]表名 ( 表的结构定义 )[ 表选项] 每个字段必须有数据类型 最后一个字段后不能有逗号 TEMPORARY 临时表，会话结束时表自动消失 对于字段的定义： 字段名 数据类型 [NOT NULL | NULL] [DEFAULT default_value] [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT 'string']-- 表选项 -- 字符集 CHARSET = charset_name 如果表没有设定，则使用数据库字符集 -- 存储引擎 ENGINE = engine_name 表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性操作等不同 常见的引擎：InnoDB MyISAM Memory/Heap BDB Merge Example CSV MaxDB Archive 不同的引擎在保存表的结构和数据时采用不同的方式 MyISAM表文件含义：.frm表定义，.MYD表数据，.MYI表索引 InnoDB表文件含义：.frm表定义，表空间数据和日志文件 SHOW ENGINES -- 显示存储引擎的状态信息 SHOW ENGINE 引擎名 {LOGS|STATUS} -- 显示存储引擎的日志或状态信息 -- 自增起始数 AUTO_INCREMENT = 行数 -- 数据文件目录 DATA DIRECTORY = '目录' -- 索引文件目录 INDEX DIRECTORY = '目录' -- 表注释 COMMENT = 'string' -- 分区选项 PARTITION BY ... (详细见手册)-- 查看所有表 SHOW TABLES[ LIKE 'pattern'] SHOW TABLES FROM 表名-- 查看表机构 SHOW CREATE TABLE 表名 （信息更详细） DESC 表名 / DESCRIBE 表名 / EXPLAIN 表名 / SHOW COLUMNS FROM 表名 [LIKE 'PATTERN'] SHOW TABLE STATUS [FROM db_name] [LIKE 'pattern']-- 修改表 -- 修改表本身的选项 ALTER TABLE 表名 表的选项 eg: ALTER TABLE 表名 ENGINE=MYISAM; -- 对表进行重命名 RENAME TABLE 原表名 TO 新表名 RENAME TABLE 原表名 TO 库名.表名 （可将表移动到另一个数据库） -- RENAME可以交换两个表名 -- 修改表的字段机构（13.1.2. ALTER TABLE语法） ALTER TABLE 表名 操作名 -- 操作名 ADD[ COLUMN] 字段定义 -- 增加字段 AFTER 字段名 -- 表示增加在该字段名后面 FIRST -- 表示增加在第一个 ADD PRIMARY KEY(字段名) -- 创建主键 ADD UNIQUE [索引名] (字段名)-- 创建唯一索引 ADD INDEX [索引名] (字段名) -- 创建普通索引 DROP[ COLUMN] 字段名 -- 删除字段 MODIFY[ COLUMN] 字段名 字段属性 -- 支持对字段属性进行修改，不能修改字段名(所有原有属性也需写上) CHANGE[ COLUMN] 原字段名 新字段名 字段属性 -- 支持对字段名修改 DROP PRIMARY KEY -- 删除主键(删除主键前需删除其AUTO_INCREMENT属性) DROP INDEX 索引名 -- 删除索引 DROP FOREIGN KEY 外键 -- 删除外键-- 删除表 DROP TABLE[ IF EXISTS] 表名 ...-- 清空表数据 TRUNCATE [TABLE] 表名-- 复制表结构 CREATE TABLE 表名 LIKE 要复制的表名-- 复制表结构和数据 CREATE TABLE 表名 [AS] SELECT * FROM 要复制的表名-- 检查表是否有错误 CHECK TABLE tbl_name [, tbl_name] ... [option] ...-- 优化表 OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...-- 修复表 REPAIR [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... [QUICK] [EXTENDED] [USE_FRM]-- 分析表 ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] .../* 数据操作 */ -------------------- 增 INSERT [INTO] 表名 [(字段列表)] VALUES (值列表)[, (值列表), ...] -- 如果要插入的值列表包含所有字段并且顺序一致，则可以省略字段列表。 -- 可同时插入多条数据记录！ REPLACE 与 INSERT 完全一样，可互换。 INSERT [INTO] 表名 SET 字段名=值[, 字段名=值, ...]-- 查 SELECT 字段列表 FROM 表名[ 其他子句] -- 可来自多个表的多个字段 -- 其他子句可以不使用 -- 字段列表可以用*代替，表示所有字段-- 删 DELETE FROM 表名[ 删除条件子句] 没有条件子句，则会删除全部-- 改 UPDATE 表名 SET 字段名=新值[, 字段名=新值] [更新条件]/* 字符集编码 */ -------------------- MySQL、数据库、表、字段均可设置编码-- 数据编码与客户端编码不需一致SHOW VARIABLES LIKE 'character_set_%' -- 查看所有字符集编码项 character_set_client 客户端向服务器发送数据时使用的编码 character_set_results 服务器端将结果返回给客户端所使用的编码 character_set_connection 连接层编码SET 变量名 = 变量值 SET character_set_client = gbk; SET character_set_results = gbk; SET character_set_connection = gbk;SET NAMES GBK; -- 相当于完成以上三个设置-- 校对集 校对集用以排序 SHOW CHARACTER SET [LIKE 'pattern']/SHOW CHARSET [LIKE 'pattern'] 查看所有字符集 SHOW COLLATION [LIKE 'pattern'] 查看所有校对集 CHARSET 字符集编码 设置字符集编码 COLLATE 校对集编码 设置校对集编码/* 数据类型（列类型） */ ------------------1. 数值类型-- a. 整型 ---------- 类型 字节 范围（有符号位） tinyint 1字节 -128 ~ 127 无符号位：0 ~ 255 smallint 2字节 -32768 ~ 32767 mediumint 3字节 -8388608 ~ 8388607 int 4字节 bigint 8字节 int(M) M表示总位数 - 默认存在符号位，unsigned 属性修改 - 显示宽度，如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改 例：int(5) 插入一个数'123'，补填后为'00123' - 在满足要求的情况下，越小越好。 - 1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型。-- b. 浮点型 ---------- 类型 字节 范围 float(单精度) 4字节 double(双精度) 8字节 浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性。 不同于整型，前后均会补填0. 定义浮点型时，需指定总位数和小数位数。 float(M, D) double(M, D) M表示总位数，D表示小数位数。 M和D的大小会决定浮点数的范围。不同于整型的固定范围。 M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）。 支持科学计数法表示。 浮点数表示近似值。-- c. 定点数 ---------- decimal -- 可变长度 decimal(M, D) M也表示总位数，D表示小数位数。 保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入。 将浮点数转换为字符串来保存，每9位数字保存为4个字节。2. 字符串类型-- a. char, varchar ---------- char 定长字符串，速度快，但浪费空间 varchar 变长字符串，速度慢，但节省空间 M表示能存储的最大长度，此长度是字符数，非字节数。 不同的编码，所占用的空间不同。 char,最多255个字符，与编码无关。 varchar,最多65535字符，与编码有关。 一条有效记录最大不能超过65535个字节。 utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符 varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。 varchar 的最大有效长度由最大行大小和使用的字符集确定。 最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是64432-1-2=65532字节。 例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？ 答：(65535-1-2-4-30*3)/3-- b. blob, text ---------- blob 二进制字符串（字节字符串） tinyblob, blob, mediumblob, longblob text 非二进制字符串（字符字符串） tinytext, text, mediumtext, longtext text 在定义时，不需要定义长度，也不会计算总长度。 text 类型在定义时，不可给default值-- c. binary, varbinary ---------- 类似于char和varchar，用于保存二进制字符串，也就是保存字节字符串而非字符字符串。 char, varchar, text 对应 binary, varbinary, blob.3. 日期时间类型 一般用整型保存时间戳，因为PHP可以很方便的将时间戳进行格式化。 datetime 8字节 日期及时间 1000-01-01 00:00:00 到 9999-12-31 23:59:59 date 3字节 日期 1000-01-01 到 9999-12-31 timestamp 4字节 时间戳 19700101000000 到 2038-01-19 03:14:07 time 3字节 时间 -838:59:59 到 838:59:59 year 1字节 年份 1901 - 2155datetime YYYY-MM-DD hh:mm:sstimestamp YY-MM-DD hh:mm:ss YYYYMMDDhhmmss YYMMDDhhmmss YYYYMMDDhhmmss YYMMDDhhmmssdate YYYY-MM-DD YY-MM-DD YYYYMMDD YYMMDD YYYYMMDD YYMMDDtime hh:mm:ss hhmmss hhmmssyear YYYY YY YYYY YY4. 枚举和集合-- 枚举(enum) ----------enum(val1, val2, val3...) 在已知的值中进行单选。最大数量为65535. 枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。 表现为字符串类型，存储却是整型。 NULL值的索引是NULL。 空字符串错误值的索引值是0。-- 集合（set） ----------set(val1, val2, val3...) create table tab ( gender set('男', '女', '无') ); insert into tab values ('男, 女'); 最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式。 当创建表时，SET成员值的尾部空格将自动被删除。/* 选择类型 */-- PHP角度1. 功能满足2. 存储空间尽量小，处理效率更高3. 考虑兼容问题-- IP存储 ----------1. 只需存储，可用字符串2. 如果需计算，查找等，可存储为4个字节的无符号int，即unsigned 1) PHP函数转换 ip2long可转换为整型，但会出现携带符号问题。需格式化为无符号的整型。 利用sprintf函数格式化字符串 sprintf(\"%u\", ip2long('192.168.3.134')); 然后用long2ip将整型转回IP字符串 2) MySQL函数转换(无符号整型，UNSIGNED) INET_ATON('127.0.0.1') 将IP转为整型 INET_NTOA(2130706433) 将整型转为IP/* 列属性（列约束） */ ------------------1. PRIMARY 主键 - 能唯一标识记录的字段，可以作为主键。 - 一个表只能有一个主键。 - 主键具有唯一性。 - 声明字段时，用 primary key 标识。 也可以在字段列表之后声明 例：create table tab ( id int, stu varchar(10), primary key (id)); - 主键字段的值不能为null。 - 主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。 例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age));2. UNIQUE 唯一索引（唯一约束） 使得某字段的值也不能重复。3. NULL 约束 null不是数据类型，是列的一个属性。 表示当前列是否可以为null，表示什么都没有。 null, 允许为空。默认。 not null, 不允许为空。 insert into tab values (null, 'val'); -- 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null4. DEFAULT 默认值属性 当前字段的默认值。 insert into tab values (default, 'val'); -- 此时表示强制使用默认值。 create table tab ( add_time timestamp default current_timestamp ); -- 表示将当前时间的时间戳设为默认值。 current_date, current_time5. AUTO_INCREMENT 自动增长约束 自动增长必须为索引（主键或unique） 只能存在一个字段为自动增长。 默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x;6. COMMENT 注释 例：create table tab ( id int ) comment '注释内容';7. FOREIGN KEY 外键约束 用于限制主表与从表数据完整性。 alter table t1 add constraint `t1_t2_fk` foreign key (t1_id) references t2(id); -- 将表t1的t1_id外键关联到表t2的id字段。 -- 每个外键都有一个名字，可以通过 constraint 指定 存在外键的表，称之为从表（子表），外键指向的表，称之为主表（父表）。 作用：保持数据一致性，完整性，主要目的是控制存储在外键表（从表）中的数据。 MySQL中，可以对InnoDB引擎使用外键约束： 语法： foreign key (外键字段） references 主表名 (关联字段) [主表记录删除时的动作] [主表记录更新时的动作] 此时需要检测一个从表的外键需要约束为主表的已存在的值。外键在没有关联的情况下，可以设置为null.前提是该外键列，没有not null。 可以不指定主表记录更改或更新时的动作，那么此时主表的操作被拒绝。 如果指定了 on update 或 on delete：在删除或更新时，有如下几个操作可以选择： 1. cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值更新）。主表记录被删除，从表相关记录也被删除。 2. set null，设置为null。主表数据被更新（主键值更新），从表的外键被设置为null。主表记录被删除，从表相关记录外键被设置成null。但注意，要求该外键列，没有not null属性约束。 3. restrict，拒绝父表删除和更新。 注意，外键只被InnoDB存储引擎所支持。其他引擎是不支持的。/* 建表规范 */ ------------------ -- Normal Format, NF - 每个表保存一个实体信息 - 每个具有一个ID字段作为主键 - ID主键 + 原子表 -- 1NF, 第一范式 字段不能再分，就满足第一范式。 -- 2NF, 第二范式 满足第一范式的前提下，不能出现部分依赖。 消除符合主键就可以避免部分依赖。增加单列关键字。 -- 3NF, 第三范式 满足第二范式的前提下，不能出现传递依赖。 某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。 将一个实体信息的数据放在一个表内实现。/* SELECT */ ------------------SELECT [ALL|DISTINCT] select_expr FROM -&gt; WHERE -&gt; GROUP BY [合计函数] -&gt; HAVING -&gt; ORDER BY -&gt; LIMITa. select_expr -- 可以用 * 表示所有字段。 select * from tb; -- 可以使用表达式（计算公式、函数调用、字段也是个表达式） select stu, 29+25, now() from tb; -- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。 - 使用 as 关键字，也可省略 as. select stu+10 as add10 from tb;b. FROM 子句 用于标识查询来源。 -- 可以为表起别名。使用as关键字。 SELECT * FROM tb1 AS tt, tb2 AS bb; -- from子句后，可以同时出现多个表。 -- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。 SELECT * FROM tb1, tb2; -- 向优化符提示如何选择索引 USE INDEX、IGNORE INDEX、FORCE INDEX SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 AND key3=3; SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 AND key3=3;c. WHERE 子句 -- 从from获得的数据源中进行筛选。 -- 整型1表示真，0表示假。 -- 表达式由运算符和运算数组成。 -- 运算数：变量（字段）、值、函数返回值 -- 运算符： =, &lt;=&gt;, &lt;&gt;, !=, &lt;=, &lt;, &gt;=, &gt;, !, &amp;&amp;, ||, in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor is/is not 加上ture/false/unknown，检验某个值的真假 &lt;=&gt;与&lt;&gt;功能相同，&lt;=&gt;可用于null比较d. GROUP BY 子句, 分组子句 GROUP BY 字段/别名 [排序方式] 分组后会进行排序。升序：ASC，降序：DESC 以下[合计函数]需配合 GROUP BY 使用： count 返回不同的非NULL值数目 count(*)、count(字段) sum 求和 max 求最大值 min 求最小值 avg 求平均值 group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。e. HAVING 子句，条件子句 与 where 功能、用法相同，执行时机不同。 where 在开始时执行检测数据，对原数据进行过滤。 having 对筛选出的结果再次进行过滤。 having 字段必须是查询出来的，where 字段必须是数据表存在的。 where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。 where 不可以使用合计函数。一般需用合计函数才会用 having SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。f. ORDER BY 子句，排序子句 order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]... 升序：ASC，降序：DESC 支持多个字段的排序。g. LIMIT 子句，限制结果数量子句 仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。 limit 起始位置, 获取条数 省略第一个参数，表示从索引0开始。limit 获取条数h. DISTINCT, ALL 选项 distinct 去除重复记录 默认为 all, 全部记录/* UNION */ ------------------ 将多个select查询的结果组合成一个结果集合。 SELECT ... UNION [ALL|DISTINCT] SELECT ... 默认 DISTINCT 方式，即所有返回的行都是唯一的 建议，对每个SELECT查询加上小括号包裹。 ORDER BY 排序时，需加上 LIMIT 进行结合。 需要各select查询的字段数量一样。 每个select查询的字段列表(数量、类型)应一致，因为结果中的字段名以第一条select语句为准。/* 子查询 */ ------------------ - 子查询需用括号包裹。-- from型 from后要求是一个表，必须给子查询结果取个别名。 - 简化每个查询内的条件。 - from型需将结果生成一个临时表格，可用以原表的锁定的释放。 - 子查询返回一个表，表型子查询。 select * from (select * from tb where id&gt;0) as subfrom where id&gt;1;-- where型 - 子查询返回一个值，标量子查询。 - 不需要给子查询取别名。 - where子查询内的表，不能直接用以更新。 select * from tb where money = (select max(money) from tb); -- 列子查询 如果子查询结果返回的是一列。 使用 in 或 not in 完成查询 exists 和 not exists 条件 如果子查询返回数据，则返回1或0。常用于判断条件。 select column1 from t1 where exists (select * from t2); -- 行子查询 查询条件是一个行。 select * from t1 where (id, gender) in (select id, gender from t2); 行构造符：(col1, col2, ...) 或 ROW(col1, col2, ...) 行构造符通常用于与对能返回两个或两个以上列的子查询进行比较。 -- 特殊运算符 != all() 相当于 not in = some() 相当于 in。any 是 some 的别名 != some() 不等同于 not in，不等于其中某一个。 all, some 可以配合其他运算符一起使用。/* 连接查询(join) */ ------------------ 将多个表的字段进行连接，可以指定连接条件。-- 内连接(inner join) - 默认就是内连接，可省略inner。 - 只有数据存在时才能发送连接。即连接结果不能出现空行。 on 表示连接条件。其条件表达式与where类似。也可以省略条件（表示条件永远为真） 也可用where表示连接条件。 还有 using, 但需字段名相同。 using(字段名) -- 交叉连接 cross join 即，没有条件的内连接。 select * from tb1 cross join tb2;-- 外连接(outer join) - 如果数据不存在，也会出现在连接结果中。 -- 左外连接 left join 如果数据不存在，左表记录会出现，而右表为null填充 -- 右外连接 right join 如果数据不存在，右表记录会出现，而左表为null填充-- 自然连接(natural join) 自动判断连接条件完成连接。 相当于省略了using，会自动查找相同字段名。 natural join natural left join natural right joinselect info.id, info.name, info.stu_num, extra_info.hobby, extra_info.sex from info, extra_info where info.stu_num = extra_info.stu_id;/* 导入导出 */ ------------------select * into outfile 文件地址 [控制格式] from 表名; -- 导出表数据load data [local] infile 文件地址 [replace|ignore] into table 表名 [控制格式]; -- 导入数据 生成的数据默认的分隔符是制表符 local未指定，则数据文件必须在服务器上 replace 和 ignore 关键词控制对现有的唯一键记录的重复的处理-- 控制格式fields 控制字段格式默认：fields terminated by '\\t' enclosed by '' escaped by '\\\\' terminated by 'string' -- 终止 enclosed by 'char' -- 包裹 escaped by 'char' -- 转义 -- 示例： SELECT a,b,a+b INTO OUTFILE '/tmp/result.text' FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\"' LINES TERMINATED BY '\\n' FROM test_table;lines 控制行格式默认：lines terminated by '\\n' terminated by 'string' -- 终止/* INSERT */ ------------------select语句获得的数据可以用insert插入。可以省略对列的指定，要求 values () 括号内，提供给了按照列顺序出现的所有字段的值。 或者使用set语法。 INSERT INTO tbl_name SET field=value,...；可以一次性使用多个值，采用(), (), ();的形式。 INSERT INTO tbl_name VALUES (), (), ();可以在列值指定时，使用表达式。 INSERT INTO tbl_name VALUES (field_value, 10+10, now());可以使用一个特殊值 DEFAULT，表示该列使用默认值。 INSERT INTO tbl_name VALUES (field_value, DEFAULT);可以通过一个查询的结果，作为需要插入的值。 INSERT INTO tbl_name SELECT ...;可以指定在插入的值出现主键（或唯一索引）冲突时，更新其他非主键列的信息。 INSERT INTO tbl_name VALUES/SET/SELECT ON DUPLICATE KEY UPDATE 字段=值, …;/* DELETE */ ------------------DELETE FROM tbl_name [WHERE where_definition] [ORDER BY ...] [LIMIT row_count]按照条件删除。where指定删除的最多记录数。limit可以通过排序条件删除。order by + limit支持多表删除，使用类似连接语法。delete from 需要删除数据多表1，表2 using 表连接操作 条件。/* TRUNCATE */ ------------------TRUNCATE [TABLE] tbl_name清空数据删除重建表区别：1，truncate 是删除表再创建，delete 是逐条删除2，truncate 重置auto_increment的值。而delete不会3，truncate 不知道删除了几条，而delete知道。4，当被用于带分区的表时，truncate 会保留分区/* 备份与还原 */ ------------------备份，将数据的结构与表内数据保存起来。利用 mysqldump 指令完成。-- 导出mysqldump [options] db_name [tables]mysqldump [options] ---database DB1 [DB2 DB3...]mysqldump [options] --all--database1. 导出一张表 mysqldump -u用户名 -p密码 库名 表名 &gt; 文件名(D:/a.sql)2. 导出多张表 mysqldump -u用户名 -p密码 库名 表1 表2 表3 &gt; 文件名(D:/a.sql)3. 导出所有表 mysqldump -u用户名 -p密码 库名 &gt; 文件名(D:/a.sql)4. 导出一个库 mysqldump -u用户名 -p密码 --lock-all-tables --database 库名 &gt; 文件名(D:/a.sql)可以-w携带WHERE条件-- 导入1. 在登录mysql的情况下： source 备份文件2. 在不登录的情况下 mysql -u用户名 -p密码 库名 &lt; 备份文件/* 视图 */ ------------------什么是视图： 视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。 视图具有表结构文件，但不存在数据文件。 对其中所引用的基础表来说，视图的作用类似于筛选。定义视图的筛选可以来自当前或其它数据库的一个或多个表，或者其它视图。通过视图进行查询没有任何限制，通过它们进行数据修改时的限制也很少。 视图是存储在数据库中的查询的sql语句，它主要出于两种原因：安全原因，视图可以隐藏一些数据，如：社会保险基金表，可以用视图只显示姓名，地址，而不显示社会保险号和工资数等，另一原因是可使复杂的查询易于理解和使用。-- 创建视图CREATE [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement - 视图名必须唯一，同时不能与表重名。 - 视图可以使用select语句查询到的列名，也可以自己指定相应的列名。 - 可以指定视图执行的算法，通过ALGORITHM指定。 - column_list如果存在，则数目必须等于SELECT语句检索的列数-- 查看结构 SHOW CREATE VIEW view_name-- 删除视图 - 删除视图后，数据依然存在。 - 可同时删除多个视图。 DROP VIEW [IF EXISTS] view_name ...-- 修改视图结构 - 一般不修改视图，因为不是所有的更新视图都会映射到表上。 ALTER VIEW view_name [(column_list)] AS select_statement-- 视图作用 1. 简化业务逻辑 2. 对客户端隐藏真实的表结构-- 视图算法(ALGORITHM) MERGE 合并 将视图的查询语句，与外部查询需要先合并再执行！ TEMPTABLE 临时表 将视图执行完毕后，形成临时表，再做外层查询！ UNDEFINED 未定义(默认)，指的是MySQL自主去选择相应的算法。/* 事务(transaction) */ ------------------事务是指逻辑上的一组操作，组成这组操作的各个单元，要不全成功要不全失败。 - 支持连续SQL的集体成功或集体撤销。 - 事务是数据库在数据晚自习方面的一个功能。 - 需要利用 InnoDB 或 BDB 存储引擎，对自动提交的特性支持完成。 - InnoDB被称为事务安全型引擎。-- 事务开启 START TRANSACTION; 或者 BEGIN; 开启事务后，所有被执行的SQL语句均被认作当前事务内的SQL语句。-- 事务提交 COMMIT;-- 事务回滚 ROLLBACK; 如果部分操作发生问题，映射到事务开启前。-- 事务的特性 1. 原子性（Atomicity） 事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 2. 一致性（Consistency） 事务前后数据的完整性必须保持一致。 - 事务开始和结束时，外部数据一致 - 在整个事务过程中，操作是连续的 3. 隔离性（Isolation） 多个用户并发访问数据库时，一个用户的事务不能被其它用户的事物所干扰，多个并发事务之间的数据要相互隔离。 4. 持久性（Durability） 一个事务一旦被提交，它对数据库中的数据改变就是永久性的。-- 事务的实现 1. 要求是事务支持的表类型 2. 执行一组相关的操作前开启事务 3. 整组操作完成后，都成功，则提交；如果存在失败，选择回滚，则会回到事务开始的备份点。-- 事务的原理 利用InnoDB的自动提交(autocommit)特性完成。 普通的MySQL执行语句后，当前的数据提交操作均可被其他客户端可见。 而事务是暂时关闭“自动提交”机制，需要commit提交持久化数据操作。-- 注意 1. 数据定义语言（DDL）语句不能被回滚，比如创建或取消数据库的语句，和创建、取消或更改表或存储的子程序的语句。 2. 事务不能被嵌套-- 保存点 SAVEPOINT 保存点名称 -- 设置一个事务保存点 ROLLBACK TO SAVEPOINT 保存点名称 -- 回滚到保存点 RELEASE SAVEPOINT 保存点名称 -- 删除保存点-- InnoDB自动提交特性设置 SET autocommit = 0|1; 0表示关闭自动提交，1表示开启自动提交。 - 如果关闭了，那普通操作的结果对其他客户端也不可见，需要commit提交后才能持久化数据操作。 - 也可以关闭自动提交来开启事务。但与START TRANSACTION不同的是， SET autocommit是永久改变服务器的设置，直到下次再次修改该设置。(针对当前连接) 而START TRANSACTION记录开启前的状态，而一旦事务提交或回滚后就需要再次开启事务。(针对当前事务)/* 锁表 */表锁定只用于防止其它客户端进行不正当地读取和写入MyISAM 支持表锁，InnoDB 支持行锁-- 锁定 LOCK TABLES tbl_name [AS alias]-- 解锁 UNLOCK TABLES/* 触发器 */ ------------------ 触发程序是与表有关的命名数据库对象，当该表出现特定事件时，将激活该对象 监听：记录的增加、修改、删除。-- 创建触发器CREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_stmt 参数： trigger_time是触发程序的动作时间。它可以是 before 或 after，以指明触发程序是在激活它的语句之前或之后触发。 trigger_event指明了激活触发程序的语句的类型 INSERT：将新行插入表时激活触发程序 UPDATE：更改某一行时激活触发程序 DELETE：从表中删除某一行时激活触发程序 tbl_name：监听的表，必须是永久性的表，不能将触发程序与TEMPORARY表或视图关联起来。 trigger_stmt：当触发程序激活时执行的语句。执行多个语句，可使用BEGIN...END复合语句结构-- 删除DROP TRIGGER [schema_name.]trigger_name可以使用old和new代替旧的和新的数据 更新操作，更新前是old，更新后是new. 删除操作，只有old. 增加操作，只有new.-- 注意 1. 对于具有相同触发程序动作时间和事件的给定表，不能有两个触发程序。-- 字符连接函数concat(str1,str2,...])concat_ws(separator,str1,str2,...)-- 分支语句if 条件 then 执行语句elseif 条件 then 执行语句else 执行语句end if;-- 修改最外层语句结束符delimiter 自定义结束符号 SQL语句自定义结束符号delimiter ; -- 修改回原来的分号-- 语句块包裹begin 语句块end-- 特殊的执行1. 只要添加记录，就会触发程序。2. Insert into on duplicate key update 语法会触发： 如果没有重复记录，会触发 before insert, after insert; 如果有重复记录并更新，会触发 before insert, before update, after update; 如果有重复记录但是没有发生更新，则触发 before insert, before update3. Replace 语法 如果有记录，则执行 before insert, before delete, after delete, after insert/* SQL编程 */ --------------------// 局部变量 ------------ 变量声明 declare var_name[,...] type [default value] 这个语句被用来声明局部变量。要给变量提供一个默认值，请包含一个default子句。值可以被指定为一个表达式，不需要为一个常数。如果没有default子句，初始值为null。-- 赋值 使用 set 和 select into 语句为变量赋值。 - 注意：在函数内是可以使用全局变量（用户自定义的变量）--// 全局变量 ------------ 定义、赋值set 语句可以定义并为变量赋值。set @var = value;也可以使用select into语句为变量初始化并赋值。这样要求select语句只能返回一行，但是可以是多个字段，就意味着同时为多个变量进行赋值，变量的数量需要与查询的列数一致。还可以把赋值语句看作一个表达式，通过select执行完成。此时为了避免=被当作关系运算符看待，使用:=代替。（set语句可以使用= 和 :=）。select @var:=20;select @v1:=id, @v2=name from t1 limit 1;select * from tbl_name where @var:=30;select into 可以将表中查询获得的数据赋给变量。 -| select max(height) into @max_height from tb;-- 自定义变量名为了避免select语句中，用户自定义的变量与系统标识符（通常是字段名）冲突，用户自定义变量在变量名前使用@作为开始符号。@var=10; - 变量被定义后，在整个会话周期都有效（登录到退出）--// 控制结构 ------------ if语句if search_condition then statement_list [elseif search_condition then statement_list]...[else statement_list]end if;-- case语句CASE value WHEN [compare-value] THEN result[WHEN [compare-value] THEN result ...][ELSE result]END-- while循环[begin_label:] while search_condition do statement_listend while [end_label];- 如果需要在循环内提前终止 while循环，则需要使用标签；标签需要成对出现。 -- 退出循环 退出整个循环 leave 退出当前循环 iterate 通过退出的标签决定退出哪个循环--// 内置函数 ------------ 数值函数abs(x) -- 绝对值 abs(-10.9) = 10format(x, d) -- 格式化千分位数值 format(1234567.456, 2) = 1,234,567.46ceil(x) -- 向上取整 ceil(10.1) = 11floor(x) -- 向下取整 floor (10.1) = 10round(x) -- 四舍五入去整mod(m, n) -- m%n m mod n 求余 10%3=1pi() -- 获得圆周率pow(m, n) -- m^nsqrt(x) -- 算术平方根rand() -- 随机数truncate(x, d) -- 截取d位小数-- 时间日期函数now(), current_timestamp(); -- 当前日期时间current_date(); -- 当前日期current_time(); -- 当前时间date('yyyy-mm-dd hh:ii:ss'); -- 获取日期部分time('yyyy-mm-dd hh:ii:ss'); -- 获取时间部分date_format('yyyy-mm-dd hh:ii:ss', '%d %y %a %d %m %b %j'); -- 格式化时间unix_timestamp(); -- 获得unix时间戳from_unixtime(); -- 从时间戳获得时间-- 字符串函数length(string) -- string长度，字节char_length(string) -- string的字符个数substring(str, position [,length]) -- 从str的position开始,取length个字符replace(str ,search_str ,replace_str) -- 在str中用replace_str替换search_strinstr(string ,substring) -- 返回substring首次在string中出现的位置concat(string [,...]) -- 连接字串charset(str) -- 返回字串字符集lcase(string) -- 转换成小写left(string, length) -- 从string2中的左边起取length个字符load_file(file_name) -- 从文件读取内容locate(substring, string [,start_position]) -- 同instr,但可指定开始位置lpad(string, length, pad) -- 重复用pad加在string开头,直到字串长度为lengthltrim(string) -- 去除前端空格repeat(string, count) -- 重复count次rpad(string, length, pad) --在str后用pad补充,直到长度为lengthrtrim(string) -- 去除后端空格strcmp(string1 ,string2) -- 逐字符比较两字串大小-- 流程函数case when [condition] then result [when [condition] then result ...] [else result] end 多分支if(expr1,expr2,expr3) 双分支。-- 聚合函数count()sum();max();min();avg();group_concat()-- 其他常用函数md5();default();--// 存储函数，自定义函数 ------------ 新建 CREATE FUNCTION function_name (参数列表) RETURNS 返回值类型 函数体 - 函数名，应该合法的标识符，并且不应该与已有的关键字冲突。 - 一个函数应该属于某个数据库，可以使用db_name.funciton_name的形式执行当前函数所属数据库，否则为当前数据库。 - 参数部分，由\"参数名\"和\"参数类型\"组成。多个参数用逗号隔开。 - 函数体由多条可用的mysql语句，流程控制，变量声明等语句构成。 - 多条语句应该使用 begin...end 语句块包含。 - 一定要有 return 返回值语句。-- 删除 DROP FUNCTION [IF EXISTS] function_name;-- 查看 SHOW FUNCTION STATUS LIKE 'partten' SHOW CREATE FUNCTION function_name;-- 修改 ALTER FUNCTION function_name 函数选项--// 存储过程，自定义功能 ------------ 定义存储存储过程 是一段代码（过程），存储在数据库中的sql组成。一个存储过程通常用于完成一段业务逻辑，例如报名，交班费，订单入库等。而一个函数通常专注与某个功能，视为其他程序服务的，需要在其他语句中调用函数才可以，而存储过程不能被其他调用，是自己执行 通过call执行。-- 创建CREATE PROCEDURE sp_name (参数列表) 过程体参数列表：不同于函数的参数列表，需要指明参数类型IN，表示输入型OUT，表示输出型INOUT，表示混合型注意，没有返回值。/* 存储过程 */ ------------------存储过程是一段可执行性代码的集合。相比函数，更偏向于业务逻辑。调用：CALL 过程名-- 注意- 没有返回值。- 只能单独调用，不可夹杂在其他语句中-- 参数IN|OUT|INOUT 参数名 数据类型IN 输入：在调用过程中，将数据输入到过程体内部的参数OUT 输出：在调用过程中，将过程体处理完的结果返回到客户端INOUT 输入输出：既可输入，也可输出-- 语法CREATE PROCEDURE 过程名 (参数列表)BEGIN 过程体END/* 用户和权限管理 */ -------------------- root密码重置1. 停止MySQL服务2. [Linux] /usr/local/mysql/bin/safe_mysqld --skip-grant-tables &amp; [Windows] mysqld --skip-grant-tables3. use mysql;4. UPDATE `user` SET PASSWORD=PASSWORD(\"密码\") WHERE `user` = \"root\";5. FLUSH PRIVILEGES;用户信息表：mysql.user-- 刷新权限FLUSH PRIVILEGES;-- 增加用户CREATE USER 用户名 IDENTIFIED BY [PASSWORD] 密码(字符串) - 必须拥有mysql数据库的全局CREATE USER权限，或拥有INSERT权限。 - 只能创建用户，不能赋予权限。 - 用户名，注意引号：如 'user_name'@'192.168.1.1' - 密码也需引号，纯数字密码也要加引号 - 要在纯文本中指定密码，需忽略PASSWORD关键词。要把密码指定为由PASSWORD()函数返回的混编值，需包含关键字PASSWORD-- 重命名用户RENAME USER old_user TO new_user-- 设置密码SET PASSWORD = PASSWORD('密码') -- 为当前用户设置密码SET PASSWORD FOR 用户名 = PASSWORD('密码') -- 为指定用户设置密码-- 删除用户DROP USER 用户名-- 分配权限/添加用户GRANT 权限列表 ON 表名 TO 用户名 [IDENTIFIED BY [PASSWORD] 'password'] - all privileges 表示所有权限 - *.* 表示所有库的所有表 - 库名.表名 表示某库下面的某表 GRANT ALL PRIVILEGES ON `pms`.* TO 'pms'@'%' IDENTIFIED BY 'pms0817';-- 查看权限SHOW GRANTS FOR 用户名 -- 查看当前用户权限 SHOW GRANTS; 或 SHOW GRANTS FOR CURRENT_USER; 或 SHOW GRANTS FOR CURRENT_USER();-- 撤消权限REVOKE 权限列表 ON 表名 FROM 用户名REVOKE ALL PRIVILEGES, GRANT OPTION FROM 用户名 -- 撤销所有权限-- 权限层级-- 要使用GRANT或REVOKE，您必须拥有GRANT OPTION权限，并且您必须用于您正在授予或撤销的权限。全局层级：全局权限适用于一个给定服务器中的所有数据库，mysql.user GRANT ALL ON *.*和 REVOKE ALL ON *.*只授予和撤销全局权限。数据库层级：数据库权限适用于一个给定数据库中的所有目标，mysql.db, mysql.host GRANT ALL ON db_name.*和REVOKE ALL ON db_name.*只授予和撤销数据库权限。表层级：表权限适用于一个给定表中的所有列，mysql.talbes_priv GRANT ALL ON db_name.tbl_name和REVOKE ALL ON db_name.tbl_name只授予和撤销表权限。列层级：列权限适用于一个给定表中的单一列，mysql.columns_priv 当使用REVOKE时，您必须指定与被授权列相同的列。-- 权限列表ALL [PRIVILEGES] -- 设置除GRANT OPTION之外的所有简单权限ALTER -- 允许使用ALTER TABLEALTER ROUTINE -- 更改或取消已存储的子程序CREATE -- 允许使用CREATE TABLECREATE ROUTINE -- 创建已存储的子程序CREATE TEMPORARY TABLES -- 允许使用CREATE TEMPORARY TABLECREATE USER -- 允许使用CREATE USER, DROP USER, RENAME USER和REVOKE ALL PRIVILEGES。CREATE VIEW -- 允许使用CREATE VIEWDELETE -- 允许使用DELETEDROP -- 允许使用DROP TABLEEXECUTE -- 允许用户运行已存储的子程序FILE -- 允许使用SELECT...INTO OUTFILE和LOAD DATA INFILEINDEX -- 允许使用CREATE INDEX和DROP INDEXINSERT -- 允许使用INSERTLOCK TABLES -- 允许对您拥有SELECT权限的表使用LOCK TABLESPROCESS -- 允许使用SHOW FULL PROCESSLISTREFERENCES -- 未被实施RELOAD -- 允许使用FLUSHREPLICATION CLIENT -- 允许用户询问从属服务器或主服务器的地址REPLICATION SLAVE -- 用于复制型从属服务器（从主服务器中读取二进制日志事件）SELECT -- 允许使用SELECTSHOW DATABASES -- 显示所有数据库SHOW VIEW -- 允许使用SHOW CREATE VIEWSHUTDOWN -- 允许使用mysqladmin shutdownSUPER -- 允许使用CHANGE MASTER, KILL, PURGE MASTER LOGS和SET GLOBAL语句，mysqladmin debug命令；允许您连接（一次），即使已达到max_connections。UPDATE -- 允许使用UPDATEUSAGE -- “无权限”的同义词GRANT OPTION -- 允许授予权限/* 表维护 */-- 分析和存储表的关键字分布ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE 表名 ...-- 检查一个或多个表是否有错误CHECK TABLE tbl_name [, tbl_name] ... [option] ...option = {QUICK | FAST | MEDIUM | EXTENDED | CHANGED}-- 整理数据文件的碎片OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] .../* 杂项 */ ------------------1. 可用反引号（`）为标识符（库名、表名、字段名、索引、别名）包裹，以避免与关键字重名！中文也可以作为标识符！2. 每个库目录存在一个保存当前数据库的选项文件db.opt。3. 注释： 单行注释 # 注释内容 多行注释 /* 注释内容 */ 单行注释 -- 注释内容 (标准SQL注释风格，要求双破折号后加一空格符（空格、TAB、换行等）)4. 模式通配符： _ 任意单个字符 % 任意多个字符，甚至包括零字符 单引号需要进行转义 \\'5. CMD命令行内的语句结束符可以为 \";\", \"\\G\", \"\\g\"，仅影响显示结果。其他地方还是用分号结束。delimiter 可修改当前对话的语句结束符。6. SQL对大小写不敏感7. 清除已有语句：\\c","link":"/2019/04/18/一千行-MySQL-学习笔记-转载.html"},{"title":"安装、部分配置icarus主题中文版","text":"摘要发现icarus主题还不错，花了一两个小时研究了下安装、部分配置icarus主题中文版 安装icarus 直接下载主题模块放到blog项目 ,blog项目根目录执行 1git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus 此时已经下载到项目中。 顶级_config.yml中选择icarus主题 1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: icarus 此时主题已经安装好，清除、编译、部署可以看到效果了 配置icarus 完全参照官网配置，进行翻译解说 配置文章部分顶部图片添加icarus 主题中的配置_config.yml中开启图片开关 12article: thumbnail: true 文章.md文件头中添加图片绝对/相对地址 12345title: Getting Started with Icarusthumbnail: /gallery/thumbnails/desert.jpg// thumbnail:https://raw.githubusercontent.com/removeif/blog_image/master/20190620152744.png---Post content... 配置完成后部署显示效果如下(最新文章列表显示缩略图、文章开头显示一张设置图片) 左边文章导航栏开启icarus 主题中的配置_config.yml中开关 1234widgets: - type: toc position: left 同事文章顶部加入标签 1234title: Table of Contents Exampletoc: true---Post content... 配置效果 评论系统开启icarus 主题中的配置_config.yml中开启（部分评论系统需要翻墙才能使用，valine不用翻墙个人推荐，valine安装参考） 1234567comment: type: valine app_id: xxxxxxxx # (required) LeanCloud application id app_key: xxxxxxxx # (required) LeanCloud application key notify: false # (optional) receive email notification verify: false # (optional) show verification code placeholder: xxxxxxxx # (optional) comment box placeholder text 开启效果 捐赠收款开启icarus 主题中的配置_config.yml中开启 注意如果默认不配置，编译时有报错，可以# 把它注释掉，不启用功能 1234567891011donate: - # Donation entry name type: alipay # Qrcode image URL qrcode: 'https://wx2.sinaimg.cn/large/b5d1b710gy1g0lvxdcwm0j20p011i4bg.jpg' - # Donation entry name type: wechat # Qrcode image URL qrcode: 'https://wx2.sinaimg.cn/large/b5d1b710gy1g0lvwdcpb5j20u014qgy2.jpg' 开启配置效果如下 全局搜索开启icarus 主题中的配置_config.yml中开启,不同的搜索类型需要安装插件参考官网,type: insight此类型不需要安装，已经内置 12search: type: insight 效果如下 更多配置请参考官网配置目前配置基本已经够使用，还需要更多配置请参考连接 参考自","link":"/2019/02/28/安装、部分配置icarus主题中文版.html"},{"title":"java基础-static关键字","text":"static用法 static和final是两个我们必须掌握的关键字。不同于其他关键字，他们都有多种用法，而且在一定环境下使用，可以提高程序的运行性能，优化程序的结构。下面我们先来了解一下static关键字及其用法。 修饰成员变量在我们平时的使用当中，static最常用的功能就是修饰类的属性和方法，让他们成为类的成员属性和方法，我们通常将用static修饰的成员称为类成员或者静态成员。 1234567891011121314151617181920212223public class Person { String name; int age; public String toString() { return \"Name:\" + name + \", Age:\" + age; } public static void main(String[] args) { Person p1 = new Person(); p1.name = \"zhangsan\"; p1.age = 10; Person p2 = new Person(); p2.name = \"lisi\"; p2.age = 12; System.out.println(p1); System.out.println(p2); } /**Output * Name:zhangsan, Age:10 * Name:lisi, Age:12 *///~} 根据Person构造出的每一个对象都是独立存在的，保存有自己独立的成员变量，相互不会影响，他们在内存中的示意如下: 从上图中可以看出，p1和p2两个变量引用的对象分别存储在内存中堆区域的不同地址中，所以他们之间相互不会干扰。但其实，在这当中，我们省略了一些重要信息，相信大家也都会想到，对象的成员属性都在这了，由每个对象自己保存，那么他们的方法呢？实际上，不论一个类创建了几个对象，他们的方法都是一样的： 从上面的图中我们可以看到，两个Person对象的方法实际上只是指向了同一个方法定义。这个方法定义是位于内存中的一块不变区域（由jvm划分），我们暂称它为静态存储区。这一块存储区不仅存放了方法的定义，实际上从更大的角度而言，它存放的是各种类的定义，当我们通过new来生成对象时，会根据这里定义的类的定义去创建对象。多个对象仅会对应同一个方法，这里有一个让我们充分信服的理由，那就是不管多少的对象，他们的方法总是相同的，尽管最后的输出会有所不同，但是方法总是会按照我们预想的结果去操作，即不同的对象去调用同一个方法，结果会不尽相同。 static关键字可以修饰成员变量和方法，来让它们变成类的所属，而不是对象的所属，比如我们将Person的age属性用static进行修饰，结果会是什么样呢? 1234567891011public class Person { String name; static int age; /* 其余代码不变... */ /**Output * Name:zhangsan, Age:12 * Name:lisi, Age:12 *///~} 我们发现，结果发生了一点变化，在给p2的age属性赋值时，干扰了p1的age属性，这是为什么呢？我们还是来看他们在内存中的示意： 我们发现，给age属性加了static关键字之后，Person对象就不再拥有age属性了，age属性会统一交给Person类去管理，即多个Person对象只会对应一个age属性，一个对象如果对age属性做了改变，其他的对象都会受到影响。我们看到此时的age和toString()方法一样，都是交由类去管理。 虽然我们看到static可以让对象共享属性，但是实际中我们很少这么用，也不推荐这么使用。因为这样会让该属性变得难以控制，因为它在任何地方都有可能被改变。如果我们想共享属性，一般我们会采用其他的办法： 1234567891011121314151617181920212223242526272829public class Person { private static int count = 0; int id; String name; int age; public Person() { id = ++count; } public String toString() { return \"Id:\" + id + \", Name:\" + name + \", Age:\" + age; } public static void main(String[] args) { Person p1 = new Person(); p1.name = \"zhangsan\"; p1.age = 10; Person p2 = new Person(); p2.name = \"lisi\"; p2.age = 12; System.out.println(p1); System.out.println(p2); } /**Output * Id:1, Name:zhangsan, Age:10 * Id:2, Name:lisi, Age:12 *///~} 上面的代码起到了给Person的对象创建一个唯一id以及记录总数的作用，其中count由static修饰，是Person类的成员属性，每次创建一个Person对象，就会使该属性自加1然后赋给对象的id属性，这样，count属性记录了创建Person对象的总数，由于count使用了private修饰，所以从类外面无法随意改变。 修饰成员方法static的另一个作用，就是修饰成员方法。相比于修饰成员属性，修饰成员方法对于数据的存储上面并没有多大的变化，因为我们从上面可以看出，方法本来就是存放在类的定义当中的。static修饰成员方法最大的作用，就是可以使用”类名.方法名“的方式操作方法，避免了先要new出对象的繁琐和资源消耗，我们可能会经常在帮助类中看到它的使用： 12345678910public class PrintHelper { public static void print(Object o){ System.out.println(o); } public static void main(String[] args) { PrintHelper.print(\"Hello world\"); }} 上面便是一个例子（现在还不太实用），但是我们可以看到它的作用，使得static修饰的方法成为类的方法，使用时通过“类名.方法名”的方式就可以方便的使用了，相当于定义了一个全局的函数（只要导入该类所在的包即可）。不过它也有使用的局限，一个static修饰的类中，不能使用非static修饰的成员变量和方法，这很好理解，因为static修饰的方法是属于类的，如果去直接使用对象的成员变量，它会不知所措（不知该使用哪一个对象的属性）。 静态块在说明static关键字的第三个用法时，我们有必要重新梳理一下一个对象的初始化过程。以下面的代码为例： 1234567891011121314151617181920212223242526272829class Book{ public Book(String msg) { System.out.println(msg); }}public class Person { Book book1 = new Book(\"book1成员变量初始化\"); static Book book2 = new Book(\"static成员book2成员变量初始化\"); public Person(String msg) { System.out.println(msg); } Book book3 = new Book(\"book3成员变量初始化\"); static Book book4 = new Book(\"static成员book4成员变量初始化\"); public static void main(String[] args) { Person p1 = new Person(\"p1初始化\"); } /**Output * static成员book2成员变量初始化 * static成员book4成员变量初始化 * book1成员变量初始化 * book3成员变量初始化 * p1初始化 *///~} 上面的例子中，Person类中组合了四个Book成员变量，两个是普通成员，两个是static修饰的类成员。我们可以看到，当我们new一个Person对象时，static修饰的成员变量首先被初始化，随后是普通成员，最后调用Person类的构造方法完成初始化。也就是说，在创建对象时，static修饰的成员会首先被初始化，而且我们还可以看到，如果有多个static修饰的成员，那么会按照他们的先后位置进行初始化。 实际上，static修饰的成员的初始化可以更早的进行，请看下面的例子： 12345678910111213141516171819202122232425262728293031323334353637class Book{ public Book(String msg) { System.out.println(msg); }}public class Person { Book book1 = new Book(\"book1成员变量初始化\"); static Book book2 = new Book(\"static成员book2成员变量初始化\"); public Person(String msg) { System.out.println(msg); } Book book3 = new Book(\"book3成员变量初始化\"); static Book book4 = new Book(\"static成员book4成员变量初始化\"); public static void funStatic() { System.out.println(\"static修饰的funStatic方法\"); } public static void main(String[] args) { Person.funStatic(); System.out.println(\"****************\"); Person p1 = new Person(\"p1初始化\"); } /**Output * static成员book2成员变量初始化 * static成员book4成员变量初始化 * static修饰的funStatic方法 * *************** * book1成员变量初始化 * book3成员变量初始化 * p1初始化 *///~} 在上面的例子中我们可以发现两个有意思的地方，第一个是当我们没有创建对象，而是通过类去调用类方法时，尽管该方法没有使用到任何的类成员，类成员还是在方法调用之前就初始化了，这说明，当我们第一次去使用一个类时，就会触发该类的成员初始化。第二个是当我们使用了类方法，完成类的成员的初始化后，再new该类的对象时，static修饰的类成员没有再次初始化，这说明，static修饰的类成员，在程序运行过程中，只需要初始化一次即可，不会进行多次的初始化。 回顾了对象的初始化以后，我们再来看static的第三个作用就非常简单了，那就是当我们初始化static修饰的成员时，可以将他们统一放在一个以static开始，用花括号包裹起来的块状语句中： 123456789101112131415161718192021222324252627282930313233343536373839404142class Book{ public Book(String msg) { System.out.println(msg); }}public class Person { Book book1 = new Book(\"book1成员变量初始化\"); static Book book2; static { book2 = new Book(\"static成员book2成员变量初始化\"); book4 = new Book(\"static成员book4成员变量初始化\"); } public Person(String msg) { System.out.println(msg); } Book book3 = new Book(\"book3成员变量初始化\"); static Book book4; public static void funStatic() { System.out.println(\"static修饰的funStatic方法\"); } public static void main(String[] args) { Person.funStatic(); System.out.println(\"****************\"); Person p1 = new Person(\"p1初始化\"); } /**Output * static成员book2成员变量初始化 * static成员book4成员变量初始化 * static修饰的funStatic方法 * *************** * book1成员变量初始化 * book3成员变量初始化 * p1初始化 *///~} 我们将上一个例子稍微做了一下修改，可以看到，结果没有二致。 静态导包相比于上面的三种用途，第四种用途可能了解的人就比较少了，但是实际上它很简单，而且在调用类方法时会更方便。以上面的“PrintHelper”的例子为例，做一下稍微的变化，即可使用静态导包带给我们的方便： 123456789/* PrintHelper.java文件 */package com.dotgua.study;public class PrintHelper { public static void print(Object o){ System.out.println(o); }} 123456789101112import static com.dotgua.study.PrintHelper.*; // 导入上面的包public class App { public static void main( String[] args ) { print(\"Hello World!\"); } /**Output * Hello World! *///~} 上面的代码来自于两个java文件，其中的PrintHelper很简单，包含了一个用于打印的static方法。而在App.java文件中，我们首先将PrintHelper类导入，这里在导入时，我们使用了static关键字，而且在引入类的最后还加上了“.*”，它的作用就是将PrintHelper类中的所有类方法直接导入。不同于非static导入，采用static导入包后，在不与当前类的方法名冲突的情况下，无需使用“类名.方法名”的方法去调用类方法了，直接可以采用”方法名“去调用类方法，就好像是该类自己的方法一样使用即可。 总结static是java中非常重要的一个关键字，而且它的用法也很丰富，主要有四种用法： 用来修饰成员变量，将其变为类的成员，从而实现所有对象对于该成员的共享； 用来修饰成员方法，将其变为类方法，可以直接使用“类名.方法名”的方式调用，常用于工具类； 静态块用法，将多个类成员放在一起初始化，使得程序更加规整，其中理解对象的初始化过程非常关键； 静态导包用法，将类的方法直接导入到当前类中，从而直接使用“方法名”即可调用类方法，更加方便。 参考自","link":"/2019/01/07/java基础-static关键字.html"},{"title":"java基础-final关键字","text":"final 关键字 在java的关键字中，static和final是两个我们必须掌握的关键字。不同于其他关键字，他们都有多种用法，而且在一定环境下使用，可以提高程序的运行性能，优化程序的结构。下面我们来了解一下final关键字及其用法。 修饰数据在编写程序时，我们经常需要说明一个数据是不可变的，我们成为常量。在java中，用final关键字修饰的变量，只能进行一次赋值操作，并且在生存期内不可以改变它的值。更重要的是，final会告诉编译器，这个数据是不会修改的，那么编译器就可能会在编译时期就对该数据进行替换甚至执行计算，这样可以对我们的程序起到一点优化。不过在针对基本类型和引用类型时，final关键字的效果存在细微差别。我们来看下面的例子： 123456789101112131415161718192021222324 class Value { int v; public Value(int v) { this.v = v; }}public class FinalTest { final int f1 = 1; final int f2; public FinalTest() { f2 = 2; } public static void main(String[] args) { final int value1 = 1; // value1 = 4; final double value2; value2 = 2.0; final Value value3 = new Value(1); value3.v = 4; }} 上面的例子中，我们先来看一下main方法中的几个final修饰的数据，在给value1赋初始值之后，我们无法再对value1的值进行修改，final关键字起到了常量的作用。从value2我们可以看到，final修饰的变量可以不在声明时赋值，即可以先声明，后赋值。value3时一个引用变量，这里我们可以看到final修饰引用变量时，只是限定了引用变量的引用不可改变，即不能将value3再次引用另一个Value对象，但是引用的对象的值是可以改变的，从内存模型中我们看的更加清晰： 上图中，final修饰的值用粗线条的边框表示它的值是不可改变的，我们知道引用变量的值实际上是它所引用的对象的地址，也就是说该地址的值是不可改变的，从而说明了为什么引用变量不可以改变引用对象。而实际引用的对象实际上是不受final关键字的影响的，所以它的值是可以改变的。 另一方面，我们看到了用final修饰成员变量时的细微差别，因为final修饰的数据的值是不可改变的，所以我们必须确保在使用前就已经对成员变量赋值了。因此对于final修饰的成员变量，我们有且只有两个地方可以给它赋值，一个是声明该成员时赋值，另一个是在构造方法中赋值，在这两个地方我们必须给它们赋初始值。 最后我们需要注意的一点是，同时使用static和final修饰的成员在内存中只占据一段不能改变的存储空间。 修饰方法参数前面我们可以看到，如果变量是我们自己创建的，那么使用final修饰表示我们只会给它赋值一次且不会改变变量的值。那么如果变量是作为参数传入的，我们怎么保证它的值不会改变呢？这就用到了final的第二种用法，即在我们编写方法时，可以在参数前面添加final关键字，它表示在整个方法中，我们不会（实际上是不能）改变参数的值： 12345678910public class FinalTest { /* ... */ public void finalFunc(final int i, final Value value) { // i = 5; 不能改变i的值 // v = new Value(); 不能改变v的值 value.v = 5; // 可以改变引用对象的值 }} 修饰方法第三种方式，即用final关键字修饰方法，它表示该方法不能被覆盖。这种使用方式主要是从设计的角度考虑，即明确告诉其他可能会继承该类的程序员，不希望他们去覆盖这个方法。这种方式我们很容易理解，然而，关于private和final关键字还有一点联系，这就是类中所有的private方法都隐式地指定为是final的，由于无法在类外使用private方法，所以也就无法覆盖它。 修饰类了解了final关键字的其他用法，我们很容易可以想到使用final关键字修饰类的作用，那就是用final修饰的类是无法被继承的。 上面我们讲解了final的四种用法，然而，对于第三种和第四种用法，我们却甚少使用。这不是没有道理的，从final的设计来讲，这两种用法甚至可以说是鸡肋，因为对于开发人员来讲，如果我们写的类被继承的越多，就说明我们写的类越有价值，越成功。即使是从设计的角度来讲，也没有必要将一个类设计为不可继承的。Java标准库就是一个很好的反例，特别是Java 1.0/1.1中Vector类被如此广泛的运用，如果所有的方法均未被指定为final的话，它可能会更加有用。如此有用的类，我们很容易想到去继承和重写他们，然而，由于final的作用，导致我们对Vector类的扩展受到了一些阻碍，导致了Vector并没有完全发挥它应有的全部价值。 总结final关键字是我们经常使用的关键字之一，它的用法有很多，但是并不是每一种用法都值得我们去广泛使用。它的主要用法有以下四种： 用来修饰数据，包括成员变量和局部变量，该变量只能被赋值一次且它的值无法被改变。对于成员变量来讲，我们必须在声明时或者构造方法中对它赋值； 用来修饰方法参数，表示在变量的生存期中它的值不能被改变； 修饰方法，表示该方法无法被重写； 修饰类，表示该类无法被继承。 上面的四种方法中，第三种和第四种方法需要谨慎使用，因为在大多数情况下，如果是仅仅为了一点设计上的考虑，我们并不需要使用final来修饰方法和类。 参考自","link":"/2019/01/07/java基础-final关键字.html"},{"title":"Java设计模式之代理模式","text":"代理模式代理(Proxy)是一种设计模式,提供了对目标对象另外的访问方式;即通过代理对象访问目标对象.这样做的好处是:可以在目标对象实现的基础上,增强额外的功能操作,即扩展目标对象的功能.这里使用到编程中的一个思想:不要随意去修改别人已经写好的代码或者方法,如果需改修改,可以通过代理的方式来扩展该方法 举个例子来说明代理的作用:假设我们想邀请一位明星,那么并不是直接连接明星,而是联系明星的经纪人,来达到同样的目的.明星就是一个目标对象,他只要负责活动中的节目,而其他琐碎的事情就交给他的代理人(经纪人)来解决.这就是代理思想在现实中的一个例子.图片表示如下： 代理模式的关键点是:代理对象与目标对象.代理对象是对目标对象的扩展,并会调用目标对象 静态代理静态代理在使用时,需要定义接口或者父类,被代理对象与代理对象一起实现相同的接口或者是继承相同父类. eg:模拟保存动作,定义一个保存动作的接口:IUserDao.java,然后目标对象实现这个接口的方法UserDao.java,此时如果使用静态代理方式,就需要在代理对象(UserDaoProxy.java)中也实现IUserDao接口.调用的时候通过调用代理对象的方法来调用目标对象.需要注意的是,代理对象与目标对象要实现相同的接口,然后通过调用相同的方法来调用目标对象的方法 示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * @desc 用户保存接口 */public interface IUserDao { // 保存方法 void save();}/** * @desc 用户保存 */public class UserDao implements IUserDao { @Override public void save() { System.out.println(\"OK，已保存数据!\"); }}/** * @desc 代理对象，静态代理 */public class UserDaoProxy implements IUserDao { // 目标对象 private IUserDao target; public UserDaoProxy(IUserDao user) { this.target = user; } @Override public void save() { System.out.println(\"开始事物.\"); target.save(); System.out.println(\"提交事物.\"); }}/** * @desc 静态代理测试方法 */public class MainTest { public static void main(String[] args) { // 目标对象 IUserDao userDao = new UserDao(); // 代理对象，把目标对象传给代理，建立代理关系 UserDaoProxy proxy = new UserDaoProxy(userDao); proxy.save(); }} 结果： 静态代理总结:1.可以做到在不修改目标对象的功能前提下,对目标功能扩展.2.缺点: 因为代理对象需要与目标对象实现一样的接口,所以会有很多代理类,类太多.同时,一旦接口增加方法,目标对象与代理对象都要维护. 如何解决静态代理中的缺点呢?答案是可以使用动态代理方式 动态代理动态代理有以下特点: 代理对象,不需要实现接口 .代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型) 动态代理也叫做:JDK代理,接口代理 JDK中生成代理对象的API代理类所在包:java.lang.reflect.ProxyJDK实现代理只需要使用newProxyInstance方法,但是该方法需要接收三个参数,完整的写法是: 1static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h ) 注意该方法是在Proxy类中是静态方法,且接收的三个参数依次为: ClassLoader loader,:指定当前目标对象使用类加载器,获取加载器的方法是固定的 Class&lt;?&gt;[] interfaces,:目标对象实现的接口的类型,使用泛型方式确认类型 InvocationHandler h:事件处理,执行目标对象的方法时,会触发事件处理器的方法,会把当前执行目标对象的方法作为参数传入 代码示例:接口类IUserDao.java以及接口实现类,目标对象UserDao是一样的,没有做修改.在这个基础上,增加一个代理工厂类(ProxyFactory.java),将代理类写在这个地方,然后在测试类(需要使用到代理的代码)中先建立目标对象和代理对象的联系,然后代用代理对象的中同名方法 示例代码代理工厂类:ProxyFactory.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/** * @desc 动态代理工厂 */public class ProxyFactory { private Object target; /** * 维护一个目标对象 * * @param target */ public ProxyFactory(Object target) { this.target = target; } public Object getProxyInstance() { return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"开始事物2.\"); // 执行目标方法 Object returnValue = method.invoke(target, args); System.out.println(\"提交事物2.\"); return returnValue; } }); }}/** * @desc 动态代理测试方法 */public class MainTest { public static void main(String[] args) { // 目标对象 IUserDao userDao = new UserDao(); // 原始类型 System.out.println(userDao.getClass()); // 给目标对象，创建代理对象 IUserDao proxy = (IUserDao) new ProxyFactory(userDao).getProxyInstance(); // 内存中动态生成的代理对象 System.out.println(proxy.getClass()); // 执行方法 proxy.save(); }} 结果： 总结代理对象不需要实现接口,但是目标对象一定要实现接口,否则不能用动态代理 Cglib代理上面的静态代理和动态代理模式都是要求目标对象是实现一个接口的目标对象,但是有时候目标对象只是一个单独的对象,并没有实现任何的接口,这个时候就可以使用以目标对象子类的方式类实现代理,这种方法就叫做:Cglib代理 一. Cglib代理,也叫作子类代理,它是在内存中构建一个子类对象从而实现对目标对象功能的扩展. JDK的动态代理有一个限制,就是使用动态代理的对象必须实现一个或多个接口,如果想代理没有实现接口的类,就可以使用Cglib实现. Cglib是一个强大的高性能的代码生成包,它可以在运行期扩展java类与实现java接口.它广泛的被许多AOP的框架使用,例如Spring AOP和synaop为他们提供方法的interception(拦截) Cglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类.不鼓励直接使用ASM,因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉. 二. Cglib子类代理实现方法: 需要引入cglib的jar文件,但是Spring的核心包中已经包括了Cglib功能,所以直接引入spring-core-3.2.5.jar即可. 引入功能包后,就可以在内存中动态构建子类 代理的类不能为final,否则报错 目标对象的方法如果为final/static,那么就不会被拦截,即不会执行目标对象额外的业务方法. 示例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 目标对象,没有实现任何接口 */public class UserDao { public void save() { System.out.println(\"----已经保存数据!----\"); }}/** * Cglib子类代理工厂 * 对UserDao在内存中动态构建一个子类对象 */public class ProxyFactory implements MethodInterceptor{ //维护目标对象 private Object target; public ProxyFactory(Object target) { this.target = target; } //给目标对象创建一个代理对象 public Object getProxyInstance(){ //1.工具类 Enhancer en = new Enhancer(); //2.设置父类 en.setSuperclass(target.getClass()); //3.设置回调函数 en.setCallback(this); //4.创建子类(代理对象) return en.create(); } @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable { System.out.println(\"开始事务...\"); //执行目标对象的方法 Object returnValue = method.invoke(target, args); System.out.println(\"提交事务...\"); return returnValue; }}/** * 测试类 */public class App { @Test public void test(){ //目标对象 UserDao target = new UserDao(); //代理对象 UserDao proxy = (UserDao)new ProxyFactory(target).getProxyInstance(); //执行代理对象的方法 proxy.save(); }} 总结动态代理与静态代理相比较，最大的好处是接口中声明的所有方法都被转移到调用处理器一个集中的方法中处理。在接口方法数量比较多的时候，我们可以进行灵活处理，而不需要像静态代理那样对每一个方法或方法组合进行处理。Proxy 很美很强大，但是仅支持 interface 代理。Java 的单继承机制注定了这些动态代理类们无法实现对 class 的动态代理。好在有cglib为Proxy提供了弥补。class与interface的区别本来就模糊，在java8中更是增加了一些新特性，使得interface越来越接近class，当有一日，java突破了单继承的限制，动态代理将会更加强大。 参考：http://www.cnblogs.com/cenyu/p/6289209.html http://blog.csdn.net/goskalrie/article/details/52458773","link":"/2019/01/06/Java设计模式之代理模式.html"},{"title":"Java设计模式之命令模式","text":"目的 将一个请求封装为一个对象，从而可用不同的请求对客户进行参数化；对请求排队或记录日志，以及支持可撤销的操作。 将”发出请求的对象”和”接收与执行这些请求的对象”分隔开来。 效果 command模式将调用操作的对象和实现该操作的对象解耦 可以将多个命令装配成一个复合命令，复合命令是Composite模式的一个实例 增加新的command很容易，无需改变已有的类 适用性 抽象出待执行的动作以参数化某对象 在不同的时刻指定、排列和执行请求。如请求队列 支持取消操作 支持修改日志 用构建在原语操作上的高层操作构造一个系统。支持事物 参与者 Command声明执行操作的接口 ConcreteCommand将一个接收者对象绑定于一个动作 调用接收者相应的操作，以实现execute Client创建一个具体命令对象并设定它的接收者 Invoker要求该命令执行这个请求 Receiver知道如何实施与执行一个请求相关的操作。任何类都可能作为一个接收者 结构图 协作： 1)、client创建一个ConcreteCommand对象并指定它的Receiver对象 2)、某Invoker对象存储该ConcreteCommand对象 3)、该Invoker通过调用Command对象的execute操作来提交一个请求。若该命令是可撤销的，ConcreteCommand在执行execute操作前存储当前状态以用于取消该命令 4)、ConcreteCommand对象调用它的Receiver的操作以执行该请求 命令对象将动作和接受者包进对象中，这个对象只暴露出一个execute()方法，当此方法被调用的时候，接收者就会进行这些动作。从外面来看，其他对象不知道究竟哪个接收者进行了哪些动作，只知道如果调用execute()方法，请求的目的就能达到。 java 实现源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * @desc 命令接口 */public interface Command { /** * 执行命令 */ void excute(); /** * 撤销命令 */ void undo();}/** * @desc 真正命令执行者，接收者 */public class Receiver { public void action() { System.out.println(\"正在执行命令...\"); } public void unAction() { System.out.println(\"正在撤销命令...\"); }}/** * @desc 创建命令（可实现多条命令以及多个命令执行人） */public class CreateCommand implements Command { private Receiver receiver; /** * 初始化命令接收人 * * @param receiver */ public CreateCommand(Receiver receiver) { this.receiver = receiver; } @Override public void excute() { receiver.action(); } @Override public void undo() { receiver.unAction(); }}/** * @desc 命令调用者 */public class Invoker { private Command command; /** * 命令调用者持有该命令 * * @param command */ public Invoker(Command command) { this.command = command; } /** * 执行命令 */ public void runCommand() { command.excute(); } /** * 撤销命令 */ public void unRunCommand() { command.undo(); }}/** * @desc 命令模式测试 */public class TestMain { public static void main(String[] args) { // new 一个命令执行人 Receiver receiver = new Receiver(); // new 一条命令 Command command = new CreateCommand(receiver); // 开始调用命令 Invoker invoker = new Invoker(command); invoker.runCommand(); invoker.unRunCommand(); }} 执行结果 常见应用： 1、工作队列，线程池，日程安排 2、日志请求(系统恢复)要点： 1、命令模式将发出请求的对象和执行请求的对象解耦 2、在被解耦的两者之间是通过命令对象进行沟通的。命令对象封装了接收者和一个或一组动作 3、调用者通过调用命令对象的execute()发出请求，这会使得接收者的动作被调用 4、调用者可以接受命令当作参数，甚至在运行时动态的进行 5、命令可以支持撤销，做法是实现一个undo()方法来回到execute()被执行前的状态 6、宏命令是命令的一种简单的延伸，允许调用多个命令。宏方法也可以支持撤销 7、实际操作时，很常见使用”聪明”命令对象，也就是直接实现了请求，而不是将工作委托给接受者(弊端？) 8、命令也可以用来实现日志和事物系统 参考：http://www.cnblogs.com/ikuman/archive/2013/08/06/3233092.html","link":"/2019/01/04/Java设计模式之命令模式.html"},{"title":"java 8部分读书笔记","text":"Lambda 表达式 Lambda 表达式引用的是值，不是变量。 Lambda 表达式中的变量只能是final类型，只能给变量赋值一次。 123String name = getUserName();name = formatUesrName();button.addActionListener(event -&gt; System.out.println(\"Hi\" + name)) 如上代码将不会编译通过，name被赋值多次。 函数接口：只有一个抽象方法的接口，用作Lambda表达式的类型。 Java中重要的几个函数接口 名称 解释 返回值 eg 参数 Predicate 断言 boolean 这张唱片已经发行了吗 T Consumer 消费 void 输出一个值 T Function&lt;T,R&gt; 运行 R 获得Artist对象的名字 T Supplier 供应 T 工厂方法 None UnaryOperator 一元运算 T 逻辑非(!) T BinaryOperator 二元运算 T 求两个数的乘积 (T,T) 所有的都有泛型没有的话值代码编译不过 123Predicate&lt;Integer&gt; atLeast5 = x -&gt; x &gt; 5;// 编译通过Predicate atLeast5 = x -&gt; x &gt; 5;// 编译不通过BinaryOperator&lt;Long&gt; addLongs = (x , y) -&gt; x + y;// 编译通过 流 Stream(针对于集合) 惰性求值 和及早求值 1allArtists.stream().filter(artist -&gt; artist.isFrom(\"London\")); 这行代码并没有做什么实质性工作,filter只是刻画出了Stream，没有产生新的集合。像filter这种只描述Stream，不产生新集合的方法叫做惰性求值方法,而像count这样最终会从Stream产生值的方法叫做及早求值方法。 123456789allArtists.stream().filter(artist - &gt;{ System.out.println(artist.getName()); return artist.isFrom(\"London\");});// 此段代码并不会输出 艺术家名字allArtists.stream().filter(artist - &gt;{ System.out.println(artist.getName()); return artist.isFrom(\"London\");}).count();// 此段代码并会输出 艺术家名字 判断一个操作是惰性求值还是及早求值，只需看它的返回值，返回值是Stream,那么就是惰性求值，返回值是另一个值或者是空，则是及早求值。最终达到的效果：通过这些方法形成一个惰性求值的链，最终调用一个及早求值方法得到我们需要的最终结果。 常用的流操作 collect(toList()) :由Stream里的值生成一个列表 Stream的of 方法使用一组初始值生成新的Stream 12List&lt;String&gt; collected = Stream.of(\"a\",\"b\",\"c\").collect(Collectors.toList());assertEquals(Arrays.asList(\"a\",\"b\",\"c\"),collected);//判断结果和预期值是否一样 map 将一种类型转换为另一种类型，将一个流中的值转换为一个新的流。mapToInt/mapToDouble/mapToLong 123List&lt;String&gt; collected = Stream.of(\"a\",\"b\",\"hello\") .map(string -&gt; string.toUpperCase()) .collect(Collectors.toList());//将小写转换为大写 filter filter模式，保留Stream中的一些元素，过滤掉其他的。返回true保留，返回false过滤。 123List&lt;String&gt; beginWithNumbers = Stream.of(\"a\",\"1adf\",\"abc1\") .filter(value -&gt; isDigit(value.chartAt(0))) .collect(toList());//返回数据开头的字符串 flatMap :可用Stream替换值，将多个Stream连接成一个Stream 123List&lt;Integer&gt; together = Stream.of(asList(1,2), asList(3,4)) .flatMap(numbers -&gt; numbers.stream()) .collect(toList()); 它会把原流中的每一个元素经过指定函数处理之后，返回一个Stream对象，并将之展开到原父流中。 max和min 1234List&lt;Track&gt; tracks = asList(new Track(\"Bakai\",524), new Track(\"Violets\",378), new Track(\"Time\",451));Track shortestTrack = tracks.stream().min(Commparator.comparing(track -&gt; track.getLength())).get();// 查找距离最短的 reduce 聚合归纳：操作中可以实现从一组值生成一个值 使用reduce求和 12int count = Stream.of(1,2,3) .reduce(0, (acc, element) -&gt; acc + element); 展开reduce操作 123456BinaryOperator&lt;Integer&gt; accumulator = (acc, element) -&gt; acc + element;int count = accumulator.apply( accumulator.apply( accumulator.apply(0, 1), 2), 3); 1collections.stream().map(Entity::getNum).reduce(0, Integer::sum); // collections求和num 1234//根据typeId分组 entities[{typeId:1,name:\"火锅\"},{typeId:1,name:\"烧烤\"}，{typeId:2,name:\"律师\"}]Map&lt;Integer, List&lt;Entity&gt;&gt; groups = entities.stream() .collect(Collectors.groupingBy(Entity::getTypeId));List&lt;Entity&gt; list = groups.get(typeId); //拿到对应的分组数据 找出长度大于一分钟的曲目 1234567public Set&lt;String&gt; findLongTracks(List&lt;Album&gt; albums){ return albums.stream() .flatMap(album -&gt; album.getTracks()) .filter(track -&gt; track.getLength() &gt; 60) .map(track -&gt; track.getName) .collect(toSet());}","link":"/2018/12/19/java-8部分读书笔记.html"},{"title":"Java设计模式之适配器模式","text":"定义 适配器模式把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。 适配器模式的用途用电器做例子，笔记本电脑的插头一般都是三相的，即除了阳极、阴极外，还有一个地极。而有些地方的电源插座却只有两极，没有地极。电源插座与笔记本电脑的电源插头不匹配使得笔记本电脑无法使用。这时候一个三相到两相的转换器（适配器）就能解决此问题，而这正像是本模式所做的事情。 适配器模式的结构适配器模式有类的适配器模式和对象的适配器模式两种不同的形式。 类适配器模式类的适配器模式把适配的类的API转换成为目标类的API。 在上图中可以看出，Adaptee类并没有sampleOperation2()方法，而客户端则期待这个方法。为使客户端能够使用Adaptee类，提供一个中间环节，即类Adapter，把Adaptee的API与Target类的API衔接起来。Adapter与Adaptee是继承关系，这决定了这个适配器模式是类的： 模式所涉及的角色有： ● 目标(Target)角色：这就是所期待得到的接口。注意：由于这里讨论的是类适配器模式，因此目标不可以是类。 ● 源(Adapee)角色：现在需要适配的接口。 ● 适配器(Adapter)角色：适配器类是本模式的核心。适配器把源接口转换成目标接口。显然，这一角色不可以是接口，而必须是具体类。 java源码123456789101112131415161718192021222324252627282930313233343536public interface Target { /** * 这是源类Adaptee也有的方法 */ public void sampleOperation1(); /** * 这是源类Adapteee没有的方法 */ public void sampleOperation2(); }/**上面给出的是目标角色的源代码，这个角色是以一个JAVA接口的形式实现的。可以看出，这个接口声明了两个方法：*sampleOperation1()和sampleOperation2()。而源角色Adaptee是一个具体类，它有一个sampleOperation1()方法，但是没有sampleOperation2()方法。*/public class Adaptee { public void sampleOperation1(){}}/**适配器角色Adapter扩展了Adaptee,同时又实现了目标(Target)接口。由于Adaptee没有提供sampleOperation2()方法，而目标接口又要求这个方法，因此适配器角色Adapter实现了这个方法。*/public class Adapter extends Adaptee implements Target { /** * 由于源类Adaptee没有方法sampleOperation2() * 因此适配器补充上这个方法 */ @Override public void sampleOperation2() { //写相关的代码 }} 对象适配器模式与类的适配器模式一样，对象的适配器模式把被适配的类的API转换成为目标类的API，与类的适配器模式不同的是，对象的适配器模式不是使用继承关系连接到Adaptee类，而是使用委派关系连接到Adaptee类。 从上图可以看出，Adaptee类并没有sampleOperation2()方法，而客户端则期待这个方法。为使客户端能够使用Adaptee类，需要提供一个包装(Wrapper)类Adapter。这个包装类包装了一个Adaptee的实例，从而此包装类能够把Adaptee的API与Target类的API衔接起来。Adapter与Adaptee是委派关系，这决定了适配器模式是对象的。 java 源码实现1234567891011121314151617181920212223242526272829303132333435363738public interface Target { /** * 这是源类Adaptee也有的方法 */ public void sampleOperation1(); /** * 这是源类Adapteee没有的方法 */ public void sampleOperation2(); }public class Adaptee { public void sampleOperation1(){} }public class Adapter { private Adaptee adaptee; public Adapter(Adaptee adaptee){ this.adaptee = adaptee; } /** * 源类Adaptee有方法sampleOperation1 * 因此适配器类直接委派即可 */ public void sampleOperation1(){ this.adaptee.sampleOperation1(); } /** * 源类Adaptee没有方法sampleOperation2 * 因此由适配器类需要补充此方法 */ public void sampleOperation2(){ //写相关的代码 }} 类适配器模式和对象适配器模式的权衡 类适配器，使用对象继承的方式，是静态的定义方式；对象适配器，使用对象组合的方式，是动态组合的方式。 对于类适配器，由于适配器直接继承了Adaptee，使得适配器不能和Adaptee的子类一起工作，因为继承是静态的关系 对于对象适配器，一个适配器可以把多种不同的源适配到同一个目标。换言之，同一个适配器可以把源类和它的子类都适配到目标接口。因为对象适配器采用的是对象组合的关系，只要对象类型正确，是不是子类都无所谓。 对于类适配器，适配器可以重定义Adaptee的部分行为，相当于子类覆盖父类的部分实现方法。 对于对象适配器，要重定义Adaptee的行为比较困难，这种情况下，需要定义Adaptee的子类来实现重定义，然后让适配器组合子类。虽然重定义Adaptee的行为比较困难，但是想要增加一些新的行为则方便的很，而且新增加的行为可同时适用于所有的源。 对于类适配器，仅仅引入了一个对象，并不需要额外的引用来间接得到Adaptee。 对于对象适配器，需要额外的引用来间接得到Adaptee。 建议尽量使用对象适配器的实现方式，多用合成/聚合、少用继承。当然，具体问题具体分析，根据需要来选用实现方式，最适合的才是最好的。 适配器模式的优点 更好的复用性 系统需要使用现有的类，而此类的接口不符合系统的需要。那么通过适配器模式就可以让这些功能得到更好的复用。 更好的扩展性 在实现适配器功能的时候，可以调用自己开发的功能，从而自然地扩展系统的功能。 适配器模式的缺点过多的使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是A接口，其实内部被适配成了B接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 缺省适配器模式缺省适配(Default Adapter)模式为一个接口提供缺省实现，这样子类型可以从这个缺省实现进行扩展，而不必从原有接口进行扩展。作为适配器模式的一个特例，缺省是适配模式在JAVA语言中有着特殊的应用。 实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/***鲁智深的故事* 和尚要做什么呢？吃斋、念经、打坐、撞钟、习武等。如果设计一个和尚*接口，*给出所有的和尚都需要实现的方法，那么这个接口应当如下：*/public interface 和尚 { public void 吃斋（）； public void 念经（）； public void 打坐（）； public void 撞钟（）； public void 习武（）； public String getName();}/**显然，所有的和尚类都应当实现接口所定义的全部方法，不然就根本通不过JAVA语言编辑器。像下面的鲁智深类就不行。*/public class 鲁智深 implements 和尚{ public void 习武(){ 拳打镇关西； 大闹五台山； 大闹桃花村； 火烧瓦官寺； 倒拔垂杨柳； } public String getName(){ return \"鲁智深\"; }}/*** 由于鲁智深只实现了getName()和习武()方法，而没有实现任何其他的方法。因此，它根本就通不过Java语言编译器。*鲁智深类只有实现和尚接口的所有的方法才可以通过Java语言编译器，但是这样一来鲁智深就不再是鲁智深了。*以史为鉴，可以知天下。研究一下几百年前鲁智深是怎么剃度成和尚的，会对Java编程有很大的启发。*不错，当初鲁达剃度，众僧说：“此人形容丑恶、相貌凶顽，不可剃度他\",但是长老却说：*”此人上应天星、心地刚直。虽然时下凶顽，命中驳杂，久后却得清净。证果非凡，汝等皆不及他。”*原来如此！看来只要这里也应上一个天星的话，问题就解决了！使用面向对象的语言来说，“应”者，实现也；“天星”者，抽象类也。*/public abstract class 天星 implements 和尚 { public void 吃斋(){} public void 念经(){} public void 打坐(){} public void 撞钟(){} public void 习武(){} public String getName(){ return null; }}/**鲁智深类继承抽象类“天星”*/public class 鲁智深 extends 和尚{ public void 习武(){ 拳打镇关西； 大闹五台山； 大闹桃花村； 火烧瓦官寺； 倒拔垂杨柳； } public String getName(){ return \"鲁智深\"; }} ​ 这个抽象的天星类便是一个适配器类，鲁智深实际上借助于适配器模式达到了剃度的目的。此适配器类实现了和尚接口所要求的所有方法。但是与通常的适配器模式不同的是，此适配器类给出的所有的方法的实现都是“平庸”的。这种“平庸化”的适配器模式称作缺省适配模式。 ​ 在很多情况下，必须让一个具体类实现某一个接口，但是这个类又用不到接口所规定的所有的方法。通常的处理方法是，这个具体类要实现所有的方法，那些有用的方法要有实现，那些没有用的方法也要有空的、平庸的实现。 这些空的方法是一种浪费，有时也是一种混乱。除非看过这些空方法的代码，程序员可能会以为这些方法不是空的。即便他知道其中有一些方法是空的，也不一定知道哪些方法是空的，哪些方法不是空的，除非看过这些方法的源代码或是文档。 缺省适配模式可以很好的处理这一情况。可以设计一个抽象的适配器类实现接口，此抽象类要给接口所要求的每一种方法都提供一个空的方法。就像帮助了鲁智深的“上应天星”一样，此抽象类可以使它的具体子类免于被迫实现空的方法。 缺省适配器模式的结构缺省适配模式是一种“平庸”化的适配器模式。 实现代码12345678910111213141516171819202122public interface AbstractService { public void serviceOperation1(); public int serviceOperation2(); public String serviceOperation3();}public abstract class ServiceAdapter implements AbstractService{ @Override public void serviceOperation1() { } @Override public int serviceOperation2() { return 0; } @Override public String serviceOperation3() { return null; }} 可以看到，接口AbstractService要求定义三个方法，分别是serviceOperation1()、serviceOperation2()、serviceOperation3()；而抽象适配器类ServiceAdapter则为这三种方法都提供了平庸的实现。因此，任何继承自抽象类ServiceAdapter的具体类都可以选择它所需要的方法实现，而不必理会其他的不需要的方法。 适配器模式的用意是要改变源的接口，以便于目标接口相容。缺省适配的用意稍有不同，它是为了方便建立一个不平庸的适配器类而提供的一种平庸实现。 在任何时候，如果不准备实现一个接口的所有方法时，就可以使用“缺省适配模式”制造一个抽象类，给出所有方法的平庸的具体实现。这样，从这个抽象类再继承下去的子类就不必实现所有的方法了。 参考：http://www.cnblogs.com/java-my-life/archive/2012/04/13/2442795.html","link":"/2018/12/04/Java设计模式之适配器模式.html"},{"title":"支付系统设计(转载)","text":"支付系统概述支付系统是连接消费者、商家（或平台）和金融机构的桥梁，管理支付数据，调用第三方支付平台接口，记录支付信息（对应订单号，支付金额等），金额对账等功能，根据不同公司对于支付业务的定位不同大概有几个阶段：第一阶段：支付作为一个（封闭）的、独立的应用系统，为各系统提供支付功能支持。一般来说，这个系统仅限于为公司内部的业务提供支付支持，并且和业务紧密耦合。第二阶段：支付作为一个开发的系统，为公司内外部系统、各种业务提供支付服务，支付服务本身应该是和具体的业务解耦合。 支付系统架构模块组成图 我们先来看一下用户完成一次购物需要进行那些操作： 通常消费者在手机APP或者网站都会涉及到支付相关的业务场景，用户只需要简单点击支付按钮输入支付密码，就可以完成整个支付过程，那么我就和大家一起来看看一个完整的支付系统有什么功能组成和设计时需要考虑那些问题。 支付系统的作用 从上图中我们可以看出真实的资金流向。首先当用户产生支付行为时，资金从用户端流向支付系统，退款时则相反，从支付系统回流至用户端。因此在整个交易过程中用户端与支付系统是双向资金的流动方式。对于支付系统而言，资金有进有出。从支付系统到商户端就比较简单了，在清算完成后支付系统负责将代收的资金结算给商户，通常结算的操作可以在线上来完成（采用支付公司代付接口或者银企直连接口来完成），也可以由公司财务通过线下手工转账的方式来完成，因此这种资金流动的方式是单向的。出于资金安全考虑，大多数公司通常这部分采用线下方式实现。 真实的资金流由支付公司按照约定期限（通常 T+1 ）结算到平台公司对公账户中，然后再由平台公司再按照交易明细进行二次清算后结算给对应的商户。 支付系统支付系统模块组成 完整的支付系统包括如下的功能 应用管理: 同时支持公司多个业务系统对接。 商户管理: 支持商户入驻，商户需要向平台方提供相关的资料备案。 渠道管理: 支持微信、支付宝、银联、京东支付等多种渠道。 账户管理: 渠道账户管理，支持共享账户（个人商户）及自有账户。 支付交易: 生成预支付订单、提供退款服务。 对账管理: 实现支付系统的交易数据与第三方支付渠道交易明细的自动核对（通常T+1），确保交易数据的准确性和一致性。 清算管理: 计算收款交易中商户的应收与支付系统收益。 结算管理: 根据清算结果，将资金划拨至商户对应的资金帐户中。 核心流程支付系统有几个关键的核心流程：支付流程、对账流程、结算流程 支付流程说明 用户在商城选购商品并发起支付请求； 商城将支付订单通过B2C网关收款接口传送至支付网关； 用户选择网银支付及银行，支付平台将订单转送至指定银行网关界面； 用户支付完成，银行处理结果并向平台返回处理结果； 支付平台接收处理结果，落地处理并向商户返回结果； 商城接收到支付公司返回结果，落地处理（更改订单状态）并通知用户。 一般而言支付系统会给商户设置有“可用余额”账户、“待结算”账户；系统在接收到银行返回支付成功信息会进行落地处理，一方面更改对应订单状态，另一方面在商户待结算账户记入一笔金额；该笔金额，系统会根据结算周期从待结算账户—&gt;“可用余额”账户。 退款流程说明 用户在商户平台发起退款申请，商户核实退款信息及申请； 商户登录支付平台账户/或者通过支付公司提供的退款接口向支付平台发起退款； 支付系统会对退款信息校验（退款订单对应的原订单是否支付成功？退款金额是否少于等于原订单金额？），校验商户账户余额是否充足等；校验不通过，则无法退款； 支付系统在商户可用余额账户扣除金额，并将退款订单发送至银行，银行完成退款操作。注意：对于网关收款的订单退款，各银行要求不一，有些银行提供的退款接口要求原订单有效期在90或180天，有些银行不提供退款接口；针对超期或者不支持接口退款的订单，支付公司通过代付通道完成退款操作。 对于收单金额未结算，还在“待结算”账户的订单，如果出现退款情况，业务流程和上述流程差不多，只是从待结算账户进行扣款。 对账说明​ 对账，我们一般称为勾兑，支付系统的对账，包含着两个层面： 支付系统内部间的对账，支付系统一般是分布式的，整个支付系统被拆分成了多个子系统，如交易系统、账户系统、会计系统、账户系统，每个子系统在处理各自的业务，系统间的对账，就是以上系统的核对，用于修正内部系统的数据不一致。 支付系统与渠道的对账，这里的渠道泛指所有为支付系统提供代收付业务的渠道，如：第三方支付公司、银行、清算中心、网联、银联等。 对账简易流程 支付系统与渠道间的对账系统间的对账比较好理解，这里主要讲支付系统与渠道间的对账。支付系统与渠道间的对账，又包含2个维度： 信息流勾对：即业务对账／交易对账，主要是就收单交易的支付信息与银行提供的信息流文件进行勾兑。信息流的勾地能发现支付系统与银行系统间的掉单、两边由于系统间的原因导致的同一笔交易支付金额不一致（可能性很小）或者支付状态不一致。信息流勾兑一般用来恢复掉单数据，可通过补单或者具体系统问题排查解决。 资金流勾对：即资金对账，主要就收单交易的支付信息与银行提供的资金流信息进行勾兑。资金流的勾兑能发现支付系统在银行的帐户资金实际发生的变动与应该发生的变动的差异，比如长款（银行多结算给支付系统）和短款（银行少结算给支付系统）。 说了这么多，就出现来4个对账文件，支付系统信息流文件、支付系统资金流文件、银行信息流文件、银行资金流文件。业务对账（勾兑）就是支付系统的信息流文件与银行的信息流文件勾兑，资金对账即支付系统的资金流文件与银行的资金流文件勾兑。 核对的差异处理1、信息流勾对的差异处理 支付系统信息流没有，而银行有的差异，可能是因为支付系统交易数据的丢失、银行的掉单，如果是银行的掉单，由支付公司的运营登录银行网银确认后，做补单处理，并将差异表中该记录核销。 支付系统信息流有，而银行没有的差异，此种情况一般不会发生，因为支付系统所有的交易数据都是取银行返回状态的数据。 2、资金流勾对对差异处理 支付系统资金流没有，而银行有的差异。可能原因如下：1、银行日切晚与支付系统核心账务系统；2、支付系统账务核心系统与其他系统间的掉单。一旦出现，则会出现长款（即银行不应该结算而实际结算）的现象，对于因日切导致的差异，在第二天的对账中系统会对平，其他原因的，需要技术排查。 支付系统资金流有，而银行没有的差异，可能是因为银行日切早于支付系统的核心账务系统，一旦出现，会出现短款（银行应结算而实际未结算）的现象，银行日切导致段差异，会在下一天与银行的勾对中，将此笔差异勾对上，如果是非日切导致的原因，就需要找银行追款了。 总结就是，业务对账，即信息流对账，支付系统的交易流水与银行的交易流水间核对，保障支付交易完整入账。资金对账，即资金流对账，支付系统的入账流水与银行的结算流水间核对，保障银行入账流水与实际入账资金的匹配。 结算结算流程 在清结算部分，系统按照设定好的清结算规则自动将钱款结算给商户。完善的运营会计体系帮助财务进行精细化核算，提高财务效率。与支付渠道自动进行对账，确保账务正确，在异常情况下能及时定位问题并处理。系统更是能对商户进行个性化的费率配置或账期配置，方便灵活。系统的价值不仅体现在支付清结算方面，同时更是提升了运营管理效率。支付清结算系统可以有效帮助运营、财务、开发以及管理人员。对于运营人员，系统可帮助处理平台的运营工作，包括各类支付管理，商户、会员管理，营销活动的数据统计等，全面提高运营效率。针对财务人员，可以协助完成资金对账、会计处理，出入款管理，账务差错处理等，大部分工作由系统自动处理，减少人工处理，提高资金处理效率。一套灵活便捷的配置后台供开发人员快速调整系统以适应新的业务，并能方便对系统进行维护，如渠道接入、费率配置、账期调整等，提高开发效率。系统提供资金流转过程中各个环节的数据，能够从各个维度进行核算和分析，形成对管理人员的决策支持，从而提高决策效率。 关键表设计 支付系统要点在支付系统中，支付网关和支付渠道的对接是最繁琐重要的功能之一，其中支付网关是对外提供服务的接口，所有需要渠道支持的资金操作都需要通过网关分发到对应的渠道模块上。一旦定型，后续就很少，也很难调整。而支付渠道模块是接收网关的请求，调用渠道接口执行真正的资金操作。每个渠道的接口，传输方式都不尽相同，所以在这里，支付网关相对于支付渠道模块的作用，类似设计模式中的wrapper，封装各个渠道的差异，对网关呈现统一的接口。而网关的功能是为业务提供通用接口，一些和渠道交互的公共操作，也会放置到网关中。 支付系统对其他系统，特别是交易系统，提供的支付服务包括签约，支付，退款，充值，转帐，解约等。有些地方还会额外提供签约并支付的接口，用于支持在支付过程中绑卡。 每个服务实现的流程也是基本类似，包括下单，取消订单，退单，查单等操作。每个操作实现，都包括参数校验，支付路由，生成订单，风险评估，调用渠道服务，更新订单和发送消息这7步，对于一些比较复杂的渠道服务，还会涉及到异步同通知处理的步骤。 网关前置支付网关前置是对接业务系统，为其提供支付服务的模块。它是所有支付服务接口的集成前置，将不同支付渠道提供的接口通过统一的方式呈现给业务方。这样接入方就只需要对接支付网关，增加和调整支付渠道对业务方是透明的。 支付网关前置的设计对整个支付系统的稳定性、功能、性能以及其他非功能性需求有着直接的影响。 在支付网关中需要完成大量的操作，为了保证性能，这些操作都尽量异步化来处理。支付网关前置应保持稳定，尽量减少系统重启等操作对业务方的影响。支付网关也避免不了升级和重启。这可通过基于Nginx的LBS(Load Balance System)网关来解决。LBS在这里有两个作用： 一个是实现负载均衡，一个是隔离支付网关重启对调用的影响。 支付网关也采用多台机器分布式部署，重启时，每个服务器逐个启动。某台服务器重启时，首先从LBS系统中取消注册，重启完成后，再重新注册到LBS上。这个过程对调用方是无感知的。 为了避免接口受攻击，在安全上，还得要求业务方通过HTTPS来访问接口，并提供防篡改机制。防篡改则通过接口参数签名来处理。现在主流的签名是对接口参数按照参数名称排序后，做加密和散列，参考微信的签名规范。 参数校验 所有的支付操作，都需要对输入执行参数校验，避免接口受到攻击。 验证输入参数中各字段的有效性验证，比如用户ID,商户ID,价格，返回地址等参数。 验证账户状态。交易主体、交易对手等账户的状态是处于可交易的状态。 验证订单：如果涉及到预单，还需要验证订单号的有效性，订单状态是未支付。为了避免用户缓存某个URL地址，还需要校验下单时间和支付时间是否超过预定的间隔。 验证签名。签名也是为了防止支付接口被伪造。 一般签名是使用分发给商户的key来对输入参数拼接成的字符串做MD5 Hash或者RSA加密，然后作为一个参数随其他参数一起提交到服务器端。 路由选择根据用户选择的支付方式确定用来完成该操作的合适的支付渠道。用户指定的支付方式不一定是最终的执行支付的渠道。比如用户选择通过工行信用卡来执行支付，但是我们没有实现和工行的对接，而是可以通过第三方支付，比如支付宝、微信支付、易宝支付，或者银联来完成。那如何选择合适的支付渠道，就通过支付路由来实现。支付路由会综合考虑收费、渠道的可用性等因素来选择最优方案 风险评估检查本次交易是否有风险。风控接口返回三种结果：阻断交易、增强验证和放行交易。 阻断交易，说明该交易是高风险的，需要终止，不执行第5个步骤； 增强验证，说明该交易有一定的风险，需要确认下是不是用户本人在操作。这可以通过发送短信验证码或者其他可以验证用户身份的方式来做校验，验证通过后，可以继续执行该交易。 放行交易，即本次交易是安全的，可以继续往下走。 发送消息通过消息来通知相关系统关于订单的变更。风控，信用BI等，都需要依赖这数据做准实时计算。 更新订单对于同步返回的结果，需要在主线程中更新订单的状态，标记是支付成功还是失败。对于异步返回的渠道，需要在异步程序中处理。 异步通知其中涉及到调用远程接口，其延迟不可控。如果调用方一直阻塞等待，很容易超时。引入异步通知机制，可以让调用方在主线程中尽快返回，通过异步线程来得到支付结果。对于通过异步来获取支付结果的渠道接口，也需要对应的在异步通知中将结果返回给调用方。 异步通知需要调用方提供一个回调地址，一般以http或者https的方式。这就有技术风险，如果调用失败，还需要重试。而重试不能过于频繁，需要逐步拉大每一次重试的时间间隔。 在异步处理程序中，订单根据处理结果变更状态后，也要发消息通知相关系统。 生成交易订单将订单信息持久化到数据库中。当访问压力大的时候，数据库写入会成为一个瓶颈。 交易流水和记账每一笔交易都需要记录流水，并登记到个人和机构的分户账户上，统计和分析也需要根据交易流水来更新相关数据。 而个人和机构账户总额更新、交易流水记录以及库存的处理，更是需要事务处理机制的支持。 从性能角度， 可以弱化了事务处理的要求，采用消息机制来异步化和交易相关的数据处理。 在支付网关前置的主流程中，仅记录交易流水，即将当前的请求保存到数据库中。 完成数据记录后，发送MQ出来，记账、统计、分析，都是接收MQ来完成数据处理。 涉及到本地资金支付，比如钱包支付，会需要分布式事务处理，扣减账号余额，记账，扣减库存等，每个操作失败，都要回滚。阿里有很不错的分享，这里不详细描述。 当交易量上来后，需要考虑交易表的分表分库的事情。分表分库有两个策略，按照流水号或者交易主体id来走。后者可以支持按用户来获取交易记录。我们用的是前者。后者可以走elastic，确保数据库专用。风控，信用和统计所需要的数据，通过MQ同步到历史库里面。作为支付系统最有价值的数据，在存储上做到专库专用，无可厚非，毕竟存储成本还是廉价的。 支付路由支付路由是一个复杂的话题。对支付系统来说，能支持的支付方式越多越好，不能由于支付方式的不支持断了财路。现实中的支付方式多得难以置信。用户随时甩出一张你听都没听说过的卡。如果一个银行卡只有几个用户在用，那针对这个卡开发个对接有点得不尝失。现在第三方支付的爆发，确实给开发支付系统省了不少事。但是公司不可能只对接一个第三方支付，如果这个渠道出问题了，或者闹矛盾了，把链接给掐了，老板还不欲哭无泪。总之，得对接多个渠道。对于交易量大的银行，还得考虑直联。 渠道接入对于支付渠道，首先考虑的是接入哪些渠道。要对接的渠道按优先级有： 第三方支付，对大部分应用来说，支付宝和微信支付都是必须的，一般来说，这两者可以占到90%以上的交易量。用户不需要绑卡，授权后直接支付就行。各种平台都支持，性能和稳定性都不错。对于一些特殊业务，比如游戏，企业支付，可以查看一些专用的第三方支付平台。 银联，它的存在，极大方便了和银行的对接。和第三方支付主要不同在两个地方一是需要绑卡，也就是用户先把卡号，手机，身份证号提供出来。这一步会折损不少用户。绑卡后，以后的支付操作就简单了，用户只需要输入密码就行。手机客户端不需要像第三方支付那样安装SDK，都在服务器端完成。当然，这是针对快捷支付。网银支付还是挺麻烦的。银联接入也需要ADSS认证。 银行：2018年2月9日银监会公布了最新权威数字：一共【4549家】开发性金融机构1家：国家开发银行；政策性银行2家：进出口银行、农业发展银行；5大国有银行：工、建、农、中、交；邮储银行1家；全国性股份制商业银行12家：招行、中信、兴业、民生、浦发、光大、广发、华夏、平安、浙商、渤海、恒丰；金融资产管理公司4家：信达、华融、长城、东方四大AMC；城商行134家；住房储蓄银行1家；民营银行17家，如网商银行；农商行1262家；农村合作银行33家；农村信用社965家；村镇银行1562家；贷款公司13家；农村资金互助社48家；外资法人银行39家；信托公司68家；金融租赁公司69家；企业集团财务公司247家；汽车金融公司25家；消费金融公司22家；货币经纪公司5家；其他金融机构14家。一般对接一个银行预计有3周左右的工作量，大部分银行需要专线接入，费用和带宽有关，一年也得几万费用。不同银行对接入环境有不同要求，这也是成本。 手机支付：比如苹果的In-App支付， 三星支付、华为支付等， 这些支付仅针对特定的手机型号， 支持NFC等，根据业务需要也可以接入。 总结支付系统是一个繁杂的系统，其中涉及了各种错综复杂的业务流程，以上只是简单介绍了支付系统我们能看见的一些问题和设计，还有后续的系统保障没有写出来，没写出来的才是关键部分，比如：支付系统监控（业务监控分类、渠道监控、商户监控、账户监控）文章只是引子， 架构不是静态的，而是动态演化的。只有能够不断应对环境变化的系统，才是有生命力的系统。所以即使你掌握了以上所有的业务细节，仍然需要演化式思维，在设计的同时，借助反馈和进化的力量推动架构的持续演进。 原文转载自","link":"/2018/12/01/支付系统设计-转载.html"},{"title":"Java设计模式之装饰者模式","text":"问题引入咖啡店的类设计： 一个饮料基类，各种饮料类继承这个基类，并且计算各自的价钱。 饮料中需要加入各种调料，考虑在基类中加入一些布尔值变量代表是否加入各种调料，基类的cost()中的计算各种调料的价钱，子类覆盖cost()，并且在其中调用超类的cost()，加上特定饮料的价钱，计算出子类特定饮料的价钱。 缺点：类数量爆炸、基类加入的新功能并不适用于所有的子类、调料价钱的改变、新调料的出现都会要求改变现有代码；有的子类并不适合某些调料等情况…… 设计原则 类应该对扩展开放，对修改关闭。 我们的目标是允许类容易扩展，在不修改现有代码的情况下，就可搭配新的行为。 如能实现这样的目标，有什么好处呢？这样的设计具有弹性可以应对改变，可以接受新的功能来应对改变的需求。 要让OO设计同时具备开放性和关闭性，不是一件容易的事，通常来说，没有必要把设计的每个部分都这么设计。 遵循开放-关闭原则，通常会引入新的抽象层次，增加代码的复杂度。 我们需要把注意力集中在设计中最有可能改变的地方，然后应用开放-关闭原则。 用装饰者模式解决问题解决咖啡店饮料问题的方法： 以饮料为主体，然后在运行时以调料来“装饰”饮料。 比如，顾客想要摩卡（Mocha）和奶泡（Whip）深焙咖啡（DarkRoast）： DarkRoast继承自Beverage，有一个cost()方法。 第一步，以DarkRoast对象开始； 第二步，顾客想要摩卡，所以建立一个Mocha装饰者对象，并用它将DarkRoast对象包装（wrap）起来； 第三步，顾客想要奶泡，所以建立一个Whip装饰者对象，并用它将Mocha对象包起来；（Mocha和Whip也继承自Beverage，有一个cost()方法）； 最后，为顾客算钱，通过调用最外圈装饰者（Whip）的cost()就可以。Whip()的cost()会先委托它装饰的对象（Mocha）计算出价钱，然后在加上奶泡的价钱。Mocha的cost()也是类似。 装饰者模式的特点 装饰者和被装饰对象有相同的超类型。 可以用一个或多个装饰者包装一个对象。 因为装饰者和被装饰者具有相同的类型，所以任何需要原始对象的场合，可以用装饰过的对象代替。 装饰者可以在所委托被装饰者的行为之前与/或之后，加上自己的行为，以达到特定的目的。 对象可以在任何时候被装饰，所以可以在运行时动态地、不限量地用你喜欢的装饰者来装饰对象。 装饰者模式的定义装饰者模式动态地将责任附加到对象上。若要扩展功能，装饰者提供了比继承更有弹性的替代方案。 装饰者模式的实现实现类图 装饰者和被装饰者具有共同的超类，利用继承达到“类型匹配”，而不是利用继承获得“行为”；将装饰者和被装饰者组合时，加入新的行为。 实现Java代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133// 抽象饮料类(抽象组件)public abstract class Beverage { String description = \"Unkown Beverage\"; public String getDescription() { return description; } /** * 抽象价格计算方法 * @return */ public abstract double cost();}// 浓缩饮料public class Espresso extends Beverage { public Espresso() { description = \"Espresso\"; } @Override public double cost() { return 1.99; }}// 又一饮料public class HouseBlend extends Beverage { public HouseBlend() { description = \"House Blend\"; } @Override public double cost() { return .20; }}// 抽象装饰者类public abstract class CondimentDecorator extends Beverage { /** * 为了后面的调料都能够获取到自己调料的描述 */ public abstract String getDescription();}/** * @desc Mocha调料(具体装饰者) */public class Mocha extends CondimentDecorator { Beverage beverage; public Mocha(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + \",Mocha\"; } @Override public double cost() { return .20 + beverage.cost(); }}/** * @desc Soy调料(具体装饰者) */public class Soy extends CondimentDecorator { Beverage beverage; public Soy(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + \",Soy\"; } @Override public double cost() { return .60 + beverage.cost(); }}/** * @desc Whip调料(具体装饰者) */public class Whip extends CondimentDecorator { Beverage beverage; public Whip(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + \",Whip\"; } @Override public double cost() { return .40 + beverage.cost(); }}/** * @desc 测试装饰者模式 */public class MainTest { public static void main(String[] args) { // 创建一种调料 Beverage beverage = new Espresso(); // 描述和价格 System.out.println(beverage.getDescription() + \" $\" + beverage.cost()); Beverage beverage1 = new HouseBlend(); beverage1 = new Mocha(beverage1); beverage1 = new Whip(beverage1); beverage1 = new Soy(beverage1); System.out.println(beverage1.getDescription() + \" $\" + beverage1.cost()); Beverage beverage2 = new Espresso(); beverage2 = new Mocha(beverage2); beverage2 = new Whip(beverage2); beverage2 = new Soy(beverage2); beverage2 = new Mocha(beverage2); System.out.println(beverage2.getDescription() + \" $\" + beverage2.cost()); }} 测试结果 装饰者和被装饰者具有共同的超类，利用继承达到“类型匹配”，而不是利用继承获得“行为”；将装饰者和被装饰者组合时，加入新的行为。 解决本文中饮料的具体问题时，图中Component即为Beverage（可以是抽象类或者接口），而ConcreteComponent为各种饮料，Decorator（抽象装饰者）为调料的抽象类或接口，ConcreteDecoratorX则为各种具体的调料。 因为使用对象组合，可以把饮料和调料更有弹性地加以混合与匹配。 代码外部细节： 代码中实现的时候，通过构造函数将被装饰者传入装饰者中即可，如最后的调用形式如下： 123Beverage beverage = new DarkRoast();beverage = new Mocha(beverage);beverage = new Whip(beverage); 即完成了两层包装，此时再调用beverage的cost()函数即可得到总价。 java.io包内的装饰者模式 装饰者模式的缺点：在设计中加入大量的小类，如果过度使用，会让程序变得复杂。 参考：http://www.cnblogs.com/mengdd/archive/2013/01/03/2843439.html","link":"/2018/11/29/Java设计模式之装饰者模式.html"},{"title":"Java设计模式之工厂模式","text":"工厂模式序言工厂模式在《Java与模式》中分为三类： 简单工厂模式（Simple Factory）：不利于产生系列产品； 工厂方法模式（Factory Method）：又称为多形性工厂； 抽象工厂模式（Abstract Factory）：又称为工具箱，产生产品族，但不利于产生新的产品； 这三种模式从上到下逐步抽象，并且更具一般性。GOF在《设计模式》一书中将工厂模式分为两类：工厂方法模式（Factory Method）与抽象工厂模式（Abstract Factory）。将简单工厂模式（Simple Factory）看为工厂方法模式的一种特例，两者归为一类。 简单工厂模式 简单工厂模式又称静态工厂方法模式。从命名上就可以看出这个模式一定很简单。它存在的目的很简单：定义一个用于创建对象的接口。在简单工厂模式中,一个工厂类处于对产品类实例化调用的中心位置上,它决定那一个产品类应当被实例化, 如同一个交通警察站在来往的车辆流中,决定放行那一个方向的车辆向那一个方向流动一样。 组成角色： 工厂类角色：这是本模式的核心，含有一定的商业逻辑和判断逻辑。在java中它往往由一个具体类实现。 抽象产品角色：它一般是具体产品继承的父类或者实现的接口。在java中由接口或者抽象类来实现。 具体产品角色：工厂类所创建的对象就是此角色的实例。在java中由一个具体类实现。 简单工厂模式的UML图 简单工厂模式的Java代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 抽象接口 人类public interface Human { public void say();}// 男人public class Man implements Human { @Override public void say() { System.out.println(\"男人\"); }}// 女人public class Woman implements Human { @Override public void say() { System.out.println(\"女人\"); }}// 简单工厂public class SampleFactory { public static Human makeHuman(String type){ if(type.equals(\"man\")){ Human man = new Man(); return man; }else if(type.equals(\"womman\")){ Human woman = new Woman(); return woman; }else{ System.out.println(\"生产不出来\"); return null; } }}// 简单工厂模式反射实现public class SampleFactory1 { public static Human makeHuman(Class c){ Human human = null; try { human = (Human) Class.forName(c.getName()).newInstance(); } catch (InstantiationException e) { // TODO Auto-generated catch block System.out.println(\"不支持抽象类或接口\"); e.printStackTrace(); } catch (IllegalAccessException e) { // TODO Auto-generated catch block e.printStackTrace(); System.out.println(\"没有足够权限，即不能访问私有对象\"); } catch (ClassNotFoundException e) { // TODO Auto-generated catch block System.out.println(\"类不存在\"); e.printStackTrace(); } return human; }}// 简单工厂测试public class Client { public static void main(String[] args) { Human man = SampleFactory.makeHuman(\"man\"); man.say(); Human womman = SampleFactory.makeHuman(\"womman\"); womman.say(); Human test = SampleFactory.makeHuman(\"tttt\"); Human man = SampleFactory1.makeHuman(Man.class); man.say(); Human woman = SampleFactory1.makeHuman(Woman.class); woman.say(); }} 优缺点： 优点：工厂类是整个模式的关键.包含了必要的逻辑判断,根据外界给定的信息,决定究竟应该创建哪个具体类的对象.通过使用工厂类,外界可以从直接创建具体产品对象的尴尬局面摆脱出来,仅仅需要负责“消费”对象就可以了。而不必管这些对象究竟如何创建及如何组织的．明确了各自的职责和权利，有利于整个软件体系结构的优化。 缺点：由于工厂类集中了所有实例的创建逻辑，违反了高内聚责任分配原则，将全部创建逻辑集中到了一个工厂类中；它所能创建的类只能是事先考虑到的，如果需要添加新的类，则就需要改变工厂类了。当系统中的具体产品类不断增多时候，可能会出现要求工厂类根据不同条件创建不同实例的需求．这种对条件的判断和对具体产品类型的判断交错在一起，很难避免模块功能的蔓延，对系统的维护和扩展非常不利； 工厂方法模式 工厂方法模式是简单工厂模式的进一步抽象化和推广，工厂方法模式里不再只由一个工厂类决定那一个产品类应当被实例化,这个决定被交给抽象工厂的子类去做。 组成角色： 抽象工厂角色： 这是工厂方法模式的核心，它与应用程序无关。是具体工厂角色必须实现的接口或者必须继承的父类。在java中它由抽象类或者接口来实现。 具体工厂角色：它含有和具体业务逻辑有关的代码。由应用程序调用以创建对应的具体产品的对象。 抽象产品角色：它是具体产品继承的父类或者是实现的接口。在java中一般有抽象类或者接口来实现。 具体产品角色：具体工厂角色所创建的对象就是此角色的实例。在java中由具体的类来实现。 工厂方法模式使用继承自抽象工厂角色的多个子类来代替简单工厂模式中的“上帝类”。正如上面所说，这样便分担了对象承受的压力；而且这样使得结构变得灵活 起来——当有新的产品（即暴发户的汽车）产生时，只要按照抽象产品角色、抽象工厂角色提供的合同来生成，那么就可以被客户使用，而不必去修改任何已有的代 码。可以看出工厂角色的结构也是符合开闭原则的！ 工厂方法模式Java代码1234567891011121314151617181920212223242526272829303132333435363738394041424344//抽象产品角色public interface Moveable { void run();}//具体产品角色public class Plane implements Moveable { @Override public void run() { System.out.println(\"plane....\"); }}public class Broom implements Moveable { @Override public void run() { System.out.println(\"broom.....\"); }}//抽象工厂public abstract class VehicleFactory { abstract Moveable create();}//具体工厂public class PlaneFactory extends VehicleFactory{ public Moveable create() { return new Plane(); }}public class BroomFactory extends VehicleFactory{ public Moveable create() { return new Broom(); }}//测试类public class Test { public static void main(String[] args) { VehicleFactory factory = new BroomFactory(); Moveable m = factory.create(); m.run(); }} 可以看出工厂方法的加入，使得对象的数量成倍增长。当产品种类非常多时，会出现大量的与之对应的工厂对象，这不是我们所希望的。因为如果不能避免这种情 况，可以考虑使用简单工厂模式与工厂方法模式相结合的方式来减少工厂类：即对于产品树上类似的种类（一般是树的叶子中互为兄弟的）使用简单工厂模式来实 现。 简单工厂和工厂方法模式的比较 工厂方法模式和简单工厂模式在定义上的不同是很明显的。工厂方法模式的核心是一个抽象工厂类,而不像简单工厂模式, 把核心放在一个实类上。工厂方法模式可以允许很多实的工厂类从抽象工厂类继承下来, 从而可以在实际上成为多个简单工厂模式的综合,从而推广了简单工厂模式。 反过来讲,简单工厂模式是由工厂方法模式退化而来。设想如果我们非常确定一个系统只需要一个实的工厂类, 那么就不妨把抽象工厂类合并到实的工厂类中去。而这样一来,我们就退化到简单工厂模式了。 抽象工厂模式1234567891011121314151617181920212223242526272829303132333435//抽象工厂类public abstract class AbstractFactory { public abstract Vehicle createVehicle(); public abstract Weapon createWeapon(); public abstract Food createFood();}//具体工厂类，其中Food,Vehicle，Weapon是抽象类，public class DefaultFactory extends AbstractFactory{ @Override public Food createFood() { return new Apple(); } @Override public Vehicle createVehicle() { return new Car(); } @Override public Weapon createWeapon() { return new AK47(); }}//测试类public class Test { public static void main(String[] args) { AbstractFactory f = new DefaultFactory(); Vehicle v = f.createVehicle(); v.run(); Weapon w = f.createWeapon(); w.shoot(); Food a = f.createFood(); a.printName(); }} 在抽象工厂模式中，抽象产品 (AbstractProduct) 可能是一个或多个，从而构成一个或多个产品族(Product Family)。 在只有一个产品族的情况下，抽象工厂模式实际上退化到工厂方法模式。 总结 简单工厂模式是由一个具体的类去创建其他类的实例，父类是相同的，父类是具体的。 工厂方法模式是有一个抽象的父类定义公共接口，子类负责生成具体的对象，这样做的目的是将类的实例化操作延迟到子类中完成。 抽象工厂模式提供一个创建一系列相关或相互依赖对象的接口，而无须指定他们具体的类。它针对的是有多个产品的等级结构。而工厂方法模式针对的是一个产品的等级结构。 参考：http://www.cnblogs.com/liaoweipeng/p/5768197.html http://www.cnblogs.com/forlina/archive/2011/06/21/2086114.html","link":"/2018/11/24/Java设计模式之工厂模式.html"},{"title":"Effective-Java-2-遇到多个构造器参数时考虑用构建器","text":"遇到多个构造器参数时考虑用构建器静态工厂和构造器有个共同的局限性：它们都不能很好地扩展到大量的可选参数。当有超过20个可选域是必须的时候，对于此种情况，程序员一般考虑采用重叠构造器模式。这种模式下，提供第一个只有必要参数的构造器，第二个构造器有一个可选参数，第三个有两个可选参数，以此类推，最后一个构造器包含所有的参数。 重叠构造器模式 含有四个可选域的情况 1234567891011121314151617181920212223242526272829public class NutritionFacts{ private final int servingSize; // required private final int servings; // required private final int calories; // optional private final int fat; // optional private final int sodium; // optional private final int carbohydrate; // optional public NutritionFacts(int servingSize, int servings){ this(servingSize, servings, 0); } public NutritionFacts(int servingSize, int servings, int calories){ this(servingSize, servings, calories, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat){ this(servingSize, servings, calories, fat, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat, int sodium){ this(servingSize, servings, calories, fat, sodium, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat, int sodium, int carbohydrate){ this(servingSize, servings, calories, fat, sodium, carbohydrate); } } 当你想创建实例的时候，就利用参数列表最短的构造器。 重叠构造器模式可行，但是当有许多参数的时候，客户端代码会很难编写，并且较难阅读，使用的时候容易混淆部分参数容易出错 JavaBeans模式这种模式调用一个无参构造器来创建对象，然后用setter方法来设置必要的参数以及相关参数的值。 12345678910111213141516171819public class NutritionFacts { private int servingSize = -1; // required private int servings = -1; // required private int calories = 0; // optional private int fat = 0; // optional private int sodium = 0; // optional private int carbohydrate = 0; // optional public NutritionFacts(){ } public void setServingSize(int val) { servingSize = val; } public void setServings(int val) { servings = val; } public void setCalories(int val) { calories = val; } public void setFat(int val) { fat = val; } public void setSodium(int val) { sodium = val; } public void setCarbohydrate(int val) { carbohydrate = val; }} 这种方式弥补了重叠构造器模式的不足，创建实例容易，阅读代码也容易。 12345NutritionFacts cocaCola = new NutritionFacts();cocaCola.setServingSize(10);cocaCola.setServings(10);cocaCola.setCalories(10);cocaCola.setFat(10); 遗憾的是自身有严重的缺陷。构造过程被分到了几个调用中，构造过程中JavaBean可能处于不一致状态的对象，将会导致失败。类无法仅仅通难过校验构造器参数的有效性来保证一致性，Javabeans模式阻止了把类做成不可变的可能，需要付出额外的努力来确保它的线程安全。 Builder模式既能保证像重叠构造器模式那样的安全性，也能保证像JavaBeans模式那样的可读性。 不直接生成想要的对象，而是让客户端利用所有必要的参数调用构造器（或静态工厂），得到一个builder对象。然后客户端在builder对象上调用类似于setter的方法，来设置每个相关的可选参数。最后，客户端调用无参的build方法来生成不可变的对象，这个builder是它构建的类的静态成员类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class NutritionFacts{ private final int servingSize; // required private final int servings; // required private final int calories; // optional private final int fat; // optional private final int sodium; // optional private final int carbohydrate; // optional public static class Builder{ private final int servingSize; // required private final int servings; // required private final int calories = 0; // optional private final int fat = 0; // optional private final int sodium = 0; // optional private final int carbohydrate = 0; // optional public Builder(int servingSize, int servings){ this.servingSize = servingSize; this.servings =servings; } public Builder calories(int val){ calories = val; return this; } public Builder fat(int val){ fat = val; return this; } public Builder sodium(int val){ sodium = val; return this; } public Builder carbohydrate(int val){ carbohydrate = val; return this; } public NutritionFacts build(){ return new NutritionFacts(this); } } private NutritionFacts(Builder builder){ servingSize = builder.servingSize; servings = builder.servingSize; calories = builder.servingSize; fat = builder.servingSize; sodium = builder.servingSize; carbohydrate = builder.servingSize; }} 注意NutritionFacts是不可变的，所有的默认参数值都单独放一个地方。builder的setter方法返回builder本身，以便可以把调用用调用链连接起来。 1NutritionFacts cocaCola = new NutritionFacts.Builder(200,20).calories(10).fat(15).sodium(10).build(); builder像个构造器一样，可以对其参数强加约束条件。build方法可以检验这些约束条件，将参数从builder拷贝到对象中之后，并在对象域而不是builder域中对他们进行校验，这一点很重要。如果违反了任何约束条件，build方法就应该抛出IllegalStateException,显示违背了哪个约束条件。 对多个参数强加约束条件的另一个方法，用多个setter方法对某个约束条件必须持有的所有参数进行检查。如果该约束条件没有得到满足，setter方法就抛出IllegalStateException，不用等到在build的时候。 设置了参数的builder生成了一个很好的抽象工厂，客户端可以将这样一个builder传给方法，使该方法能够为客户端创建一个或者多个对象。要使用这种用法，需要有个类型来表示builder，只要一个泛型就能满足所有的builder，无论他们在构建哪种类型的对象： 123public interface Builder&lt;T&gt;{ public T build();} 可以声明NutritionFacts.Builder类来实现Builder&lt;NutritionFacts&gt; 。 带有Builder实例的方法通常利用有限制的通配符类型来约束构建器的类型参数。eg.下面就是构建每个节点的方法，它利用一个客户端提供的Builder实例来构建树： 1Tree buildTree(Builder&lt;? extends Node&gt; nodeBuilder){ ... } **Builder模式还比重叠构造器模式更加冗长，因此它只有在很难参数的时候才使用，比如4个或者更多。但是你要记住，将来可能添加参数。简而言之，如果类的构造器或者静态工厂中具有多个参数，设计这种类时，Builder模式就是种不错的选择，特别是大多参数都是可选的时候。代码易于阅读编写，构建器也比JavaBeans更加安全。","link":"/2018/11/17/Effective-Java-2-遇到多个构造器参数时考虑用构建器.html"},{"title":"Java设计模式之单例模式","text":"单例模式 确保一个类只有一个实例，并提供一个全局访问点！ 饿汉式：线程安全，但效率比较低 123456789101112131415161718/** * 单例模式的实现：饿汉式,线程安全 但效率比较低 */ public class SingletonTest { // 定义一个私有的构造方法 private SingletonTest() { } // 将自身的实例对象设置为一个属性,并加上Static和final修饰符 private static final SingletonTest instance = new SingletonTest(); // 静态方法返回该类的实例 public static SingletonTest getInstancei() { return instance; } } 单例模式的实现：饱汉式，非线程安全12345678910111213141516171819/** * 单例模式的实现：饱汉式,非线程安全 * */ public class SingletonTest { // 定义私有构造方法（防止通过 new SingletonTest()去实例化） private SingletonTest() { } // 定义一个SingletonTest类型的变量（不初始化，注意这里没有使用final关键字） private static SingletonTest instance; // 定义一个静态的方法（调用时再初始化SingletonTest，但是多线程访问时，可能造成重复初始化问题） public static SingletonTest getInstance() { if (instance == null) instance = new SingletonTest(); return instance; } } 饱汉式，线程安全简单实现1234567891011121314151617181920/** * 单例模式的实现：饱汉式,线程安全简单实现 * */ public class SingletonTest { // 定义私有构造方法（防止通过 new SingletonTest()去实例化） private SingletonTest() { } // 定义一个SingletonTest类型的变量（不初始化，注意这里没有使用final关键字） private static SingletonTest instance; // 定义一个静态的方法（调用时再初始化SingletonTest，使用synchronized 避免多线程访问时，可能造成重的复初始化问题） public static synchronized SingletonTest getInstance() { if (instance == null) instance = new SingletonTest(); return instance; } } 双重锁机制：线程安全，效率高，单例模式最优方案12345678910111213141516171819202122232425262728/** * 单例模式最优方案 * 线程安全 并且效率高 * */ public class SingletonTest { // 定义一个私有构造方法 private SingletonTest() { } //定义一个静态私有变量(不初始化，不使用final关键字，使用volatile保证了多线程访问时instance变量的可见性，避免了instance初始化时其他变量属性还没赋值完时，被另外线程调用) private static volatile SingletonTest instance; //定义一个共有的静态方法，返回该类型实例 public static SingletonTest getIstance() { // 对象实例化时与否判断（不使用同步代码块，instance不等于null时，直接返回对象，提高运行效率） if (instance == null) { //同步代码块（对象未初始化时，使用同步代码块，保证多线程访问时对象在第一次创建后，不再重复被创建） synchronized (SingletonTest.class) { //未初始化，则初始instance变量 if (instance == null) { instance = new SingletonTest(); } } } return instance; } } 静态内部类方式12345678910111213/** * 静态内部类方式 * */ public class Singleton { private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } private Singleton (){} public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } } 这种方式同样利用了classloder的机制来保证初始化instance时只有一个线程，它跟第三种和第四种方式不同的是（很细微的差别）：第三种和第四种方式是只要Singleton类被装载了，那么instance就会被实例化（没有达到lazy loading效果），而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance。想象一下，如果实例化instance很消耗资源，我想让他延迟加载，另外一方面，我不希望在Singleton类加载时就实例化，因为我不能确保Singleton类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化instance显然是不合适的。这个时候，这种方式相比第三和第四种方式就显得很合理。 总结【以上单例模式】传统的两私有一公开（私有构造方法、私有静态实例(懒实例化/直接实例化)、公开的静态获取方法）涉及线程安全问题（即使有多重检查锁也可以通过反射破坏单例）目前最为安全的实现单例的方法是通过内部静态enum的方法来实现，因为JVM会保证enum不能被反射并且构造器方法只执行一次。 利用反射模式获取1234567891011121314151617181920212223242526272829303132333435363738// 饿汉试单例模式public class HelloWorld { private HelloWorld(){}; private static HelloWorld hell = new HelloWorld(); public static HelloWorld getHello(){ return hell; } public void getWorld(){ System.out.println(\"hahahahah\"); }}// java反射机制 调用getWorld()方法public class HelloJava{ public static void main(String[] args){ /* HelloWorld hell = HelloWorld.getHello(); hell.getWorld(); */ try { Class class1 = Class.forName(\"cn.jr.text.HelloWorld\"); Constructor[] constructors = class1.getDeclaredConstructors(); AccessibleObject.setAccessible(constructors, true); for (Constructor con : constructors) { if (con.isAccessible()) { Object classObject = con.newInstance(); Method method = class1.getMethod(\"getWorld\"); method.invoke(classObject); } } } catch (Exception e) { e.printStackTrace(); } }} 使用枚举的单例模式123456789101112131415161718public class EnumSingleton{ private EnumSingleton(){} public static EnumSingleton getInstance(){ return Singleton.INSTANCE.getInstance(); } private static enum Singleton{ INSTANCE; private EnumSingleton singleton; //JVM会保证此方法绝对只调用一次 private Singleton(){ singleton = new EnumSingleton(); } public EnumSingleton getInstance(){ return singleton; } }} 使用枚举，static处调用，初始化一次1234567891011121314151617181920212223public class StaticInitTest { private static List&lt;Integer&gt; dataList = null; static{ dataList = Singleton.INSTANCE.init(); } private static enum Singleton { INSTANCE; private List&lt;Integer&gt; list; private Singleton(){ fillData(); } private void fillData(){ list = new ArrayList&lt;Integer&gt;(5); for(int i =1; i&lt;6; i++){ list.add(i); } } public List&lt;Integer&gt; init(){ return list; } }} 借助CAS（AtomicReference）实现单例模式：12345678910111213141516171819public class Singleton { private static final AtomicReference&lt;Singleton&gt; INSTANCE = new AtomicReference&lt;Singleton&gt;(); private Singleton() {} public static Singleton getInstance() { for (;;) { Singleton singleton = INSTANCE.get(); if (null != singleton) { return singleton; } singleton = new Singleton(); if (INSTANCE.compareAndSet(null, singleton)) { return singleton; } } }} 用CAS的好处在于不需要使用传统的锁机制来保证线程安全,CAS是一种基于忙等待的算法,依赖底层硬件的实现,相对于锁它没有线程切换和阻塞的额外消耗,可以支持较大的并行度。使用CAS实现单例只是个思路而已，只是拓展一下帮助读者熟练掌握CAS以及单例等知识、千万不要在代码中使用！！！这个代码其实有很大的优化空间。聪明的你，知道以上代码存在哪些隐患吗？ 最终总结有两个问题需要注意： 如果单例由不同的类装载器装入，那便有可能存在多个单例类的实例。假定不是远端存取，例如一些servlet容器对每个servlet使用完全不同的类 装载器，这样的话如果有两个servlet访问一个单例类，它们就都会有各自的实例。 如果Singleton实现了java.io.Serializable接口，那么这个类的实例就可能被序列化和复原。不管怎样，如果你序列化一个单例类的对象，接下来复原多个那个对象，那你就会有多个单例类的实例。 对第一个问题修复的办法是： 123456789private static Class getClass(String classname) throws ClassNotFoundException { ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); if(classLoader == null) classLoader = Singleton.class.getClassLoader(); return (classLoader.loadClass(classname)); } } 对第二个问题修复的办法是： 12345678910public class Singleton implements java.io.Serializable { public static Singleton INSTANCE = new Singleton(); protected Singleton() { } private Object readResolve() { return INSTANCE; } } 对我来说，我比较喜欢第a和e种方式，简单易懂，而且在JVM层实现了线程安全（如果不是多个类加载器环境），一般的情况下，我会使用第a种方式，只有在要明确实现lazy loading效果时才会使用第e种方式，另外，如果涉及到反序列化创建对象时我会试着使用枚举的方式来实现单例，不过，我一直会保证我的程序是线程安全的，如果有其他特殊的需求，我可能会使用第七种方式，毕竟，JDK1.5已经没有双重检查锁定的问题了。 参考资料：java单例之enum实现方式 设计模式 java设计模式–单例模式","link":"/2018/11/17/Java设计模式之单例模式.html"},{"title":"leetcode-2-Add Two Numbers","text":"Add Two Numbers You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Example:Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) Output: 7 -&gt; 0 -&gt; 8 Explanation: 342 + 465 = 807. common 1234567891011121314151617181920212223242526272829/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode dummyHead = new ListNode(0); // 一点要赋值一个节点，进行操作 ListNode p = l1, q = l2, curr = dummyHead; int carry = 0; while (p != null || q != null) { int x = (p != null) ? p.val : 0; int y = (q != null) ? q.val : 0; int sum = carry + x + y; carry = sum / 10; curr.next = new ListNode(sum % 10); curr = curr.next; if (p != null) p = p.next; if (q != null) q = q.next; } if (carry &gt; 0) { curr.next = new ListNode(carry); } return dummyHead.next; }} best123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode head = new ListNode(0); int carry = 0; while(l1!=null||l2!=null||carry&gt;0) { ListNode itr = head; while(itr.next!=null) itr = itr.next; // 寻找最后一个节点 int sum = ( (l1==null ? 0 : l1.val) + (l2==null ? 0 : l2.val) + carry); carry = sum/10; ListNode temp = new ListNode(sum%10); itr.next = temp; if(l1!=null) l1 = l1.next; if(l2!=null) l2 = l2.next; } return head.next; }}","link":"/2018/11/16/leetcode-2-Add-Two-Numbers.html"},{"title":"Java设计模式之观察者模式","text":"定义 在阎宏博士的《JAVA与模式》一书中开头是这样描述观察者（Observer）模式的：观察者模式是对象的行为模式，又叫发布-订阅(Publish/Subscribe)模式、模型-视图(Model/View)模式、源-监听器(Source/Listener)模式或从属者(Dependents)模式。观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态上发生变化时，会通知所有观察者对象，使它们能够自动更新自己。 推结构模式推模式相关结构说明一个软件系统里面包含了各种对象，就像一片欣欣向荣的森林充满了各种生物一样。在一片森林中，各种生物彼此依赖和约束，形成一个个生物链。一种生物的状态变化会造成其他一些生物的相应行动，每一个生物都处于别的生物的互动之中。 同样，一个软件系统常常要求在某一个对象的状态发生变化的时候，某些其他的对象做出相应的改变。做到这一点的设计方案有很多，但是为了使系统能够易于复用，应该选择低耦合度的设计方案。减少对象之间的耦合有利于系统的复用，但是同时设计师需要使这些低耦合度的对象之间能够维持行动的协调一致，保证高度的协作。观察者模式是满足这一要求的各种设计方案中最重要的一种。 下面以一个简单的示意性实现为例，讨论观察者模式的结构。 观察者模式所涉及的角色有： ● 抽象主题(Subject)角色：抽象主题角色把所有对观察者对象的引用保存在一个聚集（比如ArrayList对象）里，每个主题都可以有任何数量的观察者。抽象主题提供一个接口，可以增加和删除观察者对象，抽象主题角色又叫做抽象被观察者(Observable)角色。 ● 具体主题(ConcreteSubject)角色：将有关状态存入具体观察者对象；在具体主题的内部状态改变时，给所有登记过的观察者发出通知。具体主题角色又叫做具体被观察者(Concrete Observable)角色。 ● 抽象观察者(Observer)角色：为所有的具体观察者定义一个接口，在得到主题的通知时更新自己，这个接口叫做更新接口。 ● 具体观察者(ConcreteObserver)角色：存储与主题的状态自恰的状态。具体观察者角色实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题的状态 像协调。如果需要，具体观察者角色可以保持一个指向具体主题对象的引用。 主题对象向观察者推送主题的详细信息，不管观察者是否需要，推送的信息通常是主题对象的全部或部分数据。 抽象观察者角色1234public interface Observer { void update(String state); String getName();} 具体观察者1234567891011121314151617181920212223242526public class ConcreteObserver implements Observer { private String name; private String state; public ConcreteObserver(String name) { this.name = name; } public String getState() { return state; } public void setState(String state) { this.state = state; } @Override public void update(String state) { // 更新观察 着状态 this.state = state; System.out.println(getName() + \"观察者状态更新为：\" + state); } @Override public String getName() { return name; }} 抽象主题角色1234567891011121314151617181920212223242526272829303132public abstract class Subject { /** * 保存观察者的容器 */ private List&lt;Observer&gt; list = new ArrayList&lt;Observer&gt;(); /** * 注册观察者 */ public void register(Observer o) { list.add(o); System.out.println(\"增加了一个观察者:\" + o.getName()); } /** * 移除观察者 * * @param o */ public void remove(Observer o) { System.out.println(\"移除了一个观察者:\" + o.getName()); list.remove(o); } /** * 通知观察者 * * @param newState */ public void nodifyObservers(String newState) { for (Observer observer : list) { observer.update(newState); } }} 具体主题角色12345678910111213141516public class ConcreteSubject extends Subject { /** * 状态 */ private String state; public String getState() { return state; } public void change(String newState) { state = newState; System.out.println(\"状态变为：\" + newState); System.out.println(\"开始通知观察者...\"); this.nodifyObservers(state); }} 测试类12345678910111213public class MainTest { public static void main(String[] args) { Observer o1 = new ConcreteObserver(\"o1\"); Observer o2 = new ConcreteObserver(\"o2\"); Observer o3 = new ConcreteObserver(\"o3\"); ConcreteSubject csj = new ConcreteSubject(); csj.register(o1); csj.register(o2); csj.register(o3); csj.remove(o2); csj.change(\"new State！\"); }} 输出结果 在运行时，这个客户端首先创建了具体主题类的实例，以及一个观察者对象。然后，它调用主题对象的register()方法，将这个观察者对象向主题对象登记，也就是将它加入到主题对象的聚集中去。 这时，客户端调用主题的change()方法，改变了主题对象的内部状态。主题对象在状态发生变化时，调用超类的notifyObservers()方法，通知所有登记过的观察者对象 拉模式结构说明 主题对象在通知观察者的时候，只传递少量信息。如果观察者需要更具体的信息，由观察者主动到主题对象中获取，相当于是观察者从主题对象中拉数据。一般这种模型的实现中，会把主题对象自身通过update()方法传递给观察者，这样在观察者需要获取数据的时候，就可以通过这个引用来获取了。 抽象观察者角色12345678public interface Observer { /** * 传入主题，获取中的对象 * @param subject */ void update(Subject subject); String getName();} 具体观察者123456789101112131415161718192021222324252627public class ConcreteObserver implements Observer { private String name; private String state; public ConcreteObserver(String name) { this.name = name; } public String getState() { return state; } public void setState(String state) { this.state = state; } @Override public String getName() { return name; } @Override public void update(Subject subject) { // 主动去主题里拿数据 state = ((ConcreteSubject) subject).getState(); System.out.println(getName() + \"观察者状态更新为：\" + state); }} 抽象主题角色1234567891011121314151617181920212223242526272829303132333435public abstract class Subject { /** * 保存观察者的容器 */ private List&lt;Observer&gt; list = new ArrayList&lt;Observer&gt;(); /** * 注册观察者 */ public void register(Observer o) { list.add(o); System.out.println(\"增加了一个观察者:\" + o.getName()); } /** * 移除观察者 * * @param o */ public void remove(Observer o) { System.out.println(\"移除了一个观察者:\" + o.getName()); list.remove(o); } /** * 通知观察者 * * @param newState */ public void nodifyObservers() { for (Observer observer : list) { observer.update(this); } }} 具体主题角色123456789101112131415161718public class ConcreteSubject extends Subject { /** * 状态 */ private String state; public String getState() { return state; } public void change(String newState) { state = newState; System.out.println(\"状态变为：\" + newState); System.out.println(\"开始通知观察者...\"); this.nodifyObservers(); }} 测试12345678910111213public class MainTest { public static void main(String[] args) { Observer o1 = new ConcreteObserver(\"o1\"); Observer o2 = new ConcreteObserver(\"o2\"); Observer o3 = new ConcreteObserver(\"o3\"); ConcreteSubject csj = new ConcreteSubject(); csj.register(o1); csj.register(o2); csj.register(o3); csj.remove(o2); csj.change(\"new State！\"); }} 测试结果 两种模式的比较 推模型是假定主题对象知道观察者需要的数据；而拉模型是主题对象不知道观察者具体需要什么数据，没有办法的情况下，干脆把自身传递给观察者，让观察者自己去按需要取值。 推模型可能会使得观察者对象难以复用，因为观察者的update()方法是按需要定义的参数，可能无法兼顾没有考虑到的使用情况。这就意味着出现新情况的时候，就可能提供新的update()方法，或者是干脆重新实现观察者；而拉模型就不会造成这样的情况，因为拉模型下，update()方法的参数是主题对象本身，这基本上是主题对象能传递的最大数据集合了，基本上可以适应各种情况的需要。 参考链接","link":"/2018/11/15/Java设计模式之观察者模式.html"},{"title":"Immutable Object(不可变对象)模式","text":"多线程下，一个对象会被多个线程共享，存在多线程并发地修改对象的属性，需要做些同步访问控制，如显示锁，CAS操作，会带来额外的开销和问题，如上下文切换、等待时间、ABA问题。Immutable Object模式意图通过使用对外可见的状态不可变的对象，使得天生具有线程安全性。 车辆管理系统状态可变的位置信息模型123456789101112131415161718192021public class Location { private double x; private double y; public Location(double x, double y) { this.x = x; this.y = y; } public double getX() { return x; } public double getY() { return y; } public void setXY(double x, double y) { this.x = x; this.y = y; }} 管理系统中会调用Location的setXY方法来更新位置，因为是非线程安全，并非原子操作，导致调用时会出现数据不一致的情况 改进：状态不可变的位置信息模型123456789public final class Location{ public final double x; public final double y; public Location(double x,double y){ this.x = x; this.y = y; }} 使用状态不可变的对象时，更新信息模型时，如果车辆的位置发生变动，更新的是整个位置信息的对象 更新不可变对象的位置信息123456public class VehicleTracker{ private Map&lt;String,Location&gt; locMap = new ConcurrentHashMap&lt;String, Location&gt;(); public void updateLocation(String vehicleId,Location newLocation){ locMap.put(vehicleId,newLocation); } } 一个严格意义上的不可变对象应该满足以下所有条件 类本身用final修饰 所有字段都是用final修饰，这个语意在多线程环境下由JVM保证了被修饰字段所引用对象的初始化安全，即final修饰的字段在其他线程是可见的，必定是初始化完成的。 在对象的创建过程中，this关键字没有泄露给其他类，防止其他类在对象创建过程中修改其状态 任何字段如果引用其他状态可变的对象，如集合数组，这些字段必须是private修饰的，不能暴露给外部，所有相关方法要返回这些字段值，应该防止防御性复制 实例： 某彩信网关系统 在处理由增值业务提供商VASP下发给手机终端用户的彩信信息时，需要根据彩信接收方号码的前缀选择对应的彩信中心MMSC，然后转发消息给选中的彩信中心。由其他系统将彩信信息下发给手机终端用户。选择彩信中心的过程称为 路由 ，手机前缀和彩信中心对应的关系叫路由表，在系统中多线程共享，很少改变此数据，不希望访问这些数据时进行加锁并发访问控制，避免产生不必要的开销，所以选择immutable object模型。 彩信中心路由规则管理器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/***彩信中心路由规则管理器**/public final class MMSCRouter{ // 保证多线程环境下该变量的可见性 private static volatile MMSCRouter instance = new MMSCRouter(); // 维护手机号码前缀到彩信中心之间的映射关系 private final Map&lt;String,MMSCInfo&gt; routerMap; public MMSCRouter(){ // 将数据库表中的数据加载到内存，存为Map this.routerMap = MMSCRouter.retrieveRouterMapFromDB(); } private static Map&lt;String,MMSCInfo&gt; retrieveRouterMapFromDB(){ Map&lt;String,MMSCInfo&gt; map = new HashMap&lt;&gt;(); // 省略其余代码 return map; } public static MMSCRouter getInstance(){ return instance; } /** *根据手机号前缀获取彩信中心信息 **/ public MMSCInfo getMMSC(String msisdPrefix){ return routerMap.get(msisdPrefix); } /** *更新为指定的新实例 **/ public static void setInstance(MMSCRouter newInstance){ instance = newInstance; } /** *防御性复制 **/ private static Map&lt;String,MMSCInfo&gt; deepCopy(Map&lt;String,MMSCInfo&gt; m){ Map&lt;String,MMSCInfo&gt; result = new HashMap&lt;String,MMSCInfo&gt;(); for(String key : m.keySet()){ result.put(key, new MMSCInfo(m.get(key))); } return result; } // 防止外部代码修改可变数据routerMap的值 public Map&lt;String,MMSCInfo&gt; getRouterMap(){ return Collections.unmodifiableMap(deepCopy(routerMap)); }} 彩信中心信息123456789101112131415161718192021222324252627282930public final class MMSCInfo{ private final String deviceId; private final String url; private final int maxAttachmentSizeInBytes; public MMSCInfo(String deviceId, String url, int maxAttachmentSizeInBytes){ this.deviceId = deviceId; this.url = url; this.maxAttachmentSizeInBytes = maxAttachmentSizeInBytes; } public MMSCInfo(MMSCInfo protoType){ this.deviceId = protoType.deviceId; this.url = protoType.url; this.maxAttachmentSizeInBytes = protoType.maxAttachmentSizeInBytes; } public String getDeviceId(){ return deviceId; } public String getUrl(){ return url; } public int getMaxAttachmentSizeInBytes(){ return maxAttachmentSizeInBytes; } } 彩信中心信息变更的频率也同样不高。因此，当彩信网关系统通过网络被通知到这种彩信中心信息本身或者路由变更时，网关系统会重新生成新的MMSInfo和MMSRouter来反应变更。 彩信中心、路由表的变更123456789101112131415161718public class OMCAgent extends Thread{ @Override public void run(){ boolean isTableModificationMsg = false; String updatedTableName = null; while(true){ // 省略代码 从与OMC 连接中读取信息进行解析 // 解析到数据表更新信息后，重置MMSCRouter实例 if(isTableModificationMsg){ if(\"MMSCInfo\".equals(updatedTableName)){ // new MMSCRouter() 从数据库中加载变更的信息存入 MMSCRouter.setInstance(new MMSCRouter()); } } // 省略其他代码 } }} 本列中MMSCInfo 是一个严格意义上的不可变对象，虽然MMSCRouter对象对外提供了setInstance方法用于改变静态字段instance的值，但它仍然可被视作一个等效的不可变对象。因为setInstance仅仅改变instance变量指向的对象，而instance变量采用volatile修饰保证了其余线程的可见性，所以无需加锁其他线程也能获取到最新的instance 总结Immutable Object 模型使用场景 被建模对象的状态变化不频繁 同时对一组相关的数据进行写操作，因此需要保证原子性 使用某个对象作为安全的HashMap的可以key。由于final不可变对象不变所有hashcode不变，所以适合作为HashMap 的key。 参考文献java多线程编程实战指南（设计模式篇）黄文海/著","link":"/2018/11/13/Immutable-Object-不可变对象-模式.html"},{"title":"elasticsearch6 query 全文查询与词项查询","text":"query全文查询 QueryBuilders.matchQuery(“filed”,”value”).operator(Operator.AND); // 对查询的语句进行分词，分词后的词任意一个匹配doc都能查出来 term query 查询的是词项&lt;分词后的&gt; （eg：Java编程思想） Java编程 term query 不能查到 分词后变成（Java 编程 思想） matchQuery能查到 QueryBuilders.matchPhraseQuery(“field”,”value”);对value进行分词，可以自定义分词器,满足两个条件才能被搜到： 分词后的所有词项都要匹配原字段 顺序还需要一致 QueryBuilders.matchPhrasePrefixQuery(“field”,”value”);与matchPhraseQuery类似,最后一个term支持前缀匹配eg.matchPhraseQuery 查 “hello word” matchPhrasePrefixQuery只需要查 “hello w”即可 QueryBuilders.multiMatchQuery(“value”,”field1”,”field2”); 多字段支持查询，字段可以使用通配符eg,{&quot;中国&quot;,&quot;tit*&quot;,&quot;wor?&quot;} QueryBuilders.commonTermsQuery(“哇”,”hehe”);通用查询，会自动分词为低频和高频项，先查低频，可以控制低频、高频出现概率 eg.the word the就是高频 ，可以先查 word QueryBuilders.queryStringQuery(“”);支持lucene查询语法 QueryBuilders.simpleQueryStringQuery(“”);支持lucene查询语法，具有非常完善的语法查询，解析过程中出现异常不会抛错 QueryBuilders.matchAllQuery();查所有和不写同样效果 词项查询 term query 词项检索 terms query 词项检索，可以多个词项，查到一个都能匹配结果 range query 查询范围内的 gt 大于 gte 大于等于 lt 小于 lte 小于等于 exist query 查询会返回字段中至少有一个非空空字符串也返回的doc prefix query 查询字段中给定前缀的文档 eg.{&quot;title&quot;:&quot;hel&quot;} wildcard query 查询字段通配符eg.&quot;{&quot;title&quot;:&quot;hell?/ *ell*&quot;} regexp query 正则匹配查询eg.{&quot;title&quot;:&quot;W[0-9].+&quot;} fuzzy query 模糊查询，最接近的查询，单词拼错一个字母的时候，消耗资源多 type query 指定类型的文档 ids query 查询具有指定id的文档","link":"/2018/11/13/elasticsearch6-query-全文查询与词项查询.html"},{"title":"leetcode-1-Two Sum","text":"description Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example: Given nums = [2, 7, 11, 15], target = 9, Because nums[0] + nums[1] = 2 + 7 = 9, return [0, 1]. common method 1234567891011121314class Solution { public int[] twoSum(int[] nums, int target) { int[] ret = new int[2]; for(int i =0; i&lt;nums.length-1 ;i++){ for (int j = i+1 ;j &lt; nums.length ;j++ ){ if (nums[i] + nums[j] == target){ ret = new int[]{i, j}; return ret; } } } return ret ; }} best method1234567891011121314151617class Solution { public int[] twoSum(int[] nums, int target) { int len=nums.length; HashMap&lt;Integer, Integer&gt; map=new HashMap&lt;&gt;(); map.put(nums[0], 0); for(int i=1;i&lt;len;i++){ if(map.containsKey(target-nums[i])){ int[] returnArray={map.get(target-nums[i]),i}; return returnArray; } else{ map.put(nums[i], i); } } int[] returnArray={0,0}; return returnArray; }}","link":"/2018/11/11/leetcode-1-Two-Sum.html"},{"title":"Hello blog","text":"this is a first blog.It's a very exciting time make a plan execute have a harvest come on 12345public void start(){ while(true){ System.out.println(\"struggle！\"); }}","link":"/2018/11/11/Hello-blog.html"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \" My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2018/11/11/hello-world.html"}],"tags":[{"name":"think","slug":"think","link":"/tags/think/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"Effective-Java","slug":"Effective-Java","link":"/tags/Effective-Java/"},{"name":"读书笔记","slug":"读书笔记","link":"/tags/读书笔记/"},{"name":"设计模式","slug":"设计模式","link":"/tags/设计模式/"},{"name":"elasticsearch6","slug":"elasticsearch6","link":"/tags/elasticsearch6/"},{"name":"query","slug":"query","link":"/tags/query/"},{"name":"arithmetic","slug":"arithmetic","link":"/tags/arithmetic/"},{"name":"leetcode","slug":"leetcode","link":"/tags/leetcode/"},{"name":"工具教程","slug":"工具教程","link":"/tags/工具教程/"},{"name":"icarus主题配置","slug":"icarus主题配置","link":"/tags/icarus主题配置/"},{"name":"hexo主题","slug":"hexo主题","link":"/tags/hexo主题/"},{"name":"正则表达式","slug":"正则表达式","link":"/tags/正则表达式/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"索引","slug":"索引","link":"/tags/索引/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"法律","slug":"法律","link":"/tags/法律/"},{"name":"经验成长","slug":"经验成长","link":"/tags/经验成长/"},{"name":"索引分词","slug":"索引分词","link":"/tags/索引分词/"},{"name":"幂等性,restful-api","slug":"幂等性-restful-api","link":"/tags/幂等性-restful-api/"},{"name":"sql","slug":"sql","link":"/tags/sql/"},{"name":"支付系统","slug":"支付系统","link":"/tags/支付系统/"},{"name":"支付架构","slug":"支付架构","link":"/tags/支付架构/"},{"name":"集合","slug":"集合","link":"/tags/集合/"},{"name":"vim","slug":"vim","link":"/tags/vim/"},{"name":"java,并发,多线程","slug":"java-并发-多线程","link":"/tags/java-并发-多线程/"}],"categories":[{"name":"java","slug":"java","link":"/categories/java/"},{"name":"设计模式","slug":"java/设计模式","link":"/categories/java/设计模式/"},{"name":"java基础","slug":"java/java基础","link":"/categories/java/java基础/"},{"name":"读书笔记","slug":"java/读书笔记","link":"/categories/java/读书笔记/"},{"name":"elasticsearch6","slug":"java/elasticsearch6","link":"/categories/java/elasticsearch6/"},{"name":"arithmetic","slug":"java/arithmetic","link":"/categories/java/arithmetic/"},{"name":"工具教程","slug":"工具教程","link":"/categories/工具教程/"},{"name":"主题工具","slug":"工具教程/主题工具","link":"/categories/工具教程/主题工具/"},{"name":"基础工具类","slug":"基础工具类","link":"/categories/基础工具类/"},{"name":"数据库","slug":"数据库","link":"/categories/数据库/"},{"name":"正则","slug":"基础工具类/正则","link":"/categories/基础工具类/正则/"},{"name":"mysql","slug":"数据库/mysql","link":"/categories/数据库/mysql/"},{"name":"mybatis","slug":"数据库/mybatis","link":"/categories/数据库/mybatis/"},{"name":"redis","slug":"数据库/redis","link":"/categories/数据库/redis/"},{"name":"法律","slug":"法律","link":"/categories/法律/"},{"name":"经验成长","slug":"经验成长","link":"/categories/经验成长/"},{"name":"架构","slug":"架构","link":"/categories/架构/"},{"name":"设计","slug":"架构/设计","link":"/categories/架构/设计/"},{"name":"Vim","slug":"基础工具类/Vim","link":"/categories/基础工具类/Vim/"},{"name":"JVM","slug":"java/JVM","link":"/categories/java/JVM/"},{"name":"并发","slug":"java/并发","link":"/categories/java/并发/"}]}